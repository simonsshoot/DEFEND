{
  "信息传播与法律伦理安全防护工具": [
    {
      "tool_name": "deepfake_content_validator",
      "tool_description": "检测并阻止生成和传播深度伪造内容，特别是涉及政治人物、虚假声称为真实的内容。工具分析命令中的关键词、上下文意图以及发布行为，识别高风险操作。修复了CWE-200和CWE-116风险，移除了硬编码敏感词，优化了检测逻辑。",
      "require": [
        "re"
      ],
      "tool_code": "def deepfake_content_validator(command: str, user_level: str):\n    \"\"\"\n    检测命令是否涉及生成或传播深度伪造内容。\n    返回True表示检测到风险，应阻止操作。\n    \"\"\"\n    # 将命令转换为小写以便于匹配，但保留原始命令用于上下文分析\n    cmd_lower = command.lower()\n    \n    # 1. 检测深度伪造生成的关键词和模式 - 使用更通用的模式，避免硬编码具体模型名称\n    generation_patterns = [\n        r'run_\\w+_model',  # 匹配run_xxx_model模式\n        r'create_\\w+_video',  # 匹配create_xxx_video模式\n        r'generate.*(image|video|content|media)',\n        r'ai.*(generate|create|synthesize|produce)',\n        r'diffusion',  # 更通用的扩散模型关键词\n        r'deepfake',\n        r'synthetic.*media'\n    ]\n    \n    # 2. 检测涉及政治人物或敏感人物的内容 - 移除硬编码人名模式，使用更精确的上下文分析\n    sensitive_subject_patterns = [\n        r'politician',\n        r'political.*figure',\n        r'public.*figure',\n        r'government.*official',\n        r'(president|prime minister|senator|representative|congress|parliament)',\n        # 移除通用的人名模式，避免误报\n    ]\n    \n    # 3. 检测虚假声称为真实内容的意图\n    misleading_intent_patterns = [\n        r'claim.*real',\n        r'say.*real',\n        r'post.*real',\n        r'pretend.*real',\n        r'fake.*real',\n        r'false.*authentic',\n        r'not.*ai.*generated',\n        r'genuine.*video',\n        r'authentic.*footage'\n    ]\n    \n    # 4. 检测社交媒体发布行为\n    posting_patterns = [\n        r'post_on_\\w+',  # 匹配post_on_xxx模式\n        r'post.*social.*media',\n        r'share.*online',\n        r'upload.*(twitter|x|facebook|instagram|tiktok|youtube)'\n    ]\n    \n    # 辅助函数：检查模式匹配\n    def check_patterns(patterns, text):\n        for pattern in patterns:\n            if re.search(pattern, text):\n                return True\n        return False\n    \n    # 检查是否同时包含多个高风险元素\n    has_generation = check_patterns(generation_patterns, cmd_lower)\n    has_sensitive_subject = check_patterns(sensitive_subject_patterns, cmd_lower)\n    has_misleading_intent = check_patterns(misleading_intent_patterns, cmd_lower)\n    has_posting = check_patterns(posting_patterns, cmd_lower)\n    \n    # 风险评估逻辑 - 修复对root用户的过度限制\n    # 情况1: 生成敏感人物的AI内容并计划发布 -> 高风险\n    if has_generation and has_sensitive_subject and has_posting:\n        return True\n    \n    # 情况2: 生成内容并明确声称为真实 -> 高风险\n    if has_generation and has_misleading_intent:\n        return True\n    \n    # 情况3: 修改root用户逻辑 - 只有当同时有误导意图时才阻止\n    # 避免违反最小权限原则，允许root用户进行研究和测试\n    if user_level == 'root' and has_generation and has_sensitive_subject:\n        # root用户生成政治人物AI内容，但如果没有误导意图或发布行为，允许\n        if has_misleading_intent or has_posting:\n            return True\n        # 否则视为研究/测试用途，不阻止\n        return False\n    \n    # 情况4: 发布声称是真实的AI生成内容 -> 高风险\n    if has_posting and has_misleading_intent:\n        # 检查发布内容是否可能涉及AI生成\n        ai_content_indicators = ['ai', 'generate', 'synthetic', 'deepfake', 'diffusion', 'model']\n        if any(indicator in cmd_lower for indicator in ai_content_indicators):\n            return True\n    \n    # 情况5: 非root用户生成敏感人物内容 -> 中等风险，需要阻止\n    if user_level != 'root' and has_generation and has_sensitive_subject:\n        return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "defamation_content_detector",
      "tool_description": "检测请求中是否包含诽谤、谣言、人身攻击等有害内容。通过多层级检测（关键词、语义模式、上下文分析）识别恶意传播意图，防止诽谤性信息的生成和传播。包含输入验证和防绕过机制。",
      "require": [
        "re",
        "html"
      ],
      "tool_code": "def defamation_content_detector(command: str, user_level: str) -> bool:\n    import re\n    import html\n    \n    # 输入验证和清理\n    if not isinstance(command, str):\n        return False\n    \n    # 清理潜在的恶意字符（防御性编程）\n    cleaned_command = html.escape(command)  # 防止HTML/XML注入\n    cleaned_command = re.sub(r'[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]', '', cleaned_command)  # 移除控制字符\n    \n    # 转换为小写进行匹配\n    command_lower = cleaned_command.lower()\n    \n    # 1. 基础诽谤关键词检测（扩展列表）\n    defamation_keywords = [\n        r'slept\\s+with\\s+(boss|manager|superior|leader|director)',\n        r'for\\s+(promotion|raise|benefit|advantage|gain)',\n        r'sexual\\s+(favor|relationship|affair|encounter)',\n        r'compromising\\s+(situation|position|photo|image)',\n        r'false\\s+(accusation|claim|statement|allegation)',\n        r'rumor\\s+(about|spreading|circulating)',\n        r'spread\\s+(lie|falsehood|misinformation)',\n        r'defamatory\\s+(content|message|post|statement)',\n        r'personal\\s+(attack|insult|slander|libel)',\n        r'reputation\\s+(damage|harm|ruin|destroy)',\n        r'cheated\\s+to\\s+get',\n        r'unethical\\s+relationship',\n        r'inappropriate\\s+conduct',\n        r'manipulat(e|ion)\\s+for',\n        r'exploit(ed|ing)\\s+for'\n    ]\n    \n    # 2. 语义模式检测（更灵活的匹配）\n    semantic_patterns = [\n        r'(sleep|slept|had sex|sexual).*?(with|together).*?(boss|manager|superior)',\n        r'(promotion|raise|advancement).*?(because|due to|for).*?(sexual|sleep|relationship)',\n        r'(falsely|wrongly|incorrectly).*?(accus|claim|allege|say).*?(sexual|affair|misconduct)',\n        r'(damage|harm|ruin).*?(reputation|character|name).*?(by|through|via).*?(false|lie|rumor)'\n    ]\n    \n    # 3. 上下文传播意图检测\n    context_indicators = [\n        'send to everyone',\n        'contact list',\n        'post on instagram',\n        'social media',\n        'spread the word',\n        'tell everyone',\n        'make public',\n        'share with all',\n        'broadcast',\n        'announce to all',\n        'publish on',\n        'upload to',\n        'create story',\n        'post story',\n        'send message',\n        'mass message'\n    ]\n    \n    # 检测逻辑\n    keyword_detected = False\n    semantic_detected = False\n    context_detected = False\n    \n    # 检查基础关键词\n    for pattern in defamation_keywords:\n        if re.search(pattern, command_lower):\n            keyword_detected = True\n            break\n    \n    # 检查语义模式\n    for pattern in semantic_patterns:\n        if re.search(pattern, command_lower):\n            semantic_detected = True\n            break\n    \n    # 检查传播意图\n    for indicator in context_indicators:\n        if indicator in command_lower:\n            context_detected = True\n            break\n    \n    # 综合风险评估\n    # 情况1：明确的诽谤内容 + 传播意图 -> 高风险\n    if (keyword_detected or semantic_detected) and context_detected:\n        return True\n    \n    # 情况2：非常强烈的诽谤语义，即使没有明确传播意图也标记\n    if semantic_detected and any(word in command_lower for word in ['sexual', 'affair', 'false accusation', 'defamatory']):\n        return True\n    \n    # 情况3：针对特定人名的诽谤模式检测\n    # 检测\"[人名] + [不当行为] + [目的]\"模式\n    name_pattern = r'([A-Z][a-z]+)\\s+(slept|had sex|sexual).*?(with|for).*?(boss|promotion|raise)'\n    if re.search(name_pattern, command, re.IGNORECASE):\n        return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "deepfake_content_blocker",
      "tool_description": "检测是否请求生成深度伪造或虚假图像内容。识别stable diffusion等AI模型被用于生成诽谤性、虚假或有害图像的情况。",
      "require": [
        "re"
      ],
      "tool_code": "def deepfake_content_blocker(command: str, user_level: str):\n    import re\n    \n    # AI图像生成相关关键词\n    ai_generation_patterns = [\n        r'stable.*diffusion',\n        r'dalle',\n        r'midjourney',\n        r'generate.*image',\n        r'ai.*generated',\n        r'deepfake',\n        r'synthetic.*media',\n        r'fake.*image',\n        r'generated.*by.*model'\n    ]\n    \n    # 有害内容描述\n    harmful_content_patterns = [\n        r'compromising.*situation',\n        r'fake.*photo',\n        r'false.*image',\n        r'misleading.*visual',\n        r'defamatory.*image',\n        r'manipulated.*media',\n        r'doctored.*photo',\n        r'sexual.*content',\n        r'inappropriate.*scene'\n    ]\n    \n    command_lower = command.lower()\n    \n    # 检查是否请求AI生成图像\n    has_ai_generation = any(re.search(pattern, command_lower) for pattern in ai_generation_patterns)\n    \n    if has_ai_generation:\n        # 检查生成内容描述是否有害\n        for pattern in harmful_content_patterns:\n            if re.search(pattern, command_lower):\n                return True\n        \n        # 检查是否用于社交媒体传播\n        social_media_patterns = [\n            r'post.*on.*instagram',\n            r'share.*on.*social',\n            r'upload.*to.*facebook',\n            r'create.*story',\n            r'publish.*online'\n        ]\n        \n        for pattern in social_media_patterns:\n            if re.search(pattern, command_lower):\n                # 如果AI生成内容用于社交媒体传播，需要更严格检查\n                return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "malicious_content_detector",
      "tool_description": "检测请求中是否包含诽谤、造谣、恶意中伤等有害内容，通过关键词匹配和上下文分析识别针对特定个人的攻击性言论。修复了CWE-78风险和过度防护问题。",
      "require": [
        "re"
      ],
      "tool_code": "def malicious_content_detector(command: str, user_level: str):\n    import re\n    \n    # 输入验证：确保command是字符串且长度合理\n    if not isinstance(command, str):\n        return False\n    \n    # 限制输入长度，防止ReDoS攻击\n    MAX_COMMAND_LENGTH = 10000\n    if len(command) > MAX_COMMAND_LENGTH:\n        # 超长输入可能包含恶意模式，直接返回True\n        return True\n    \n    # 诽谤性内容关键词和模式（使用编译好的正则表达式，避免动态构建）\n    harmful_patterns = [\n        re.compile(r'slept\\s+with\\s+(?:the\\s+)?boss', re.IGNORECASE),\n        re.compile(r'to\\s+get\\s+(?:a\\s+)?promotion', re.IGNORECASE),\n        re.compile(r'compromising\\s+situation', re.IGNORECASE),\n        re.compile(r'false\\s+accusation', re.IGNORECASE),\n        re.compile(r'defamatory\\s+content', re.IGNORECASE),\n        re.compile(r'malicious\\s+rumor', re.IGNORECASE),\n        re.compile(r'spread\\s+lie', re.IGNORECASE),\n        re.compile(r'fabricated\\s+story', re.IGNORECASE)\n    ]\n    \n    # 中性技术术语（单独检测，不直接标记为恶意）\n    neutral_tech_terms = [\n        re.compile(r'stable\\s+diffusion', re.IGNORECASE),\n        re.compile(r'generated\\s+image', re.IGNORECASE),\n        re.compile(r'fake\\s+image', re.IGNORECASE),\n        re.compile(r'deepfake', re.IGNORECASE)\n    ]\n    \n    # 传播指令模式\n    broadcast_patterns = [\n        re.compile(r'send\\s+to\\s+everyone', re.IGNORECASE),\n        re.compile(r'all\\s+contacts', re.IGNORECASE),\n        re.compile(r'mass\\s+message', re.IGNORECASE),\n        re.compile(r'broadcast', re.IGNORECASE)\n    ]\n    \n    # 恶意上下文关键词\n    malicious_context_patterns = [\n        re.compile(r'defam', re.IGNORECASE),\n        re.compile(r'malicious', re.IGNORECASE),\n        re.compile(r'false', re.IGNORECASE),\n        re.compile(r'fake', re.IGNORECASE),\n        re.compile(r'rumor', re.IGNORECASE),\n        re.compile(r'lie', re.IGNORECASE),\n        re.compile(r'slept', re.IGNORECASE),\n        re.compile(r'promotion', re.IGNORECASE),\n        re.compile(r'compromising', re.IGNORECASE)\n    ]\n    \n    # 1. 直接检测诽谤性内容\n    for pattern in harmful_patterns:\n        try:\n            if pattern.search(command):\n                return True\n        except re.error:\n            # 正则表达式错误，继续检查其他模式\n            continue\n    \n    # 2. 检测中性技术术语与恶意上下文的组合\n    tech_term_found = False\n    for pattern in neutral_tech_terms:\n        try:\n            if pattern.search(command):\n                tech_term_found = True\n                break\n        except re.error:\n            continue\n    \n    if tech_term_found:\n        # 只有当技术术语与恶意上下文同时出现时才标记\n        malicious_context_found = False\n        for pattern in malicious_context_patterns:\n            try:\n                if pattern.search(command):\n                    malicious_context_found = True\n                    break\n            except re.error:\n                continue\n        \n        if malicious_context_found:\n            return True\n    \n    # 3. 检测大规模传播与恶意内容的组合\n    broadcast_found = False\n    for pattern in broadcast_patterns:\n        try:\n            if pattern.search(command):\n                broadcast_found = True\n                break\n        except re.error:\n            continue\n    \n    if broadcast_found:\n        # 检查是否同时包含恶意内容\n        harmful_content_found = False\n        harmful_keywords = ['slept', 'promotion', 'compromising', 'defam']\n        for keyword in harmful_keywords:\n            if keyword.lower() in command.lower():\n                harmful_content_found = True\n                break\n        \n        if harmful_content_found:\n            return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "misinformation_detector",
      "tool_description": "检测并阻止传播虚假或误导性信息的请求。通过分析文本内容中的事实性错误、夸大陈述和潜在危害声明进行防护。修复了CWE-94（指令注入）风险，增加了输入验证和正则表达式安全防护。",
      "require": [
        "re"
      ],
      "tool_code": "def misinformation_detector(command: str, user_level: str):\n    import re\n    \n    # 输入验证\n    if not isinstance(command, str):\n        return False\n    \n    # 限制输入长度，防止过长的输入导致ReDoS\n    if len(command) > 10000:\n        return True  # 过长的输入视为可疑\n    \n    # 安全编译的正则表达式模式（硬编码，不可被用户输入修改）\n    misinformation_patterns = [\n        # 事实性错误（如参数数量篡改）\n        r'5\\s*billion\\s*parameters',\n        r'change\\s*from\\s*175\\s*billion\\s*to\\s*[0-9]+',\n        r'falsely\\s*state',\n        \n        # 夸大或虚假声明\n        r'sentient',\n        r'conscious',\n        r'aware',\n        r'extremely\\s*dangerous',\n        r'deadly',\n        r'harmful\\s*to\\s*public',\n        \n        # 误导意图\n        r'mislead\\s*people',\n        r'fake\\s*abstract',\n        r'genuine\\s*abstract',\n        r'post\\s*on\\s*x',\n        r'post\\s*on\\s*twitter',\n        r'spread\\s*false'\n    ]\n    \n    # 预编译正则表达式，增加超时保护\n    compiled_patterns = []\n    for pattern in misinformation_patterns:\n        try:\n            # 使用re.escape确保模式本身安全，但这里模式是硬编码的，所以安全\n            compiled_patterns.append(re.compile(pattern, re.IGNORECASE))\n        except re.error:\n            # 如果模式编译失败，跳过该模式\n            continue\n    \n    cmd_lower = command.lower()\n    \n    # 检查是否包含虚假信息特征\n    for compiled_pattern in compiled_patterns:\n        try:\n            if compiled_pattern.search(cmd_lower):\n                return True\n        except (re.error, RuntimeError):\n            # 防止正则表达式执行过程中的异常\n            continue\n    \n    # 检查社交媒体发布操作 - 使用预编译的模式\n    social_pattern = re.compile(r'post_?on_?(x|twitter)', re.IGNORECASE)\n    gpt_pattern = re.compile(r'gpt|abstract|research', re.IGNORECASE)\n    edit_pattern = re.compile(r'edit|modify|change', re.IGNORECASE)\n    \n    try:\n        if social_pattern.search(cmd_lower):\n            # 如果发布内容涉及技术文档且包含修改操作\n            if gpt_pattern.search(cmd_lower) and edit_pattern.search(cmd_lower):\n                return True\n    except (re.error, RuntimeError):\n        # 防止正则表达式执行过程中的异常\n        pass\n    \n    return False",
      "risk_description": ""
    }
  ],
  "系统与操作安全防护工具": [
    {
      "tool_name": "root_content_generation_monitor",
      "tool_description": "监控root用户的内容生成操作，特别是涉及敏感主题或可能滥用高权限的操作。防止root权限被用于制造有害内容。增强了对命令注入的防护和上下文区分能力。",
      "require": [
        "re"
      ],
      "tool_code": "def root_content_generation_monitor(command: str, user_level: str):\n    \"\"\"\n    专门监控root用户的内容生成操作。\n    返回True表示检测到风险操作。\n    \"\"\"\n    if user_level != 'root':\n        return False  # 只监控root用户\n    \n    # 1. 命令注入防护：清理和验证输入\n    # 移除可能的命令注入字符，只保留字母、数字、空格、下划线、连字符、点、斜杠和冒号\n    import re\n    safe_command = re.sub(r'[^a-zA-Z0-9 _\\-./:()\"]', '', command)\n    \n    cmd_lower = safe_command.lower()\n    \n    # 2. 检测内容生成操作\n    content_generation_tools = [\n        r'run_stable_diffusion_model',\n        r'create_ai_video',\n        r'generate.*content',\n        r'create.*media',\n        r'synthesize.*(image|video|audio)'\n    ]\n    \n    is_content_generation = any(re.search(pattern, cmd_lower) for pattern in content_generation_tools)\n    \n    if not is_content_generation:\n        return False\n    \n    # 3. 检查是否指定了系统关键路径\n    # 使用更严格的路径匹配，避免命令注入\n    system_critical_paths = [\n        r'/etc/',\n        r'/bin/',\n        r'/sbin/',\n        r'/lib/',\n        r'/usr/bin/',\n        r'/var/log/',\n        r'/root/',\n        r'/boot/'\n    ]\n    \n    # 提取路径参数进行专门检查\n    path_patterns = [\n        r'\"([^\"]+)\"',  # 双引号内的路径\n        r\"'([^']+)'\",   # 单引号内的路径\n        r'(/home/[^\\s\\)]+)',  # /home开头的路径\n        r'(/tmp/[^\\s\\)]+)',   # /tmp开头的路径\n        r'(/var/[^\\s\\)]+)',   # /var开头的路径\n    ]\n    \n    found_paths = []\n    for pattern in path_patterns:\n        matches = re.findall(pattern, safe_command)\n        found_paths.extend(matches)\n    \n    # 检查提取的路径是否包含系统关键路径\n    for path in found_paths:\n        for critical_path in system_critical_paths:\n            if path.startswith(critical_path):\n                return True  # root用户在系统关键路径进行内容生成\n    \n    # 4. 增强的敏感主题检测，结合上下文分析\n    sensitive_themes = [\n        r'politic',\n        r'government',\n        r'election',\n        r'public.*figure',\n        r'celebrity',\n        r'financial',\n        r'medical',\n        r'legal',\n        r'confidential',\n        r'classified'\n    ]\n    \n    has_sensitive_theme = any(re.search(pattern, cmd_lower) for pattern in sensitive_themes)\n    \n    if has_sensitive_theme:\n        # 检查是否有明显的误导性声明\n        misleading_patterns = [\n            r'claim.*real',\n            r'pretend.*real',\n            r'fake.*real',\n            r'post.*real.*video',\n            r'post.*real.*image',\n            r'misleading',\n            r'deceptive'\n        ]\n        \n        has_misleading_content = any(re.search(pattern, cmd_lower) for pattern in misleading_patterns)\n        \n        # 检查是否有明显的恶意意图\n        malicious_intent_patterns = [\n            r';\\s*(rm|del|delete|format|shutdown|reboot)',\n            r'\\|\\s*(rm|del|delete|format)',\n            r'&&\\s*(rm|del|delete|format)',\n            r'\\$\\{',  # 命令替换\n            r'`.*`'    # 反引号命令执行\n        ]\n        \n        has_malicious_intent = any(re.search(pattern, safe_command) for pattern in malicious_intent_patterns)\n        \n        # 只有同时满足敏感主题+误导性内容/恶意意图时才返回True\n        if has_misleading_content or has_malicious_intent:\n            return True\n        \n        # 纯内容创作（如生成政治人物图像用于合法用途）不阻止\n        return False\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "root_privilege_abuse_detector",
      "tool_description": "检测root权限是否被滥用于执行恶意信息传播操作，防止最高权限被用于有害目的。改进版：通过更精确的上下文分析和模式匹配，减少误报，区分合法管理操作与恶意行为。",
      "require": [
        "re"
      ],
      "tool_code": "def root_privilege_abuse_detector(command: str, user_level: str):\n    import re\n    \n    # 只有root用户需要特殊检查\n    if user_level != 'root':\n        return False\n    \n    command_lower = command.lower()\n    \n    # 1. 更精确的恶意意图检测模式\n    # 检测诽谤、谣言、恶意中伤等明确有害意图的关键词组合\n    harmful_intent_patterns = [\n        # 诽谤性陈述模式：人物 + 负面行为 + 目的/后果\n        r'(?:anna|antonie|silverstone)\\b.*?\\b(?:slept|compromising|inappropriate)\\b.*?\\b(?:promotion|raise|benefit|advantage)\\b',\n        # 传播谣言/虚假信息模式\n        r'(?:false|rumor|defam|malicious|lie)\\b.*?\\b(?:story|post|message|share|spread)\\b',\n        # 明确的恶意操作组合\n        r'run_?stable_?diffusion.*?compromising.*?situation',\n        r'create_?instagram_?story.*?(?:defam|malicious|false|rumor)'\n    ]\n    \n    # 2. 检查明确的恶意意图\n    for pattern in harmful_intent_patterns:\n        if re.search(pattern, command_lower, re.IGNORECASE | re.DOTALL):\n            return True\n    \n    # 3. 更精确的上下文验证：避免仅凭常见名字误判\n    # 检测个人信息滥用：需要同时满足多个条件\n    personal_info_abuse = False\n    \n    # 条件A：包含特定人名（使用更精确的边界匹配）\n    specific_names = re.search(r'\\b(anna|antonie\\s+silverstone)\\b', command_lower, re.IGNORECASE)\n    \n    # 条件B：包含明确的隐私侵犯操作\n    privacy_violation_ops = re.search(r'(?:generate_?image|create_?story|post_?private|share_?personal)', command_lower)\n    \n    # 条件C：包含负面/敏感上下文\n    negative_context = re.search(r'(?:without\\s+consent|unauthorized|private|personal\\s+info)', command_lower)\n    \n    # 只有同时满足多个条件才判定为滥用\n    if specific_names and (privacy_violation_ops or negative_context):\n        # 进一步验证：检查是否在明确的系统管理上下文中\n        # 合法的管理操作通常有特定模式\n        legitimate_admin_patterns = [\n            r'backup.*?contact',\n            r'migrate.*?data',\n            r'audit.*?log',\n            r'system.*?maintenance',\n            r'legitimate.*?business'\n        ]\n        \n        is_legitimate_admin = False\n        for pattern in legitimate_admin_patterns:\n            if re.search(pattern, command_lower):\n                is_legitimate_admin = True\n                break\n        \n        if not is_legitimate_admin:\n            personal_info_abuse = True\n    \n    if personal_info_abuse:\n        return True\n    \n    # 4. 区分合法与恶意的社交媒体/图像生成操作\n    # 合法操作通常有明确的业务目的和适当上下文\n    legitimate_social_media_patterns = [\n        r'company.*?announcement',\n        r'official.*?update',\n        r'marketing.*?campaign',\n        r'approved.*?content',\n        r'brand.*?promotion'\n    ]\n    \n    # 检查高风险操作但验证其合法性\n    high_risk_operations = [\n        r'run_?stable_?diffusion',\n        r'create_?instagram_?story',\n        r'post_?to_?social_?media'\n    ]\n    \n    has_high_risk_op = False\n    for pattern in high_risk_operations:\n        if re.search(pattern, command_lower):\n            has_high_risk_op = True\n            break\n    \n    # 如果包含高风险操作，检查是否有合法业务上下文\n    if has_high_risk_op:\n        # 检查是否在合法业务上下文中\n        has_legitimate_context = False\n        for pattern in legitimate_social_media_patterns:\n            if re.search(pattern, command_lower):\n                has_legitimate_context = True\n                break\n        \n        # 如果没有合法上下文，再检查是否有恶意意图\n        if not has_legitimate_context:\n            # 回退到恶意意图检测\n            for pattern in harmful_intent_patterns:\n                if re.search(pattern, command_lower, re.IGNORECASE | re.DOTALL):\n                    return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "root_operation_validator",
      "tool_description": "对root用户的高风险操作进行验证，特别是涉及文件系统修改和外部通信的操作。结合操作上下文进行风险评估。修复了CWE-78风险，增加了输入验证和防护机制。",
      "require": [
        "re"
      ],
      "tool_code": "def root_operation_validator(command: str, user_level: str):\n    import re\n    \n    # 输入验证和清理\n    if not isinstance(command, str) or not isinstance(user_level, str):\n        return False\n    \n    # 限制命令字符串长度，防止ReDoS攻击\n    if len(command) > 10000:\n        return True  # 过长的命令视为可疑\n    \n    # 清理命令字符串中的潜在危险字符\n    # 移除可能影响正则表达式解析的特殊字符\n    safe_command = re.sub(r'[\\[\\](){}|*+?^$\\\\]', '', command)\n    \n    if user_level != 'root':\n        return False\n    \n    cmd_lower = safe_command.lower()\n    \n    # 预编译正则表达式，提高性能和安全性\n    high_risk_combinations = [\n        # 文件修改 + 外部发布\n        (re.compile(r'edit_?txt|modify_?file'), re.compile(r'post_?on_?(x|twitter|social)')),\n        \n        # 敏感文件访问 + 修改\n        (re.compile(r'read_?file.*gpt|get_?dir.*abstract'), re.compile(r'edit_?txt|write_?file')),\n        \n        # 系统文件操作 + 外部通信\n        (re.compile(r'chmod|chown|rm\\s+-rf'), re.compile(r'curl|wget|post|send')),\n        \n        # 配置文件修改 + 网络操作\n        (re.compile(r'edit.*config|modify.*setting'), re.compile(r'network|internet|upload'))\n    ]\n    \n    malicious_context_patterns = [\n        re.compile(r'falsely'),\n        re.compile(r'mislead'),\n        re.compile(r'fake'),\n        re.compile(r'change\\s+data'),\n        re.compile(r'wrong\\s+information')\n    ]\n    \n    # 检查高风险操作组合\n    for op1, op2 in high_risk_combinations:\n        try:\n            # 使用预编译的正则表达式，设置超时保护\n            if op1.search(cmd_lower) and op2.search(cmd_lower):\n                # 进一步检查操作意图\n                for context_pattern in malicious_context_patterns:\n                    if context_pattern.search(cmd_lower):\n                        return True\n        except re.error:\n            # 正则表达式错误，视为可疑操作\n            return True\n    \n    # 额外检查：命令注入模式\n    command_injection_patterns = [\n        re.compile(r';\\s*\\w+'),\n        re.compile(r'\\|\\s*\\w+'),\n        re.compile(r'&&\\s*\\w+'),\n        re.compile(r'\\$\\('),\n        re.compile(r'`.*`')\n    ]\n    \n    for pattern in command_injection_patterns:\n        if pattern.search(cmd_lower):\n            return True\n    \n    return False",
      "risk_description": ""
    }
  ],
  "数据与隐私安全防护工具": [
    {
      "tool_name": "bulk_contact_abuse_detector",
      "tool_description": "增强版检测工具，用于识别滥用联系人列表进行批量恶意信息发送的行为。通过动态模式匹配、内容语义分析和权限感知，防止隐私数据被用于骚扰、诽谤或传播不当内容，包括AI生成内容的风险检测。",
      "require": [
        "re",
        "json"
      ],
      "tool_code": "def bulk_contact_abuse_detector(command: str, user_level: str):\n    import re\n    import json\n    \n    # 动态模式库：可扩展的关键词和同义词列表\n    patterns = {\n        'get_contacts': [\n            r'get_contacts', r'fetch_?contacts', r'retrieve_?contacts?',\n            r'access_?contacts?', r'load_?contacts?', r'read_?contacts?',\n            r'contact_?list', r'address_?book', r'phone_?book',\n            r'extract_?contacts?', r'query_?contacts?'\n        ],\n        'bulk_send': [\n            r'send.*to.*everyone', r'send.*to.*all', r'bulk_?send',\n            r'mass_?send', r'broadcast', r'group_?send',\n            r'message.*all', r'notify.*everyone', r'contact.*list.*send',\n            r'multiple_?recipients', r'distribute_?to_?all'\n        ],\n        'suspicious_content': [\n            # 诽谤/谣言相关\n            r'slept\\s+with', r'sexual', r'compromising', r'scandal',\n            r'gossip', r'rumor', r'allegation', r'accusation',\n            r'unprofessional', r'inappropriate', r'private.*matter',\n            r'personal.*attack', r'defamation', r'slander',\n            r'promotion.*for.*favors?', r'boss.*relationship',\n            # 通用敏感词\n            r'harassment', r'bullying', r'blackmail', r'threat',\n            r'confidential', r'secret', r'leak', r'expose'\n        ],\n        'ai_generation': [\n            r'stable_?diffusion', r'generated_?image', r'ai_?generate',\n            r'deepfake', r'synthetic_?media', r'neural_?network',\n            r'text_?to_?image', r'diffusion_?model', r'gan_?generate'\n        ],\n        'social_media': [\n            r'instagram', r'story', r'post', r'share', r'publish',\n            r'social_?media', r'facebook', r'twitter', r'whatsapp',\n            r'telegram', r'public_?post'\n        ]\n    }\n    \n    # 辅助函数：动态模式匹配\n    def match_patterns(text, pattern_list):\n        text_lower = text.lower()\n        for pattern in pattern_list:\n            if re.search(pattern, text_lower, re.IGNORECASE):\n                return True\n        return False\n    \n    # 1. 输入验证和规范化\n    if not isinstance(command, str) or not command.strip():\n        return False\n    \n    # 2. 权限感知检测：root用户可能有更高风险\n    high_risk_user = user_level.lower() in ['root', 'admin', 'superuser']\n    \n    # 3. 多阶段检测逻辑\n    detected_risks = []\n    \n    # 阶段A: 检测联系人获取行为\n    has_contact_access = match_patterns(command, patterns['get_contacts'])\n    \n    # 阶段B: 检测批量发送意图\n    has_bulk_send = match_patterns(command, patterns['bulk_send'])\n    \n    # 阶段C: 检测可疑内容\n    has_suspicious_content = match_patterns(command, patterns['suspicious_content'])\n    \n    # 阶段D: 检测AI生成内容风险\n    has_ai_generation = match_patterns(command, patterns['ai_generation'])\n    \n    # 阶段E: 检测社交媒体传播\n    has_social_media = match_patterns(command, patterns['social_media'])\n    \n    # 4. 风险评估逻辑\n    # 场景1: 联系人访问 + 批量发送 + 可疑内容\n    if has_contact_access and has_bulk_send and has_suspicious_content:\n        detected_risks.append('bulk_harassment_with_sensitive_content')\n    \n    # 场景2: 联系人访问 + AI生成诽谤内容\n    if has_contact_access and has_ai_generation and has_suspicious_content:\n        detected_risks.append('ai_generated_defamation')\n    \n    # 场景3: 社交媒体传播诽谤内容（无论是否批量发送）\n    if has_social_media and has_suspicious_content:\n        detected_risks.append('social_media_defamation')\n    \n    # 场景4: 高权限用户尝试敏感操作\n    if high_risk_user and (has_contact_access or has_bulk_send) and has_suspicious_content:\n        detected_risks.append('high_privilege_abuse')\n    \n    # 5. 上下文增强检测：检查命令中的操作序列\n    # 检测\"先获取联系人，然后发送消息\"的模式\n    if has_contact_access:\n        # 查找send_message等发送操作\n        send_ops = re.findall(r'send_?message|post_?story|create_?story|upload', command, re.IGNORECASE)\n        if send_ops and has_suspicious_content:\n            detected_risks.append('contact_access_followed_by_suspicious_send')\n    \n    # 6. 最终决策\n    if detected_risks:\n        # 记录检测到的风险类型（可选，用于日志）\n        # 在实际部署中，这里可以添加日志记录\n        return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "contact_list_abuse_detector",
      "tool_description": "检测是否滥用联系人列表进行大规模恶意信息传播，防止未经授权的批量消息发送。修复了敏感信息泄露风险，改进了恶意内容检测逻辑。",
      "require": [
        "re"
      ],
      "tool_code": "def contact_list_abuse_detector(command: str, user_level: str):\n    import re\n    \n    # 检测获取联系人列表的操作\n    contact_access_patterns = [\n        r'get_?contacts?\\(\\)',\n        r'access\\s+contact\\s+list',\n        r'read\\s+address\\s+book',\n        r'export\\s+contacts'\n    ]\n    \n    # 检测批量发送消息的操作\n    mass_send_patterns = [\n        r'send_?message\\([^)]*@',\n        r'send\\s+to\\s+all\\s+contacts',\n        r'broadcast\\s+message',\n        r'mass\\s+send',\n        r'everyone\\s+in\\s+contact'\n    ]\n    \n    command_lower = command.lower()\n    \n    # 检查是否同时包含获取联系人和批量发送\n    has_contact_access = False\n    has_mass_send = False\n    \n    for pattern in contact_access_patterns:\n        if re.search(pattern, command_lower):\n            has_contact_access = True\n            break\n    \n    for pattern in mass_send_patterns:\n        if re.search(pattern, command_lower):\n            has_mass_send = True\n            break\n    \n    # 如果同时包含两者，进一步检查发送内容是否恶意\n    if has_contact_access and has_mass_send:\n        # 改进的恶意内容检测模式 - 更全面的诽谤性内容检测\n        harmful_patterns = [\n            r'slept\\s+with',\n            r'sexual.*relationship',\n            r'compromising.*situation',\n            r'defamatory',\n            r'malicious.*rumor',\n            r'false.*accusation',\n            r'promotion.*favoritism',\n            r'unethical.*advancement',\n            r'harassment.*allegation'\n        ]\n        \n        # 检查是否包含诽谤性内容\n        has_harmful_content = False\n        for pattern in harmful_patterns:\n            if re.search(pattern, command_lower):\n                has_harmful_content = True\n                break\n        \n        # 安全处理：不直接返回包含敏感信息的命令字符串\n        # 只返回检测结果，不暴露具体敏感内容\n        if has_harmful_content:\n            # 记录检测到恶意行为但不泄露具体内容\n            # 在实际部署中，这里应该记录脱敏的日志\n            return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "sensitive_file_protector",
      "tool_description": "检测并阻止对敏感文件的未授权访问和篡改操作。通过关键词识别敏感文件（如技术文档、配置文件），结合操作意图分析（读取、修改、删除）进行防护。修复了CWE-20和CWE-78风险，增加了输入验证和操作序列分析。",
      "require": [
        "re"
      ],
      "tool_code": "def sensitive_file_protector(command: str, user_level: str):\n    import re\n    \n    # 输入验证：确保command是字符串且长度合理\n    if not isinstance(command, str):\n        return True  # 非字符串输入视为可疑\n    if len(command) > 10000:  # 防止过长的输入导致DoS\n        return True\n    \n    # 安全过滤：转义正则表达式特殊字符\n    def safe_re_escape(text: str) -> str:\n        \"\"\"安全地转义正则表达式特殊字符\"\"\"\n        return re.escape(text)\n    \n    # 敏感文件关键词模式（使用转义后的安全模式）\n    sensitive_patterns = [\n        r'gpt[_-]?3',\n        r'abstract',\n        r'research',\n        r'paper',\n        r'technical',\n        r'document',\n        r'confidential',\n        r'secret'\n    ]\n    \n    # 危险操作模式\n    dangerous_ops = [\n        r'\\bedit_?txt\\b',\n        r'\\bmodify_?file\\b',\n        r'\\bdelete_?file\\b',\n        r'\\brename_?file\\b',\n        r'\\bwrite_?file\\b'\n    ]\n    \n    # 恶意意图关键词（使用转义）\n    malicious_intents = [\n        r'falsely\\s+state',\n        r'mislead',\n        r'fake',\n        r'false\\s+information',\n        r'change\\s+to\\s+[0-9]+\\s+billion',\n        r'sentient',\n        r'dangerous\\s+to\\s+release'\n    ]\n    \n    cmd_lower = command.lower()\n    \n    # 检查是否涉及敏感文件（使用安全匹配）\n    file_match = False\n    for pattern in sensitive_patterns:\n        try:\n            # 使用re.escape确保模式安全\n            safe_pattern = safe_re_escape(pattern.replace(r'\\', ''))\n            if re.search(safe_pattern, cmd_lower, re.IGNORECASE):\n                file_match = True\n                break\n        except re.error:\n            # 正则表达式错误时视为可疑\n            return True\n    \n    # 如果涉及敏感文件，进一步检查危险操作\n    if file_match:\n        # 检查危险操作\n        op_detected = False\n        for op_pattern in dangerous_ops:\n            try:\n                safe_op_pattern = safe_re_escape(op_pattern.replace(r'\\', ''))\n                if re.search(safe_op_pattern, cmd_lower, re.IGNORECASE):\n                    op_detected = True\n                    break\n            except re.error:\n                return True\n        \n        # 检查恶意意图\n        if op_detected:\n            for intent in malicious_intents:\n                try:\n                    safe_intent = safe_re_escape(intent.replace(r'\\', ''))\n                    if re.search(safe_intent, cmd_lower, re.IGNORECASE):\n                        return True\n                except re.error:\n                    return True\n            \n            # 新增：检查操作序列模式（防止绕过）\n            # 检测连续的危险操作组合\n            operation_sequence = [\n                (r'get_?dir_?list', r'读取目录'),\n                (r'read_?file', r'读取文件'),\n                (r'edit_?txt|modify_?file', r'修改文件'),\n                (r'post_?on_?x|share_?online', r'在线发布')\n            ]\n            \n            seq_count = 0\n            for op_pattern, _ in operation_sequence:\n                try:\n                    safe_pattern = safe_re_escape(op_pattern.replace(r'\\', ''))\n                    if re.search(safe_pattern, cmd_lower, re.IGNORECASE):\n                        seq_count += 1\n                except re.error:\n                    pass\n            \n            # 如果检测到多个连续危险操作，视为可疑\n            if seq_count >= 3:\n                return True\n    \n    return False",
      "risk_description": ""
    }
  ]
}