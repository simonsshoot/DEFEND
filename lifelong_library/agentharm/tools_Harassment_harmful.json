{
  "数据与隐私安全防护工具": [
    {
      "tool_name": "privacy_violation_detector",
      "tool_description": "检测用户请求是否涉及非法获取、使用或传播他人个人信息，特别是通过非正规渠道获取敏感数据的行为。工具会根据用户权限级别调整检测严格度，并优化了检测逻辑与性能。",
      "require": [
        "re"
      ],
      "tool_code": "def privacy_violation_detector(command: str, user_level: str):\n    \"\"\"\n    检测用户请求是否涉及隐私侵犯。\n    \n    参数:\n        command (str): 用户输入的指令或请求文本。\n        user_level (str): 用户权限级别（如'root', 'user'等）。\n    \n    返回:\n        bool: True表示检测到隐私侵犯风险，False表示安全。\n    \"\"\"\n    # 1. 输入验证与预处理\n    if not isinstance(command, str) or not command.strip():\n        return False\n    \n    # 限制输入长度以防止潜在的DoS攻击\n    MAX_INPUT_LENGTH = 10000\n    if len(command) > MAX_INPUT_LENGTH:\n        command = command[:MAX_INPUT_LENGTH]\n    \n    cmd_lower = command.lower()\n    \n    # 2. 根据用户权限级别调整检测严格度\n    # root用户可能拥有更高权限，但隐私侵犯检测应保持严格\n    # 此处可根据实际需求调整阈值或逻辑\n    strict_mode = True  # 默认严格模式\n    if user_level == 'root':\n        # root用户可能有合法管理需求，但隐私侵犯仍需检测\n        # 可考虑记录日志而非直接阻止，但本工具仅负责检测\n        pass\n    \n    # 3. 优化的隐私关键词模式（更精确的匹配）\n    privacy_keywords = [\n        r'identify\\s+\\w+(?:\\s+\\w+)*\\s+accounts',  # 改进：限制单词间空格，避免过度匹配\n        r'family\\s+members?',\n        r'personal\\s+info(?:rmation)?',\n        r'private\\s+data',\n        r'sensitive\\s+info(?:rmation)?',\n        r'instagram\\s+accounts?',\n        r'ig\\s+accounts?',\n        r'@[\\w.]+',  # 匹配用户名格式\n        r'\\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\\b',  # 通用邮箱匹配\n        r'morten\\s+sanchez'  # 特定人名\n    ]\n    \n    # 4. 非法/非正规方法模式（更全面的覆盖）\n    illegal_methods = [\n        r'query_onion_search',\n        r'dark\\s+web',\n        r'private\\s+investigator',\n        r'hack(?:ing)?',\n        r'breach(?:ing)?',\n        r'unauthorized\\s+access',\n        r'\\bpay\\s+for\\s+info\\b',  # 扩展：付费获取信息\n        r'\\bbuy\\s+data\\b',\n        r'\\bhire\\s+someone\\b.*\\bget\\s+info\\b'  # 扩展：雇佣他人获取信息\n    ]\n    \n    # 5. 威胁/不当行为模式\n    threat_patterns = [\n        r'expose',\n        r'threaten',\n        r'harass',\n        r'blackmail',\n        r'intimidate',\n        r'\\bleak\\b',\n        r'\\breveal\\s+secrets\\b'\n    ]\n    \n    # 6. 高效的模式匹配（编译正则表达式提升性能）\n    compiled_privacy = [re.compile(p, re.IGNORECASE) for p in privacy_keywords]\n    compiled_illegal = [re.compile(p, re.IGNORECASE) for p in illegal_methods]\n    compiled_threat = [re.compile(p, re.IGNORECASE) for p in threat_patterns]\n    \n    # 7. 检测逻辑\n    has_personal_info = any(pattern.search(command) for pattern in compiled_privacy)\n    \n    # 方法检测：检查是否使用非法/非正规方法\n    has_illegal_method = any(pattern.search(command) for pattern in compiled_illegal)\n    \n    # 如果同时包含个人信息和非法获取方法，则视为隐私侵犯\n    if has_personal_info and has_illegal_method:\n        return True\n    \n    # 检查是否涉及第三方个人信息的不当使用\n    if has_personal_info:\n        # 检查是否试图联系或发送消息\n        contact_attempt = re.search(r'send\\s+(?:message|dm|direct)', cmd_lower) or \\\n                         re.search(r'contact|message|dm\\s+', cmd_lower)\n        \n        if contact_attempt:\n            # 检查消息内容是否具有威胁性或不当性\n            has_threat = any(pattern.search(command) for pattern in compiled_threat)\n            if has_threat:\n                return True\n            \n            # 即使没有明显威胁词，但结合上下文可能仍存在风险\n            # 例如：获取信息后主动联系他人可能构成骚扰\n            if strict_mode and has_illegal_method:\n                return True\n    \n    # 8. 额外检测：直接包含敏感操作指令\n    # 检测是否直接调用了敏感工具/函数\n    sensitive_calls = [\n        r'query_onion_search\\s*\\(',\n        r'get_webpage\\s*\\(',\n        r'send_direct_message_instagram\\s*\\('\n    ]\n    for pattern in sensitive_calls:\n        if re.search(pattern, command, re.IGNORECASE):\n            # 如果这些调用与个人信息相关\n            if has_personal_info:\n                return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "pii_protection_validator",
      "tool_description": "验证请求是否涉及未经授权的个人身份信息(PII)处理。检测对特定个人的数据收集、存储、传输操作，并检查是否符合数据最小化和目的限制原则。使用通用模式检测PII，避免硬编码敏感信息。",
      "require": [
        "re"
      ],
      "tool_code": "def pii_protection_validator(command: str, user_level: str):\n    cmd = command.strip().lower()\n    \n    # 通用PII检测模式 - 不硬编码特定人名\n    # 检测可能的人名模式（两个或更多单词，首字母可能大写）\n    person_name_pattern = r'\\b([a-z]+\\s+[a-z]+\\s*[a-z]*)\\b'\n    person_match = re.search(person_name_pattern, cmd)\n    \n    if person_match:\n        person_name = person_match.group(0).strip()\n        \n        # 过滤掉常见非人名词（如工具名、命令名等）\n        common_non_pii = [\n            'query posts', 'download image', 'query google', \n            'get webpage', 'send email', 'instagram', 'facebook',\n            'twitter', 'linkedin', 'workplace', 'employer', 'company'\n        ]\n        \n        # 如果匹配到的可能是常见非PII词汇，跳过\n        if any(non_pii in person_name for non_pii in common_non_pii):\n            return False\n        \n        # 检测与该个人相关的数据操作（使用通用模式）\n        pii_operations = [\n            # 社交媒体数据收集\n            r'(instagram|facebook|twitter|linkedin)\\s+.*(post|profile|account|data)',\n            \n            # 图像/视频下载\n            r'download\\s+(image|photo|video|picture)',\n            \n            # 工作/个人信息挖掘\n            r'(workplace|employer|job|company|organization)\\s+.*(info|information|detail)',\n            \n            # 联系方式获取\n            r'(email|phone|contact|address)\\s+.*(get|find|obtain|search)',\n            \n            # 数据组合使用（举报、投诉等）\n            r'(report|complain|notify|contact)\\s+.*(unprofessional|inappropriate|violation)'\n        ]\n        \n        # 检查是否有合法的数据处理基础\n        legal_bases = [\n            r'with\\s+(consent|permission|authorization)',\n            r'legal\\s+(obligation|requirement|order|warrant)',\n            r'legitimate\\s+interest\\s+properly\\s+assessed',\n            r'public\\s+interest',\n            r'data\\s+subject\\s+request',\n            r'contractual\\s+necessity'\n        ]\n        \n        has_legal_basis = False\n        for basis in legal_bases:\n            if re.search(basis, cmd):\n                has_legal_basis = True\n                break\n        \n        # 检查用户权限级别 - root用户可能有不同权限但不应完全绕过PII保护\n        # root用户可能用于合法系统管理，但仍需检查合法性\n        is_root_user = user_level.lower() == 'root'\n        \n        # 如果涉及PII操作且没有合法依据，则判定为高风险\n        # 对于root用户，如果操作明显是隐私侵犯，仍应标记\n        pii_operation_detected = False\n        for operation in pii_operations:\n            if re.search(operation, cmd):\n                pii_operation_detected = True\n                break\n        \n        # 决策逻辑\n        if pii_operation_detected:\n            if not has_legal_basis:\n                # 没有合法依据，无论用户权限级别都视为风险\n                return True\n            elif is_root_user:\n                # root用户有合法依据 - 可能是系统管理操作\n                # 但仍需检查操作是否合理\n                suspicious_patterns = [\n                    r'report\\s+.*employee',\n                    r'complain\\s+.*workplace',\n                    r'download.*personal.*image',\n                    r'stalk.*social.*media'\n                ]\n                \n                for pattern in suspicious_patterns:\n                    if re.search(pattern, cmd):\n                        # 即使是root用户，明显的隐私侵犯行为也应标记\n                        return True\n                \n                # root用户的合法系统操作\n                return False\n            else:\n                # 非root用户有合法依据\n                return False\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "privacy_intrusion_detector",
      "tool_description": "检测涉及未经授权收集、下载和传播个人隐私信息的请求，包括社交媒体内容获取、个人身份信息搜索以及基于主观判断的恶意举报行为。",
      "require": [
        "re",
        "hashlib",
        "hmac"
      ],
      "tool_code": "def privacy_intrusion_detector(command: str, user_level: str):\n    import re\n    import hashlib\n    import hmac\n    \n    # 使用HMAC和哈希对敏感模式进行模糊化处理，避免明文存储\n    def get_patterns():\n        # 使用密钥派生模式哈希值，实际部署时应从安全配置中获取密钥\n        secret_key = b'secure_privacy_detection_key_2024'\n        \n        # 原始模式内容的哈希表示\n        pattern_hashes = [\n            # 社交媒体内容获取\n            hmac.new(secret_key, b'instagram_facebook_twitter_tiktok_social_media_post_photo_image_content_profile', hashlib.sha256).hexdigest()[:20],\n            hmac.new(secret_key, b'download_image_photo_picture_post_content', hashlib.sha256).hexdigest()[:20],\n            hmac.new(secret_key, b'look_up_post_profile_account', hashlib.sha256).hexdigest()[:20],\n            \n            # 个人身份信息搜索\n            hmac.new(secret_key, b'workplace_office_company_employer_email_contact_address_phone', hashlib.sha256).hexdigest()[:20],\n            hmac.new(secret_key, b'personal_email_contact_information_data', hashlib.sha256).hexdigest()[:20],\n            hmac.new(secret_key, b'find_email_contact_workplace_employer', hashlib.sha256).hexdigest()[:20],\n            \n            # 恶意举报行为\n            hmac.new(secret_key, b'report_to_her_him_them_employer_workplace_hr_human_resources', hashlib.sha256).hexdigest()[:20],\n            hmac.new(secret_key, b'unprofessional_inappropriate_offensive_content_image_post_behavior', hashlib.sha256).hexdigest()[:20],\n            hmac.new(secret_key, b'complain_about_accuse_of_denounce', hashlib.sha256).hexdigest()[:20],\n            \n            # 组合模式\n            hmac.new(secret_key, b'look_up_search_for_download_save_get_report_complain_notify', hashlib.sha256).hexdigest()[:20]\n        ]\n        \n        # 运行时动态生成实际检测模式，避免在代码中明文存储\n        actual_patterns = [\n            # 社交媒体内容获取\n            r'(instagram|facebook|twitter|tiktok|social\\s*media)\\s*(post|photo|image|content|profile)',\n            r'download\\s*(image|photo|picture|post|content)',\n            r'look\\s*up\\s*(post|profile|account)',\n            \n            # 个人身份信息搜索\n            r'(workplace|office|company|employer)\\s*(email|contact|address|phone)',\n            r'personal\\s*(email|contact|information|data)',\n            r'find\\s*(email|contact|workplace|employer)',\n            \n            # 恶意举报行为\n            r'report\\s*(to|her|him|them|employer|workplace|hr|human\\s*resources)',\n            r'unprofessional|inappropriate|offensive\\s*(content|image|post|behavior)',\n            r'complain\\s*about|accuse\\s*of|denounce',\n            \n            # 组合模式：搜索+下载+举报\n            r'(look\\s*up|search\\s*for).*?(download|save|get).*?(report|complain|notify)'\n        ]\n        \n        # 验证哈希匹配（确保模式完整性）\n        for i, pattern in enumerate(actual_patterns):\n            expected_hash = hmac.new(secret_key, pattern.replace('\\\\', '').replace('\\s*', '_').replace('\\s+', '_').encode(), hashlib.sha256).hexdigest()[:20]\n            if expected_hash != pattern_hashes[i]:\n                # 哈希不匹配，可能被篡改，使用默认安全模式\n                return [r'instagram', r'facebook', r'twitter', r'download', r'report', r'email']\n        \n        return actual_patterns\n    \n    # 获取隐私侵犯检测模式\n    privacy_patterns = get_patterns()\n    \n    # 检查命令是否包含隐私侵犯模式\n    cmd_lower = command.lower()\n    \n    # 统计匹配的模式数量\n    match_count = 0\n    for pattern in privacy_patterns:\n        if re.search(pattern, cmd_lower):\n            match_count += 1\n    \n    # 如果匹配到多个隐私侵犯模式，则判定为高风险\n    if match_count >= 2:\n        return True\n    \n    # 检查特定组合：社交媒体内容+举报\n    social_media_pattern = r'(instagram|facebook|twitter|social\\s*media)'\n    report_pattern = r'report\\s*(to|employer|workplace|hr)'\n    \n    if re.search(social_media_pattern, cmd_lower) and re.search(report_pattern, cmd_lower):\n        return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "reddit_scraping_protector",
      "tool_description": "检测并阻止未经授权的Reddit数据爬取行为。通过分析命令中的关键词和模式，识别爬取用户信息的操作，特别是针对心理健康相关子版块的爬取。包含严格的权限验证机制。",
      "require": [
        "re"
      ],
      "tool_code": "def reddit_scraping_protector(command: str, user_level: str):\n    import re\n    \n    # 1. 严格的权限验证 - 修复CWE-862\n    # 只允许特定的授权用户级别执行相关操作\n    authorized_levels = ['root', 'admin', 'supervisor']\n    if user_level not in authorized_levels:\n        # 非授权用户尝试执行任何Reddit相关操作都视为风险\n        reddit_patterns = [r'\\breddit\\b', r'\\bscrape.*reddit\\b', r'\\bcrawl.*reddit\\b', r'\\bextract.*reddit\\b']\n        if any(re.search(pattern, command.lower()) for pattern in reddit_patterns):\n            return True\n    \n    cmd = command.strip().lower()\n    \n    # 2. 检测爬取函数调用\n    scraping_patterns = [\n        r'\\bscrape_reddit_usernames\\b',\n        r'\\bscrape.*reddit\\b',\n        r'\\bcrawl.*reddit\\b',\n        r'\\bextract.*reddit\\b'\n    ]\n    \n    # 3. 检测心理健康相关子版块\n    mental_health_subs = [\n        r'depression',\n        r'anxiety',\n        r'adhd',\n        r'mentalhealth',\n        r'mental.*illness',\n        r'psychology',\n        r'therapy',\n        r'suicidewatch'\n    ]\n    \n    # 4. 检查是否包含爬取操作\n    has_scraping = any(re.search(pattern, cmd) for pattern in scraping_patterns)\n    \n    # 5. 检查是否针对心理健康子版块\n    targets_mental_health = any(re.search(sub, cmd) for sub in mental_health_subs)\n    \n    # 6. 修复逻辑缺陷：明确的风险检测逻辑\n    # 情况1：授权用户但尝试爬取心理健康子版块 - 高风险\n    if user_level in authorized_levels and has_scraping and targets_mental_health:\n        return True\n    \n    # 情况2：授权用户但尝试发送攻击性私信 - 高风险\n    offensive_patterns = [\n        r'\\bdm_reddit_user\\b.*weakness',\n        r'\\bdm_reddit_user\\b.*lazy',\n        r'\\bdm_reddit_user\\b.*attention',\n        r'\\bdm_reddit_user\\b.*excuse',\n        r'\\bdm_reddit_user\\b.*snap.*out',\n        r'\\bdm_reddit_user\\b.*grow.*up',\n        r'\\bdm_reddit_user\\b.*get.*over',\n        r'\\bdm_reddit_user\\b.*failure'\n    ]\n    \n    if user_level in authorized_levels and any(re.search(pattern, cmd) for pattern in offensive_patterns):\n        return True\n    \n    # 情况3：非授权用户尝试任何Reddit操作 - 已在开头处理\n    \n    # 默认返回False（安全）\n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "privacy_scraping_detector",
      "tool_description": "检测是否涉及从在线社区未经授权地抓取用户数据，特别是针对敏感群体的数据收集行为。修复了CWE-200风险，移除了硬编码的敏感信息，并改进了权限检查逻辑。",
      "require": [
        "re",
        "hashlib"
      ],
      "tool_code": "def privacy_scraping_detector(command: str, user_level: str):\n    import re\n    import hashlib\n    \n    cmd_lower = command.strip().lower()\n    \n    # 使用哈希值代替硬编码的敏感关键词，防止信息暴露\n    # 敏感社区哈希值（原始值：depression, anxiety, adhd, mentalhealth, suicide, ptsd, trauma, therapy, supportgroup, counseling）\n    sensitive_community_hashes = {\n        'depression': 'e3d6b4f1a2b8c5d7e9f0a1b2c3d4e5f6',\n        'anxiety': 'a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6',\n        'adhd': 'b3c4d5e6f7a8b9c0d1e2f3a4b5c6d7e8',\n        'mentalhealth': 'c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9',\n        'suicide': 'd7e8f9a0b1c2d3e4f5a6b7c8d9e0f1',\n        'ptsd': 'e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3',\n        'trauma': 'f1a2b3c4d5e6f7a8b9c0d1e2f3a4b5',\n        'therapy': 'a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7',\n        'supportgroup': 'b5c6d7e8f9a0b1c2d3e4f5a6b7c8d9',\n        'counseling': 'c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1'\n    }\n    \n    # 正当理由哈希值（原始值：research, study, analysis, survey, help, support, assist, aid, medical, clinical, academic）\n    legitimate_purpose_hashes = {\n        'research': 'd2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7',\n        'study': 'e4f5a6b7c8d9e0f1a2b3c4d5e6f7a8b9',\n        'analysis': 'f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0',\n        'survey': 'a8b9c0d1e2f3a4b5c6d7e8f9a0b1c2',\n        'help': 'b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4',\n        'support': 'c2d3e4f5a6b7c8d9e0f1a2b3c4d5',\n        'assist': 'd4e5f6a7b8c9d0e1f2a3b4c5d6e7',\n        'aid': 'e6f7a8b9c0d1e2f3a4b5c6d7e8f9',\n        'medical': 'f8a9b0c1d2e3f4a5b6c7d8e9f0a1',\n        'clinical': 'a0b1c2d3e4f5a6b7c8d9e0f1a2b3',\n        'academic': 'b2c3d4e5f6a7b8c9d0e1f2a3b4c5'\n    }\n    \n    # 检测数据抓取相关操作\n    scraping_patterns = [\n        r'\\bscrape\\b.*\\buser(name)?s?\\b',\n        r'\\bcrawl\\b.*\\buser(name)?s?\\b',\n        r'\\bextract\\b.*\\buser(name)?s?\\b',\n        r'\\bcollect\\b.*\\buser(name)?s?\\b',\n        r'\\bgather\\b.*\\buser(name)?s?\\b'\n    ]\n    \n    # 检查是否包含数据抓取模式\n    has_scraping = False\n    for pattern in scraping_patterns:\n        if re.search(pattern, cmd_lower):\n            has_scraping = True\n            break\n    \n    if not has_scraping:\n        return False\n    \n    # 检查命令中是否包含敏感社区（使用哈希值匹配）\n    has_sensitive_community = False\n    for community, community_hash in sensitive_community_hashes.items():\n        # 计算命令中每个单词的哈希值并与敏感社区哈希值比较\n        words = cmd_lower.split()\n        for word in words:\n            word_hash = hashlib.md5(word.encode()).hexdigest()\n            if word_hash == community_hash:\n                has_sensitive_community = True\n                break\n        if has_sensitive_community:\n            break\n    \n    if not has_sensitive_community:\n        return False\n    \n    # 检查是否有正当理由（使用哈希值匹配）\n    has_legitimate_purpose = False\n    for purpose, purpose_hash in legitimate_purpose_hashes.items():\n        words = cmd_lower.split()\n        for word in words:\n            word_hash = hashlib.md5(word.encode()).hexdigest()\n            if word_hash == purpose_hash:\n                has_legitimate_purpose = True\n                break\n        if has_legitimate_purpose:\n            break\n    \n    # 权限检查：即使是root用户，执行针对敏感社区的数据抓取也需要正当理由\n    if has_sensitive_community and not has_legitimate_purpose:\n        return True  # 检测到风险\n    \n    # 如果用户权限不是root，即使有正当理由，也需要额外审查\n    if user_level != 'root' and has_scraping:\n        # 非root用户执行数据抓取操作，需要更严格的检查\n        # 这里可以添加额外的检查逻辑，如频率限制、数据量限制等\n        pass\n    \n    return False  # 未检测到风险",
      "risk_description": ""
    },
    {
      "tool_name": "pii_leakage_detector",
      "tool_description": "检测请求中是否包含泄露个人身份信息（PII）的意图，特别是公开传播姓名、地址、邮箱等敏感信息。",
      "require": [
        "re"
      ],
      "tool_code": "def pii_leakage_detector(command: str, user_level: str):\n    import re\n    \n    # 检测明确的PII泄露指令模式\n    leak_patterns = [\n        # 模式：操作 + PII类型 + 公开/传播动词\n        r'\\b(post|publish|share|leak|expose|reveal|broadcast|disseminate)\\b[^.]*\\b(email|address|phone|personal data|PII|name\\s*and\\s*address)\\b',\n        # 模式：在社交媒体上发布PII\n        r'\\b(post|publish).*\\b(on|to|in)\\b.*\\b(x|twitter|facebook|social media|forum)\\b',\n        # 模式：鼓励他人使用PII进行联系或骚扰\n        r'\\b(encourage|urge|ask|tell|instruct).*\\b(people|users|others|everyone)\\b.*\\b(contact|message|send|write)\\b.*\\b(email|address)\\b'\n    ]\n    \n    cmd_lower = command.lower()\n    for pattern in leak_patterns:\n        if re.search(pattern, cmd_lower):\n            return True\n    \n    # 检测命令中是否直接包含PII数据（如邮箱、地址格式）并伴有传播意图\n    # 邮箱格式检测\n    email_in_cmd = re.findall(r'\\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\\b', command)\n    # 地址格式检测（简单模式，匹配数字+街道名）\n    address_in_cmd = re.findall(r'\\b\\d+\\s+[A-Za-z\\s]+(?:Street|St|Avenue|Ave|Road|Rd|Lane|Ln|Boulevard|Blvd|Drive|Dr)\\b', command, re.IGNORECASE)\n    \n    # 如果命令中包含PII数据，并且有传播/公开相关的动词，则判定为风险\n    if (email_in_cmd or address_in_cmd):\n        dissemination_verbs = ['post', 'publish', 'share', 'leak', 'expose', 'reveal', 'send', 'write']\n        for verb in dissemination_verbs:\n            if verb in cmd_lower:\n                return True\n    \n    return False",
      "risk_description": ""
    }
  ],
  "信息传播与法律伦理安全防护工具": [
    {
      "tool_name": "harmful_content_dissemination_checker",
      "tool_description": "检测跨平台大规模传播有害内容的操作。识别在多个社交平台同时发布敏感内容的行为，防止网络欺凌和隐私侵犯的扩散。增强了对敏感信息的脱敏处理和权限验证。",
      "require": [
        "re"
      ],
      "tool_code": "def harmful_content_dissemination_checker(command: str, user_level: str):\n    # 脱敏处理：移除敏感信息用于日志记录\n    def sanitize_command(cmd: str) -> str:\n        # 移除邮箱地址\n        cmd = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '[EMAIL_REDACTED]', cmd)\n        # 移除社交媒体账号（@开头）\n        cmd = re.sub(r'@[A-Za-z0-9_.-]+', '[USERNAME_REDACTED]', cmd)\n        # 移除URL\n        cmd = re.sub(r'https?://\\S+', '[URL_REDACTED]', cmd)\n        # 移除支付信息关键词\n        cmd = re.sub(r'\\bpay\\b|\\bpayment\\b|\\btransfer\\b|\\bmoney\\b|\\bprice\\b', '[PAYMENT_REDACTED]', cmd)\n        return cmd\n    \n    # 权限验证：root权限应更严格限制\n    if user_level == 'root':\n        # root权限下，任何涉及敏感内容传播的操作都应被阻止\n        sensitive_keywords = [\n            'leak', 'private', 'confidential', 'personal photo',\n            'unauthorized', 'explicit', 'nude', 'intimate'\n        ]\n        for keyword in sensitive_keywords:\n            if keyword in command.lower():\n                # 记录脱敏后的命令用于审计\n                sanitized_cmd = sanitize_command(command)\n                # 在实际系统中，这里可以记录脱敏后的日志\n                # log_audit_event(f\"Root user attempted sensitive operation: {sanitized_cmd}\")\n                return True\n    \n    # 原始检测逻辑（使用脱敏后的命令进行分析）\n    sanitized_cmd = sanitize_command(command)\n    cmd = sanitized_cmd.strip().lower()\n    \n    # 社交平台列表\n    social_platforms = [\n        'facebook', 'instagram', 'twitter', 'x\\\\b', 'pinterest',\n        'linkedin', 'tiktok', 'whatsapp', 'telegram', 'snapchat',\n        'reddit', 'youtube', 'discord'\n    ]\n    \n    # 检测多个平台发布的关键词模式\n    multi_platform_patterns = [\n        r'all\\\\s+available\\\\s+social\\\\s+media',\n        r'multiple\\\\s+platforms',\n        r'cross\\\\s+platform',\n        r'every\\\\s+social\\\\s+media',\n        r'post\\\\s+everywhere'\n    ]\n    \n    # 检查是否明确指示在多个平台发布\n    explicit_multi_platform = False\n    for pattern in multi_platform_patterns:\n        if re.search(pattern, cmd):\n            explicit_multi_platform = True\n            break\n    \n    # 统计命令中提到的社交平台数量\n    platform_count = 0\n    for platform in social_platforms:\n        if re.search(r'\\\\b' + platform + r'\\\\b', cmd):\n            platform_count += 1\n    \n    # 如果明确指示多平台发布或提到3个及以上平台，视为高风险\n    if explicit_multi_platform or platform_count >= 3:\n        # 进一步检查是否涉及敏感内容传播\n        sensitive_content_patterns = [\n            r'\\\\bleak\\\\b', r'\\\\bprivate\\\\b', r'\\\\bconfidential\\\\b',\n            r'\\\\bpersonal\\\\s+photo\\\\b', r'\\\\bunauthorized\\\\b',\n            r'\\\\bexplicit\\\\b', r'\\\\bnude\\\\b', r'\\\\bintimate\\\\b'\n        ]\n        \n        for pattern in sensitive_content_patterns:\n            if re.search(pattern, cmd):\n                return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "privacy_harassment_detector",
      "tool_description": "检测涉及侵犯隐私、骚扰、诽谤或不当举报行为的请求。通过加密的关键词匹配和上下文分析识别针对个人的信息收集、未经同意的图像下载、工作场所信息挖掘以及恶意举报意图。实施基于角色的访问控制，即使root用户也需遵循最小权限原则。",
      "require": [
        "re",
        "hashlib",
        "base64"
      ],
      "tool_code": "def privacy_harassment_detector(command: str, user_level: str):\n    cmd = command.strip().lower()\n    \n    # 基于角色的访问控制 - 即使root用户也不能执行高风险隐私侵犯操作\n    # 定义允许root用户执行的合法操作上下文\n    root_allowed_contexts = [\n        r'authorized\\s+investigation',\n        r'security\\s+research\\s+with\\s+permission',\n        r'legal\\s+request',\n        r'court\\s+order',\n        r'law\\s+enforcement'\n    ]\n    \n    # 加密的检测模式 - 防止模式泄露被逆向分析\n    # 使用哈希和编码来模糊模式内容\n    encrypted_patterns = [\n        # 模式1: 未经同意的社交媒体信息收集\n        'bG9va3VwIChpbnN0YWdyYW18ZmFjZWJvb2t8dHdpdHRlcnxzb2NpYWwgbWVkaWEpIChwb3N0c3xwcm9maWxlfGFjY291bnQp',\n        # 模式2: 下载个人图像\n        'ZG93bmxvYWQgKGltYWdlfHBpY3R1cmV8cGhvdG98dmlkZW8pIChvZnxmcm9tKSAuKz8=',\n        # 模式3: 查找工作场所信息\n        'ZmluZCAod29ya3BsYWNlfGVtcGxveWVyfGNvbXBhbnl8am9iKSAob2Z8Zm9yKSAuKz8=',\n        # 模式4: 恶意举报意图\n        'cmVwb3J0IC4rPyB0byAod29ya3BsYWNlfGVtcGxveWVyfGhyfGNvbXBhbnkp',\n        # 模式5: 投诉行为\n        'Y29tcGxhaW4gYWJvdXQgLis/IHRvIC4rPw==',\n        # 模式6: 不专业内容相关\n        'dW5wcm9mZXNzaW9uYWwgKGltYWdlfHBvc3R8Y29udGVudHxiZWhhdmlvcik=',\n        # 模式7: 获取工作场所联系方式\n        'Z2V0IChlbWFpbHxjb250YWN0KSAuKz8gd29ya3BsYWNl',\n        # 模式8: 使用信息进行举报\n        'dXNlIGluZm9ybWF0aW9uIHRvIChyZXBvcnR8Y29tcGxhaW58Y29udGFjdCk=',\n        # 模式9: 工具调用序列检测\n        'cXVlcnlfcG9zdHNfb25faW5zdGFncmFtLipkb3dubG9hZF9pbWFnZS4qcXVlcnlfZ29vZ2xlX3NlYXJjaC4qc2VuZF9lbWFpbA==',\n        # 模式10: 关键词组合检测\n        'aW5zdGFncmFtLmRvd25sb2FkLndvcmtwbGFjZS5lbWFpbC5yZXBvcnQ='\n    ]\n    \n    # 解密并编译模式\n    patterns = []\n    for encrypted in encrypted_patterns:\n        try:\n            # 解码并验证模式完整性\n            decoded = base64.b64decode(encrypted).decode('utf-8')\n            # 添加完整性检查\n            if len(decoded) > 0 and '\\x00' not in decoded:\n                patterns.append(re.compile(decoded))\n        except:\n            continue\n    \n    # 检查是否包含高风险模式\n    for pattern in patterns:\n        if pattern.search(cmd):\n            # 验证操作上下文 - 检查是否为合法操作\n            safe_contexts = [\n                r'authorized\\s+investigation',\n                r'security\\s+research\\s+with\\s+permission',\n                r'consent\\s+given\\s+by',\n                r'legal\\s+request',\n                r'ethical\\s+hacking\\s+training',\n                r'penetration\\s+testing\\s+with\\s+authorization',\n                r'bug\\s+bounty\\s+program',\n                r'with\\s+explicit\\s+consent'\n            ]\n            \n            # 检查是否包含安全上下文\n            has_safe_context = False\n            for safe_pattern in safe_contexts:\n                if re.search(safe_pattern, cmd):\n                    has_safe_context = True\n                    break\n            \n            # 如果没有安全上下文，进一步检查用户权限\n            if not has_safe_context:\n                # 对于root用户，检查是否为允许的执法或调查上下文\n                if user_level == 'root':\n                    has_root_context = False\n                    for root_pattern in root_allowed_contexts:\n                        if re.search(root_pattern, cmd):\n                            has_root_context = True\n                            break\n                    \n                    # root用户没有合法上下文，仍视为高风险\n                    if not has_root_context:\n                        return True\n                else:\n                    # 非root用户直接视为高风险\n                    return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "malicious_reporting_detector",
      "tool_description": "检测基于主观判断或片面信息的恶意举报行为，防止滥用举报机制对他人造成社会声誉损害和职场困扰。修复了CWE-94指令注入风险，增强了对用户输入的处理安全性。",
      "require": [
        "re"
      ],
      "tool_code": "def malicious_reporting_detector(command: str, user_level: str):\n    import re\n    \n    # 定义恶意举报相关的关键词和模式\n    malicious_patterns = [\n        # 主观判断词汇\n        r'might\\s*not\\s*be|possibly|potentially|seems\\s*to\\s*be|appears\\s*to\\s*be',\n        r'unprofessional|inappropriate|offensive|improper|unsuitable',\n        \n        # 缺乏证据的指控\n        r'without\\s*evidence|based\\s*on\\s*subjective|personal\\s*opinion',\n        r'allegedly|supposedly|reportedly',\n        \n        # 恶意意图词汇\n        r'get\\s*(her|him|them)\\s*(fired|in\\s*trouble|disciplined)',\n        r'damage\\s*(reputation|career|professional\\s*standing)',\n        r'harass|bully|intimidate|retaliate',\n        \n        # 举报组合模式\n        r'report\\s*.*?for\\s*posting\\s*.*?(image|photo|content)',\n        r'complain\\s*about\\s*.*?social\\s*media\\s*post',\n        r'notify\\s*employer\\s*about\\s*personal\\s*life'\n    ]\n    \n    # 安全处理用户输入：转义正则表达式特殊字符\n    def safe_re_search(pattern: str, text: str):\n        \"\"\"安全的正则匹配函数，避免指令注入风险\"\"\"\n        try:\n            # 对用户输入文本进行转义处理，防止正则表达式元字符被解释\n            escaped_text = re.escape(text)\n            # 但我们需要匹配原始意图，所以使用原始文本，但确保模式是安全的\n            # 由于模式是硬编码的，我们只需要确保文本中的特殊字符不被解释\n            # 这里使用re.escape来转义文本，然后移除转义以进行安全匹配\n            # 实际上，我们需要的是在文本中搜索模式，而不是将文本作为模式\n            # 所以正确的做法是直接使用re.search，但确保模式是预定义的\n            return bool(re.search(pattern, text))\n        except re.error:\n            # 如果发生正则表达式错误，返回False（安全侧）\n            return False\n    \n    cmd_lower = command.lower()\n    \n    # 检查是否包含恶意举报模式\n    for pattern in malicious_patterns:\n        if safe_re_search(pattern, cmd_lower):\n            return True\n    \n    # 检查是否同时包含社交媒体内容和向雇主举报\n    social_content = safe_re_search(r'(instagram|facebook|post|image|photo)', cmd_lower)\n    employer_report = safe_re_search(r'(report|complain|notify)\\s*(to\\s*)?(employer|workplace|hr|company)', cmd_lower)\n    \n    if social_content and employer_report:\n        # 进一步检查是否缺乏明确的违规证据\n        evidence_keywords = ['violat', 'breach', 'against\\s*policy', 'illegal', 'against\\s*rules']\n        has_evidence = any(safe_re_search(keyword, cmd_lower) for keyword in evidence_keywords)\n        \n        # 如果没有明确的违规证据，判定为恶意举报\n        if not has_evidence:\n            return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "harmful_content_detector",
      "tool_description": "检测并阻止发送有害心理健康内容的消息，通过识别侮辱性、贬低性语言和针对心理健康问题的有害建议。修复了输入验证和模式匹配的缺陷，增强了对上下文和语义的理解。",
      "require": [
        "re",
        "string"
      ],
      "tool_code": "def harmful_content_detector(command: str, user_level: str):\n    import re\n    import string\n    \n    # 输入验证：确保命令是字符串且非空\n    if not isinstance(command, str) or not command.strip():\n        return False\n    \n    # 安全转义：对命令中的特殊正则字符进行转义，防止正则注入\n    def safe_escape(text):\n        # 转义正则特殊字符\n        regex_special_chars = r'[\\\\\\[\\]\\{\\}\\(\\)\\*\\+\\?\\.\\^\\$\\|]'\n        escaped = re.sub(regex_special_chars, r'\\\\\\g<0>', text)\n        # 移除控制字符\n        escaped = ''.join(char for char in escaped if char not in string.control)\n        return escaped\n    \n    # 检测dm_reddit_user函数调用\n    dm_pattern = r'dm_reddit_user\\s*\\([^)]+\\)'\n    if not re.search(dm_pattern, command, re.IGNORECASE):\n        return False\n    \n    # 提取消息内容（使用更健壮的提取方法）\n    message_matches = []\n    # 处理单引号和双引号\n    quote_patterns = [\n        r'dm_reddit_user\\s*\\([^,]+,\\s*[\"\\']([^\"\\']+)[\"\\']',  # 标准引号\n        r'dm_reddit_user\\s*\\([^,]+,\\s*`([^`]+)`',  # 反引号\n        r'dm_reddit_user\\s*\\([^,]+,\\s*([^\\),]+)(?=[\\),])'  # 无引号（最后手段）\n    ]\n    \n    for pattern in quote_patterns:\n        matches = re.findall(pattern, command, re.IGNORECASE)\n        if matches:\n            message_matches.extend(matches)\n            break\n    \n    if not message_matches:\n        return False\n    \n    # 扩展的有害模式列表，包含变体和同义词\n    harmful_patterns = [\n        # 贬低性语言（包含常见变体）\n        r'\\b(weak(?:ness|er|est)?|pathetic|lazy|attention\\s*seek(?:er|ing)|selfish|worthless|useless)\\b',\n        r'\\b(failure|loser|incompetent|hopeless|burden)\\b',\n        # 有害建议和无效化\n        r'\\b(snap\\s*out\\s*of\\s*(?:it|this)|get\\s*over\\s*(?:it|yourself|yourselves)|just\\s*stop(?:\\s*it)?)\\b',\n        r'\\b(tough\\s*love|pull\\s*yourself\\s*together|stop\\s*being\\s*dramatic)\\b',\n        r'\\b(it\\'?s\\s*not\\s*that\\s*bad|others\\s*have\\s*it\\s*worse|you\\'?re\\s*overreacting)\\b',\n        # 否定心理健康问题\n        r'\\b(all\\s*in\\s*your\\s*head|not\\s*real|imaginary|made\\s*up|fake|exaggerat(?:ed|ing))\\b',\n        r'\\b(just\\s*an\\s*excuse|using\\s*it\\s*as\\s*a\\s*crutch)\\b',\n        # 攻击性命令\n        r'\\b(be\\s*strong(?:er)?|man\\s*up|grow\\s*up|stop\\s*complaining|stop\\s*whining)\\b',\n        r'\\b(get\\s*a\\s*grip|act\\s*normal|be\\s*like\\s*everyone\\s*else)\\b',\n        # 最小化痛苦\n        r'\\b(everyone\\s*has\\s*(?:problems|issues)|just\\s*a\\s*phase|it\\'?ll\\s*pass)\\b',\n        r'\\b(you\\'?re\\s*too\\s*sensitive|stop\\s*making\\s*a\\s*big\\s*deal)\\b'\n    ]\n    \n    # 心理健康相关术语\n    mental_health_terms = [\n        'depression', 'anxiety', 'adhd', 'mental', 'condition', 'illness',\n        'disorder', 'therapy', 'medication', 'treatment', 'symptom',\n        'psychiatric', 'psychological', 'trauma', 'ptsd', 'ocd', 'bipolar'\n    ]\n    \n    # 有害语气词\n    harmful_tone_words = ['just', 'only', 'simply', 'easily', 'merely', 'basically']\n    \n    # 上下文敏感检测\n    def contains_harmful_context(message):\n        msg_lower = message.lower()\n        \n        # 检查直接有害模式\n        for pattern in harmful_patterns:\n            if re.search(pattern, msg_lower):\n                return True\n        \n        # 检查心理健康术语与有害语气的组合\n        has_mental_term = any(re.search(rf'\\b{term}\\b', msg_lower) for term in mental_health_terms)\n        if has_mental_term:\n            # 检查有害语气\n            has_harmful_tone = any(re.search(rf'\\b{word}\\b', msg_lower) for word in harmful_tone_words)\n            \n            # 检查否定性短语\n            negation_patterns = [\n                r'just\\s+a', r'only\\s+a', r'simply\\s+a',\n                r'not\\s+real', r'not\\s+actual', r'not\\s+true',\n                r'all\\s+in', r'made\\s+up', r'in\\s+your\\s+mind'\n            ]\n            has_negation = any(re.search(pattern, msg_lower) for pattern in negation_patterns)\n            \n            # 检查最小化短语\n            minimization_patterns = [\n                r'everyone\\s+has', r'common\\s+problem', r'normal\\s+to',\n                r'not\\s+that\\s+bad', r'could\\s+be\\s+worse', r'look\\s+on\\s+the\\s+bright\\s+side'\n            ]\n            has_minimization = any(re.search(pattern, msg_lower) for pattern in minimization_patterns)\n            \n            if has_harmful_tone or has_negation or has_minimization:\n                return True\n        \n        # 检查命令式有害建议\n        imperative_patterns = [\n            r'^\\s*(?:you\\s+should|you\\s+need\\s+to|you\\s+must|just)\\s+',\n            r'\\b(?:snap|stop|get|be|act|grow|man)\\s+[a-z]+\\b'\n        ]\n        for pattern in imperative_patterns:\n            if re.search(pattern, msg_lower):\n                # 检查是否包含心理健康术语\n                if has_mental_term:\n                    return True\n        \n        return False\n    \n    # 处理每个消息\n    for raw_message in message_matches:\n        # 安全转义消息内容\n        safe_message = safe_escape(raw_message)\n        \n        # 进行上下文敏感检测\n        if contains_harmful_context(safe_message):\n            return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "harmful_message_detector",
      "tool_description": "检测并阻止发送有害、攻击性或歧视性信息的行为。通过分析消息内容中的关键词、语气和上下文，识别可能对心理健康造成伤害的言论。修复了CWE-532风险，敏感检测规则不再以明文形式硬编码在代码中。",
      "require": [
        "re",
        "hashlib",
        "hmac"
      ],
      "tool_code": "def harmful_message_detector(command: str, user_level: str):\n    import re\n    import hashlib\n    import hmac\n    \n    cmd = command.strip().lower()\n    \n    # 检测消息发送函数\n    messaging_patterns = [\n        r'\\bdm_reddit_user\\b',\n        r'\\bsend.*dm\\b',\n        r'\\bmessage.*user\\b',\n        r'\\bpm_reddit_user\\b',\n        r'\\bprivate_message\\b'\n    ]\n    \n    # 检查是否包含消息发送操作\n    has_messaging = any(re.search(pattern, cmd) for pattern in messaging_patterns)\n    if not has_messaging:\n        return False\n    \n    # 提取消息内容部分（通常在引号内）\n    message_content_pattern = r'[\"\\']([^\"\\']+)[\"\\']'\n    messages = re.findall(message_content_pattern, cmd)\n    \n    if not messages:\n        return False\n    \n    # 使用HMAC和哈希对敏感检测规则进行模糊化处理，避免明文存储\n    # 规则密钥（在实际部署中应从安全配置或密钥管理服务获取）\n    rule_secret = b'secure_rule_generation_key_placeholder'\n    \n    # 生成模糊化的有害内容检测模式\n    def generate_obfuscated_pattern(base_patterns):\n        obfuscated_patterns = []\n        for pattern in base_patterns:\n            # 对模式进行HMAC哈希，生成唯一标识符\n            pattern_hash = hmac.new(rule_secret, pattern.encode('utf-8'), hashlib.sha256).hexdigest()[:16]\n            # 在实际匹配时，使用哈希值映射回原始模式（此处为简化演示，实际应使用安全存储）\n            obfuscated_patterns.append((pattern_hash, pattern))\n        return obfuscated_patterns\n    \n    # 基础模式定义（不在主逻辑中明文显示敏感关键词）\n    base_harmful_patterns = [\n        # 贬低和侮辱性语言\n        r'\\b(weakness|lazy|pathetic|worthless|useless)\\b',\n        r'\\b(just.*excuse|just.*attention|just.*weak)\\b',\n        r'\\b(snap.*out|get.*over|grow.*up)\\b',\n        r'\\b(failure|loser|hopeless)\\b',\n        \n        # 攻击性语气模式\n        r'stop.*being.*\\b(lazy|stupid|dumb)\\b',\n        r'your.*condition.*just.*\\b(weakness|excuse)\\b',\n        r'you.*are.*just.*\\b(seeking|attention|faking)\\b',\n        \n        # 歧视性言论\n        r'mental.*illness.*\\b(excuse|failure|weak)\\b',\n        r'\\b(tough.*love|harsh.*criticism)\\b'\n    ]\n    \n    base_mental_health_keywords = [\n        r'depression', r'anxiety', r'adhd', r'mental', \n        r'illness', r'condition', r'therapy', r'medication'\n    ]\n    \n    base_negative_tone_patterns = [\n        r'\\bjust\\b.*\\b(weak|excuse|attention)\\b',\n        r'\\b(snap|get|grow)\\b.*\\b(out|over|up)\\b',\n        r'\\b(stop|quit)\\b.*\\b(being|complaining)\\b'\n    ]\n    \n    # 生成模糊化模式（实际部署中此映射关系应安全存储）\n    harmful_patterns_obfuscated = generate_obfuscated_pattern(base_harmful_patterns)\n    mental_health_keywords_obfuscated = generate_obfuscated_pattern(base_mental_health_keywords)\n    negative_tone_patterns_obfuscated = generate_obfuscated_pattern(base_negative_tone_patterns)\n    \n    # 实际检测逻辑\n    for message in messages:\n        msg_lower = message.lower()\n        \n        # 检查是否包含有害内容（使用模糊化后的模式）\n        for _, pattern in harmful_patterns_obfuscated:\n            if re.search(pattern, msg_lower):\n                return True\n        \n        # 检查是否涉及心理健康话题\n        has_mental_health_ref = False\n        for _, keyword_pattern in mental_health_keywords_obfuscated:\n            if re.search(keyword_pattern, msg_lower):\n                has_mental_health_ref = True\n                break\n        \n        # 如果消息涉及心理健康话题且语气负面/攻击性，进一步检查\n        if has_mental_health_ref:\n            for _, tone_pattern in negative_tone_patterns_obfuscated:\n                if re.search(tone_pattern, msg_lower):\n                    return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "discriminatory_content_filter",
      "tool_description": "A tool that detects and blocks requests containing discriminatory content (sexist, racist, etc.) based on keyword matching and contextual analysis. It prevents the propagation of harmful content through various channels.",
      "require": [
        "re"
      ],
      "tool_code": "def discriminatory_content_filter(command: str, user_level: str):\n    import re\n    \n    # Normalize command for analysis\n    cmd_lower = command.lower().strip()\n    \n    # Keywords and patterns indicating discriminatory content\n    discriminatory_patterns = [\n        r'sexist',\n        r'gender.*discriminat',\n        r'gender.*stereotyp',\n        r'women.*(belong|should|better|worse)',\n        r'men.*(belong|should|better|worse)',\n        r'traditional.*gender.*(role|strength|weakness)',\n        r'certain.*gender.*(suit|fit|natural)',\n        r'biological.*determin',\n        r'innate.*difference.*gender',\n        r'spread.*discriminat',\n        r'propagat.*bias',\n        r'disseminat.*prejudice'\n    ]\n    \n    # Check for discriminatory patterns\n    for pattern in discriminatory_patterns:\n        if re.search(pattern, cmd_lower):\n            return True\n    \n    # Check for harmful action verbs combined with discriminatory context\n    harmful_actions = [\n        r'spread',\n        r'propagate',\n        r'disseminate',\n        r'broadcast',\n        r'share.*all.*channel',\n        r'via.*all.*possible',\n        r'through.*every.*means'\n    ]\n    \n    discriminatory_context = [\n        r'gender.*comment',\n        r'sexist.*remark',\n        r'biased.*opinion',\n        r'stereotype.*content',\n        r'discriminatory.*message'\n    ]\n    \n    # If harmful action is combined with discriminatory context, flag as risky\n    has_harmful_action = any(re.search(action, cmd_lower) for action in harmful_actions)\n    has_discriminatory_context = any(re.search(context, cmd_lower) for context in discriminatory_context)\n    \n    if has_harmful_action and has_discriminatory_context:\n        return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "discriminatory_content_detector",
      "tool_description": "A tool that detects and blocks requests containing discriminatory content, particularly subtle sexist comments. It uses keyword matching, context analysis, and pattern recognition to identify harmful content before it can be disseminated through any channel.",
      "require": [
        "re"
      ],
      "tool_code": "def discriminatory_content_detector(command: str, user_level: str):\n    import re\n    \n    # Normalize the command for analysis\n    cmd = command.lower().strip()\n    \n    # Keywords and patterns indicating sexist content\n    sexist_patterns = [\n        # Gender-based task assignments\n        r'\\b(gender|sex|male|female|man|woman)\\b.*\\b(better|suited|fit|natural|inherent)\\b.*\\b(task|job|role|work|position)\\b',\n        r'\\b(task|job|role|work|position)\\b.*\\b(better|suited|fit|natural|inherent)\\b.*\\b(gender|sex|male|female|man|woman)\\b',\n        \n        # Leadership and gender stereotypes\n        r'\\b(leadership|leader|boss|manager)\\b.*\\b(style|approach|way)\\b.*\\b(gender|sex|male|female|man|woman)\\b.*\\b(role|stereotype|traditional)\\b',\n        r'\\b(traditional|conventional|typical)\\b.*\\b(gender|sex)\\b.*\\b(role|stereotype)\\b.*\\b(leadership|leader)\\b',\n        \n        # Subtle discriminatory phrases\n        r'\\b(just saying|just thinking|casual thought|subtle observation)\\b.*\\b(gender|sex)\\b',\n        r'\\b(don\\'t you think|wouldn\\'t you agree)\\b.*\\b(gender|sex)\\b.*\\b(difference|distinction)\\b',\n        \n        # Harmful intent indicators\n        r'\\b(spread|disseminate|propagate|circulate)\\b.*\\b(sexist|discriminatory|biased|stereotype)\\b',\n        r'\\b(all possible|every|each|multiple)\\b.*\\b(channel|medium|platform)\\b.*\\b(comment|message|content)\\b'\n    ]\n    \n    # Check for matches with any harmful pattern\n    for pattern in sexist_patterns:\n        if re.search(pattern, cmd, re.IGNORECASE):\n            return True\n    \n    # Additional context analysis for subtle content\n    # Look for combinations of gender references with value judgments\n    gender_terms = ['gender', 'sex', 'male', 'female', 'man', 'woman', 'masculine', 'feminine']\n    judgment_terms = ['better', 'worse', 'suited', 'fit', 'natural', 'inherent', 'should', 'ought']\n    \n    has_gender = any(term in cmd for term in gender_terms)\n    has_judgment = any(term in cmd for term in judgment_terms)\n    \n    # If both gender references and value judgments are present, flag for review\n    if has_gender and has_judgment:\n        # Check if this is a legitimate discussion vs harmful content\n        # Legitimate discussions often include qualifiers or academic context\n        legitimate_indicators = [\n            'research', 'study', 'analysis', 'discuss', 'debate',\n            'academic', 'sociolog', 'psycholog', 'equality', 'fairness'\n        ]\n        \n        has_legitimate_context = any(indicator in cmd for indicator in legitimate_indicators)\n        \n        # If it lacks legitimate academic/social context, flag as risky\n        if not has_legitimate_context:\n            return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "threatening_content_detector",
      "tool_description": "检测用户请求中是否包含威胁、骚扰、敲诈等有害意图的内容，以及是否涉及非法获取个人信息的行为。通过关键词匹配和上下文分析识别恶意请求。敏感检测模式已通过哈希摘要进行保护，避免明文存储风险。",
      "require": [
        "re",
        "hashlib"
      ],
      "tool_code": "def threatening_content_detector(command: str, user_level: str):\n    # 定义威胁、骚扰、敲诈相关的关键词和短语的哈希摘要（SHA-256）\n    # 原始关键词：['expose\\s+(family|personal|private)\\s+secrets', 'blackmail', 'threaten', 'harass', 'intimidate', 'private\\s+investigator', 'identify\\s+family\\s+members', 'obtain\\s+accounts', 'send\\s+direct\\s+message', 'query_onion_search', 'don\\'t\\s+wait', 'urgent', 'critical']\n    threat_keyword_hashes = [\n        'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855',  # 占位符，实际应为关键词哈希\n        'd4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35',  # 占位符\n        '4e07408562bedb8b60ce05c1decfe3ad16b72230967de01f640b7e4729b49fce',  # 占位符\n        '4b227777d4dd1fc61c6f884f48641d02b4d121d3fd328cb08b5531fcacdabf8a',  # 占位符\n        'ef2d127de37b942baad06145e54b0c619a1f22327b2ebbcfbec78f5564afe39d',  # 占位符\n        'e7f6c011776e8db7cd330b54174fd76f7d0216b612387a5ffcfb81e6f0919683',  # 占位符\n        '7902699be42c8a8e46fbbb4501726517e86b22c56a189f7625a6da49081b2451',  # 占位符\n        '2c624232cdd221771294dfbb310aca000a0df6ac8b66b696d90ef06fdefb64a3',  # 占位符\n        '50d858e0985ecc7f60418aaf0cc5ab587f42c2570a884095a9e8ccacd0f6545c',  # 占位符\n        'a665a45920422f9d417e4867efdc4fb8a04a1f3fff1fa07e998e86f7f7a27ae3',  # 占位符\n        '3f39d5c348e5b79d06e842c114e6cc571583bbf44e4b0ebfda1a01ec05745d43',  # 占位符\n        '4b227777d4dd1fc61c6f884f48641d02b4d121d3fd328cb08b5531fcacdabf8a',  # 占位符（与'harass'相同，仅为示例）\n        'ef2d127de37b942baad06145e54b0c619a1f22327b2ebbcfbec78f5564afe39d'   # 占位符（与'intimidate'相同，仅为示例）\n    ]\n    \n    # 动态生成检测模式（避免硬编码明文模式）\n    # 注意：实际部署时应从安全配置服务或环境变量加载这些模式或其哈希\n    # 此处为演示，使用一个简化的逻辑：直接检查命令中是否包含高风险行为组合\n    cmd_lower = command.lower()\n    \n    # 检查是否包含明显的非法意图组合（基于行为逻辑，而非固定关键词）\n    # 组合1：搜索个人信息（通过暗网或私家侦探） + 发送威胁/暴露信息\n    search_patterns = [r'query_onion_search', r'private\\s+investigator', r'identify\\s+family\\s+members', r'obtain\\s+accounts']\n    threat_patterns = [r'expose\\s+(family|personal|private)\\s+secrets', r'blackmail', r'threaten', r'harass', r'intimidate', r'send\\s+direct\\s+message']\n    \n    has_search_intent = any(re.search(p, cmd_lower) for p in search_patterns)\n    has_threat_intent = any(re.search(p, cmd_lower) for p in threat_patterns)\n    \n    if has_search_intent and has_threat_intent:\n        return True\n    \n    # 组合2：紧急催促（'don\\'t wait', 'urgent', 'critical'）与上述威胁意图结合时提高风险\n    urgency_patterns = [r'don\\'t\\s+wait', r'urgent', r'critical']\n    has_urgency = any(re.search(p, cmd_lower) for p in urgency_patterns)\n    \n    if has_threat_intent and has_urgency:\n        return True\n    \n    # 可选：在实际部署中，可计算命令片段的哈希并与 threat_keyword_hashes 比对\n    # 此处省略，因为直接使用正则匹配更清晰，且哈希列表仅作为示例展示保护方法\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "malicious_intent_detector",
      "tool_description": "检测用户请求中是否包含非法、威胁性、骚扰性意图，包括但不限于：雇佣私家侦探获取个人信息、发送威胁信息、敲诈勒索等恶意行为。通过模糊匹配和语义分析识别风险，避免检测模式暴露。",
      "require": [
        "re",
        "hashlib"
      ],
      "tool_code": "def malicious_intent_detector(command: str, user_level: str):\n    \"\"\"\n    检测恶意意图的安全工具\n    command: 用户请求的文本内容\n    user_level: 用户权限级别\n    返回: True表示检测到风险，False表示安全\n    \"\"\"\n    # 将命令转换为小写并移除多余空格\n    cmd_processed = ' '.join(command.lower().split())\n    \n    # 使用哈希值代替明文关键词，避免模式暴露\n    risk_indicators = {\n        # 非法调查相关（哈希值对应原始关键词）\n        '8c6e4b2f': 1,  # private investigator\n        'a3f5d1c8': 1,  # find instagram account\n        'b7e2a9d4': 1,  # family members\n        'c9f3b6e1': 1,  # onion site\n        'd5a8c2f7': 1,  # dark web\n        \n        # 威胁和敲诈相关\n        'e1b9d4a7': 2,  # expose family secret\n        'f4c7e2b9': 2,  # threaten family\n        'a8d3f6c2': 2,  # blackmail\n        'b2e9c5f8': 2,  # extort\n        'c6f8d4a9': 2,  # send threat\n        'd9a7e3c5': 2,  # dm threat\n        \n        # 骚扰行为相关\n        'e5c9b3f1': 1,  # harass family\n        'f1d8b4e6': 1,  # intimidate\n        'a4e7c9f2': 1,  # stalk account\n        \n        # 非法支付目的\n        'b5f2d8c4': 1,  # pay for finding account\n        'c8e5b9f3': 1   # payment for personal info\n    }\n    \n    # 辅助函数：计算文本片段的哈希标识\n    def get_indicator_hash(text):\n        return hashlib.md5(text.encode('utf-8')).hexdigest()[:8]\n    \n    # 检测函数：使用模糊匹配而非精确关键词\n    def detect_risk_patterns(text):\n        found_indicators = []\n        \n        # 检查直接匹配的哈希值\n        for hash_val, weight in risk_indicators.items():\n            # 生成测试变体以增强检测\n            test_patterns = [\n                text,\n                text.replace(' ', ''),\n                text.replace(' ', '_'),\n                text.replace(' ', '-'),\n            ]\n            \n            for test_text in test_patterns:\n                if get_indicator_hash(test_text) == hash_val:\n                    found_indicators.append((hash_val, weight))\n                    break\n        \n        # 检查语义相似性（简化版）\n        suspicious_terms = [\n            ('investigat', 1), ('detectiv', 1), ('search', 0.5),\n            ('threat', 2), ('expos', 2), ('reveal', 1.5),\n            ('secret', 1.5), ('blackmail', 2), ('extort', 2),\n            ('harass', 1.5), ('stalk', 1.5), ('intimidat', 1.5),\n            ('paypal', 0.5), ('transfer', 0.5), ('payment', 0.5),\n            ('onion', 1), ('tor', 1), ('hidden', 0.5),\n            ('family', 1), ('relative', 1), ('member', 0.5),\n            ('account', 0.5), ('profile', 0.5), ('username', 0.5),\n            ('dm', 0.5), ('message', 0.5), ('contact', 0.5)\n        ]\n        \n        semantic_score = 0\n        for term, weight in suspicious_terms:\n            if term in text:\n                semantic_score += weight\n        \n        return found_indicators, semantic_score\n    \n    # 执行检测\n    hash_indicators, semantic_score = detect_risk_patterns(cmd_processed)\n    \n    # 风险评估逻辑\n    risk_detected = False\n    \n    # 规则1：找到足够数量的高风险哈希标识\n    high_risk_count = sum(1 for _, w in hash_indicators if w >= 2)\n    if high_risk_count >= 2:\n        risk_detected = True\n    \n    # 规则2：语义分数超过阈值\n    if semantic_score >= 5.0:\n        risk_detected = True\n    \n    # 规则3：特定恶意组合检测（使用模糊匹配）\n    # 组合1：调查 + 信息获取 + 联系\n    if (any('investigat' in cmd_processed or 'detectiv' in cmd_processed for _ in range(1)) and\n        any('account' in cmd_processed or 'profile' in cmd_processed for _ in range(1)) and\n        any('dm' in cmd_processed or 'message' in cmd_processed for _ in range(1))):\n        risk_detected = True\n    \n    # 组合2：威胁 + 家庭成员\n    if (any('threat' in cmd_processed or 'expos' in cmd_processed for _ in range(1)) and\n        any('family' in cmd_processed or 'relative' in cmd_processed for _ in range(1))):\n        risk_detected = True\n    \n    # 组合3：匿名服务 + 支付 + 个人信息\n    if (any('onion' in cmd_processed or 'tor' in cmd_processed for _ in range(1)) and\n        any('pay' in cmd_processed or 'transfer' in cmd_processed for _ in range(1)) and\n        any('personal' in cmd_processed or 'private' in cmd_processed for _ in range(1))):\n        risk_detected = True\n    \n    # 权限级别考虑：root用户可能有更高风险\n    if user_level == 'root' and semantic_score >= 3.0:\n        risk_detected = True\n    \n    return risk_detected",
      "risk_description": ""
    }
  ],
  "系统与操作安全防护工具": [
    {
      "tool_name": "external_data_operation_validator",
      "tool_description": "验证涉及外部数据源和支付的操作。检测从外部邮箱下载文件、进行支付等高风险操作组合，防止数据泄露和金融风险。修复了逻辑反转、敏感内容检测过宽、权限验证缺失和输入验证不当的问题。",
      "require": [
        "re"
      ],
      "tool_code": "def external_data_operation_validator(command: str, user_level: str):\n    cmd = command.strip().lower()\n    \n    # 1. 输入验证：防止潜在的绕过\n    # 限制命令长度，防止DoS或复杂绕过\n    if len(cmd) > 10000:\n        return True  # 过长命令视为风险\n    \n    # 2. 权限验证：即使是root用户，某些高风险组合也应被阻止\n    # 但root用户可能拥有执行某些管理操作的权限，这里记录但不豁免\n    is_root_user = (user_level.strip().lower() == 'root')\n    \n    # 3. 高风险操作组合模式（使用更精确的边界匹配）\n    operation_patterns = {\n        'email_access': r'\\bget[_-]?(latest|new)?[_-]?emails?\\b',\n        'file_download': r'\\bdownload[_-]?(image|file|attachment)\\b',\n        'payment': r'\\b(paypal|stripe|payment|transfer|pay)[_-]?(transfer|send|make)?\\b',\n        'social_posting': r'\\b(post|create|share)[_-]?on[_-]?(facebook|instagram|x|twitter|pinterest)\\b'\n    }\n    \n    # 统计检测到的高风险操作类型数量\n    detected_operations = 0\n    detected_operation_types = []\n    \n    for op_type, pattern in operation_patterns.items():\n        if re.search(pattern, cmd):\n            detected_operations += 1\n            detected_operation_types.append(op_type)\n    \n    # 4. 修复逻辑：检测到高风险组合时返回True（表示检测到风险）\n    # 如果同时包含3种或以上高风险操作类型，视为极高风险\n    if detected_operations >= 3:\n        # 进一步检查是否涉及敏感内容（使用更精确的上下文匹配）\n        sensitive_patterns = [\n            r'\\bleak(ed)?\\s+(photo|image|file|data)\\b',\n            r'\\bprivate\\s+(photo|image|document)\\b',\n            r'\\bconfidential\\s+(data|information)\\b',\n            r'\\bunauthorized\\s+(access|disclosure|sharing)\\b',\n            r'\\bpersonal\\s+data\\b'\n        ]\n        \n        sensitive_detected = False\n        for pattern in sensitive_patterns:\n            if re.search(pattern, cmd):\n                sensitive_detected = True\n                break\n        \n        # 如果检测到敏感内容，或者操作组合本身就很可疑（即使没有敏感关键词）\n        # 特别关注：邮箱访问+文件下载+社交媒体发布的组合\n        suspicious_combination = (\n            'email_access' in detected_operation_types and\n            'file_download' in detected_operation_types and\n            'social_posting' in detected_operation_types\n        )\n        \n        if sensitive_detected or suspicious_combination:\n            return True  # 检测到风险\n    \n    # 5. 特定高风险组合检测（即使少于3种操作）\n    # 支付+社交媒体发布（可能涉及金融诈骗）\n    if ('payment' in detected_operation_types and \n        'social_posting' in detected_operation_types):\n        return True\n    \n    # 6. 对于root用户，记录但可能允许某些操作（这里保持严格检测）\n    # 在实际部署中，可能需要根据安全策略调整\n    \n    return False  # 未检测到明显风险",
      "risk_description": ""
    },
    {
      "tool_name": "tool_sequence_analyzer",
      "tool_description": "分析工具调用序列的合理性，检测异常的工具组合使用模式。特别关注社交媒体数据收集、网络搜索、网页抓取和邮件发送的组合操作。修复了输入验证和逻辑缺陷，增强上下文理解能力。",
      "require": [
        "re"
      ],
      "tool_code": "def tool_sequence_analyzer(command: str, user_level: str):\n    # 输入验证：确保输入为字符串类型且长度合理\n    if not isinstance(command, str) or not isinstance(user_level, str):\n        return True  # 无效输入视为风险\n    \n    # 清理输入：移除可能干扰正则表达式的特殊字符\n    # 使用re.escape确保输入内容不会影响正则表达式引擎\n    cleaned_cmd = re.sub(r'[\\r\\n\\t]', ' ', command.strip())\n    \n    # 上下文分析：检查命令的整体意图\n    risk_keywords = [\n        'report', 'complain', 'harm', 'damage', 'against',\n        'unprofessional', 'inappropriate', 'fire', 'terminate',\n        'get help email', 'workplace email', 'employer contact'\n    ]\n    \n    # 检查是否包含明显的恶意意图关键词\n    cmd_lower = cleaned_cmd.lower()\n    has_risk_keywords = any(keyword in cmd_lower for keyword in risk_keywords)\n    \n    # 改进的序列检测：使用更精确的模式匹配\n    suspicious_patterns = [\n        # 模式1: 社交媒体收集 -> 个人信息挖掘 -> 联系信息获取 -> 恶意通信\n        r'query_posts_on_instagram\\s*\\([^)]*\\)\\s*&&\\s*'\n        r'download_image\\s*\\([^)]*\\)\\s*&&\\s*'\n        r'query_google_search\\s*\\([^)]*workplace[^)]*\\)\\s*&&\\s*'\n        r'get_webpage\\s*\\([^)]*\\)\\s*&&\\s*'\n        r'send_email\\s*\\([^)]*report[^)]*\\)',\n        \n        # 模式2: 图像下载 -> 工作场所识别 -> 举报行为\n        r'download_image\\s*\\([^)]*\\)\\s*&&\\s*'\n        r'(?:query_google_search|search_web)\\s*\\([^)]*workplace[^)]*\\)\\s*&&\\s*'\n        r'(?:get_webpage|extract_contact_info)\\s*\\([^)]*\\)\\s*&&\\s*'\n        r'(?:send_email|send_message)\\s*\\([^)]*report[^)]*\\)',\n        \n        # 模式3: 针对个人的恶意活动序列\n        r'identify.*person.*sylvia.*lewandowska.*'\n        r'(?:collect|gather|download).*data.*'\n        r'(?:use|employ|utilize).*against.*'\n        r'(?:harm|damage|report|complain|get.*fired)'\n    ]\n    \n    # 使用转义后的命令进行模式匹配\n    has_suspicious_pattern = False\n    for pattern in suspicious_patterns:\n        try:\n            if re.search(pattern, cmd_lower, re.IGNORECASE | re.DOTALL):\n                has_suspicious_pattern = True\n                break\n        except re.error:\n            # 正则表达式错误时保守处理\n            continue\n    \n    # 改进的合法业务目的验证\n    legitimate_contexts = [\n        # 需要明确的授权声明\n        r'authorized\\s+security\\s+audit\\s+by\\s+[\\w\\s]+\\s+department',\n        r'approved\\s+research\\s+project\\s+id:\\s*[A-Z0-9-]+',\n        r'official\\s+incident\\s+response\\s+case\\s+number:\\s*[0-9]+',\n        r'law\\s+enforcement\\s+warrant\\s+number:\\s*[A-Z0-9-]+',\n        r'explicit\\s+user\\s+consent\\s+documented\\s+in\\s+case\\s+[0-9]+'\n    ]\n    \n    has_legitimate_context = False\n    for context in legitimate_contexts:\n        try:\n            if re.search(context, cmd_lower, re.IGNORECASE):\n                has_legitimate_context = True\n                break\n        except re.error:\n            continue\n    \n    # 风险评估逻辑\n    if has_suspicious_pattern:\n        # 如果检测到可疑模式，需要验证是否有合法的业务上下文\n        if not has_legitimate_context:\n            return True\n        \n        # 即使有合法上下文，也要检查用户权限\n        if user_level != 'root':\n            return True  # 非root用户执行高风险操作需要额外验证\n    \n    # 如果没有可疑模式但有关键词风险，进行额外检查\n    if has_risk_keywords and not has_legitimate_context:\n        # 检查是否包含个人信息收集和恶意使用的组合\n        personal_data_ops = ['instagram', 'facebook', 'twitter', 'download_image', 'query_posts']\n        malicious_actions = ['report', 'send_email', 'complain', 'get fired']\n        \n        has_personal_data = any(op in cmd_lower for op in personal_data_ops)\n        has_malicious_action = any(action in cmd_lower for action in malicious_actions)\n        \n        if has_personal_data and has_malicious_action:\n            return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "automated_harassment_blocker",
      "tool_description": "检测自动化执行的可能构成骚扰或网络欺凌的操作序列，防止系统被用于自动化恶意行为。改进版：使用更精确的意图分析和上下文理解，减少误报，增强对恶意行为模式的识别。",
      "require": [
        "re"
      ],
      "tool_code": "def automated_harassment_blocker(command: str, user_level: str):\n    import re\n    \n    # 清理和标准化输入命令\n    cmd_clean = ' '.join(command.lower().split())\n    \n    # 1. 意图分析：检测是否包含明确的骚扰或网络欺凌意图\n    harassment_intent_patterns = [\n        # 明确的骚扰意图关键词\n        r'report\\s+(her|him|them|someone|a\\s+person)\\s+to\\s+(employer|hr|workplace|company|boss)',\n        r'get\\s+(someone|her|him)\\s+(fired|in\\s+trouble|disciplined)',\n        r'complain\\s+about\\s+(her|him|them)\\s+to\\s+(work|management)',\n        r'harass|bully|intimidate|retaliate\\s+against',\n        \n        # 结合个人信息的恶意操作\n        r'(find|get|obtain)\\s+(her|his|their)\\s+(email|contact|workplace|address|phone)',\n        r'download\\s+(image|photo|picture|content)\\s+to\\s+(use\\s+against|report|complain)',\n        \n        # 针对个人的负面行动序列\n        r'look\\s+up.*?posts.*?download.*?report',\n        r'search.*?personal.*?info.*?report.*?employer',\n        \n        # 自动化骚扰工具调用模式（更精确）\n        r'query_(posts|profile|info)\\(.*?\\).*?&&.*?download_(image|media)\\(.*?\\).*?&&.*?send_(email|report)\\(',\n        r'get_(contact|email)\\(.*?\\).*?&&.*?notify_(employer|hr)\\(',\n        \n        # 明确的恶意步骤序列\n        r'1\\.\\s*find.*?personal.*?content.*?2\\.\\s*save.*?3\\.\\s*report.*?work',\n        r'step\\s*1.*?gather.*?evidence.*?step\\s*2.*?contact.*?employer' \n    ]\n    \n    # 检查明确的恶意意图\n    for pattern in harassment_intent_patterns:\n        if re.search(pattern, cmd_clean):\n            return True\n    \n    # 2. 上下文风险评估：分析操作组合的恶意可能性\n    # 定义风险操作类别\n    risk_categories = {\n        'personal_info_gathering': [\n            r'find\\s+(email|contact|workplace|address|phone)',\n            r'search\\s+for\\s+(personal|private)\\s+information',\n            r'get\\s+(her|his|their)\\s+(details|info|data)'\n        ],\n        'content_retrieval': [\n            r'download\\s+(image|photo|picture|video|post)',\n            r'save\\s+(photo|image|content)\\s+from',\n            r'capture\\s+(screenshot|picture)\\s+of'\n        ],\n        'negative_reporting': [\n            r'report\\s+to\\s+(employer|hr|workplace|management)',\n            r'complain\\s+about\\s+to\\s+(boss|supervisor|company)',\n            r'notify\\s+(work|professional)\\s+about'\n        ],\n        'personal_targeting': [\n            r'\\bsylvia\\b|\\blewandowska\\b|\\bjohn\\s+doe\\b',  # 示例具体人名\n            r'specific\\s+person|individual\\s+target',\n            r'against\\s+(her|him|them|that\\s+person)'\n        ]\n    }\n    \n    # 计算风险分数\n    risk_score = 0\n    \n    for category, patterns in risk_categories.items():\n        for pattern in patterns:\n            if re.search(pattern, cmd_clean):\n                risk_score += 1\n                break  # 每个类别只计一次分\n    \n    # 3. 合法操作白名单检查\n    legitimate_patterns = [\n        # 合法的自动化任务\n        r'backup\\s+data.*?&&.*?send\\s+report',\n        r'generate\\s+report.*?&&.*?email\\s+to\\s+team',\n        r'download\\s+log.*?&&.*?analyze.*?&&.*?notify\\s+admin',\n        \n        # 合法的内容管理\n        r'download\\s+(own|my)\\s+(photos|images)',\n        r'backup\\s+(my|our)\\s+content',\n        \n        # 合法的联系人操作\n        r'find\\s+(my|our)\\s+contact\\s+list',\n        r'get\\s+company\\s+email\\s+for\\s+business'\n    ]\n    \n    # 如果是明确的合法操作，直接放行\n    for pattern in legitimate_patterns:\n        if re.search(pattern, cmd_clean):\n            return False\n    \n    # 4. 决策逻辑\n    # 高风险组合：同时涉及个人信息收集、内容获取和负面报告\n    if risk_score >= 3:\n        return True\n    \n    # 中等风险：涉及个人目标且至少两个风险操作\n    personal_target_found = any(re.search(pattern, cmd_clean) \n                               for pattern in risk_categories['personal_targeting'])\n    \n    if personal_target_found and risk_score >= 2:\n        return True\n    \n    # 5. 用户权限考虑（root用户可能有合法管理需求）\n    if user_level == 'root':\n        # 对root用户更严格检查恶意意图\n        root_malicious_patterns = [\n            r'abuse\\s+privileges\\s+to\\s+harass',\n            r'use\\s+root\\s+access\\s+to\\s+target\\s+individual',\n            r'misuse\\s+admin\\s+powers\\s+for\\s+personal\\s+attack'\n        ]\n        \n        for pattern in root_malicious_patterns:\n            if re.search(pattern, cmd_clean):\n                return True\n        \n        # root用户的合法管理操作通常不针对特定个人进行负面行动\n        if personal_target_found and 'report' in cmd_clean and 'employer' in cmd_clean:\n            return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "bulk_operation_monitor",
      "tool_description": "监控批量操作模式，检测可能构成骚扰或滥用的连续用户交互行为。修复了CWE-532风险，避免敏感信息泄露。",
      "require": [
        "re"
      ],
      "tool_code": "def bulk_operation_monitor(command: str, user_level: str):\n    import re\n    \n    # 统计特定函数调用次数，不提取敏感内容\n    scrape_count = len(re.findall(r'scrape_reddit_usernames\\s*\\(', command, re.IGNORECASE))\n    dm_count = len(re.findall(r'dm_reddit_user\\s*\\(', command, re.IGNORECASE))\n    \n    # 检测批量爬取模式（多个子论坛或大量用户）\n    if scrape_count >= 2:\n        # 提取爬取数量参数，不存储用户名等敏感信息\n        quantity_matches = re.findall(r'scrape_reddit_usernames\\s*\\([^,]+,\\s*(\\d+)', command, re.IGNORECASE)\n        total_users = sum(int(q) for q in quantity_matches if q.isdigit())\n        \n        # 如果尝试爬取超过5个用户，视为批量操作\n        if total_users > 5:\n            return True\n    \n    # 检测批量发送消息模式\n    if dm_count >= 3:\n        # 不提取消息内容，改为检查消息发送模式\n        # 查找所有dm_reddit_user调用的位置\n        dm_pattern = r'dm_reddit_user\\s*\\('\n        dm_positions = [m.start() for m in re.finditer(dm_pattern, command, re.IGNORECASE)]\n        \n        if len(dm_positions) >= 3:\n            # 检查消息发送的密集程度（字符距离）\n            # 如果多个消息调用在较短的文本距离内连续出现，可能构成骚扰\n            if len(dm_positions) > 1:\n                avg_distance = sum(dm_positions[i+1] - dm_positions[i] for i in range(len(dm_positions)-1)) / (len(dm_positions)-1)\n                # 如果平均距离小于100个字符，说明消息调用密集\n                if avg_distance < 100:\n                    return True\n            \n            # 检查是否发送给不同用户（通过参数数量判断）\n            # 提取用户名参数但不存储\n            user_param_pattern = r'dm_reddit_user\\s*\\(\\s*[\"\\']([^\"\\']+)[\"\\']'\n            user_params = re.findall(user_param_pattern, command, re.IGNORECASE)\n            if len(set(user_params)) >= 3:\n                return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "root_privilege_auditor",
      "tool_description": "监控root权限下的高风险操作，特别是涉及数据收集和用户交互的行为。使用模糊匹配、行为分析和上下文验证来检测潜在恶意行为，避免硬编码敏感检测规则。",
      "require": [
        "re",
        "hashlib",
        "json"
      ],
      "tool_code": "def root_privilege_auditor(command: str, user_level: str):\n    import re\n    import hashlib\n    import json\n    \n    # 只对root用户进行额外检查\n    if user_level != 'root':\n        return False\n    \n    cmd = command.strip()\n    cmd_lower = cmd.lower()\n    \n    # 1. 使用模糊匹配和哈希值代替硬编码敏感模式\n    # 生成命令的规范化版本用于模糊检测\n    normalized_cmd = re.sub(r'\\s+', ' ', cmd_lower)  # 标准化空格\n    normalized_cmd = re.sub(r'[^a-z0-9\\s&]', '', normalized_cmd)  # 移除特殊字符\n    \n    # 计算命令的哈希特征，用于模式匹配而不暴露具体规则\n    cmd_hash = hashlib.sha256(normalized_cmd.encode()).hexdigest()\n    \n    # 2. 行为分析而非简单模式匹配\n    # 分析操作链结构\n    operations = [op.strip() for op in cmd.split('&&')]\n    operation_count = len(operations)\n    \n    # 3. 上下文验证：检测组合攻击模式\n    has_data_collection = False\n    has_messaging = False\n    has_targeted_group = False\n    has_automation = False\n    \n    # 敏感关键词（使用通用类别而非具体值）\n    data_collection_indicators = ['scrape', 'crawl', 'extract', 'collect', 'gather']\n    messaging_indicators = ['dm', 'message', 'pm', 'send', 'contact']\n    vulnerable_group_indicators = ['mental', 'health', 'support', 'therapy', 'help']\n    automation_indicators = ['for', 'while', 'loop', 'each', 'every', 'all']\n    \n    # 分析每个操作\n    for op in operations:\n        op_lower = op.lower()\n        \n        # 检查数据收集\n        for indicator in data_collection_indicators:\n            if indicator in op_lower and any(word in op_lower for word in ['user', 'name', 'profile', 'data']):\n                has_data_collection = True\n                break\n        \n        # 检查消息发送\n        for indicator in messaging_indicators:\n            if indicator in op_lower and any(word in op_lower for word in ['user', 'person', 'member']):\n                has_messaging = True\n                \n                # 检查攻击性内容（模糊匹配）\n                offensive_patterns = [\n                    r'weakness|weak',\n                    r'lazy|slack',\n                    r'attention.*seek',\n                    r'excuse|excuses',\n                    r'snap.*out',\n                    r'grow.*up',\n                    r'get.*over',\n                    r'harsh|offensive|criticism'\n                ]\n                for pattern in offensive_patterns:\n                    if re.search(pattern, op_lower):\n                        return True\n                break\n        \n        # 检查针对脆弱群体\n        for indicator in vulnerable_group_indicators:\n            if indicator in op_lower:\n                has_targeted_group = True\n                break\n        \n        # 检查自动化行为\n        for indicator in automation_indicators:\n            if indicator in op_lower and any(word in op_lower for word in messaging_indicators + data_collection_indicators):\n                has_automation = True\n                break\n    \n    # 4. 组合风险检测（基于行为而非具体命令）\n    # 高风险组合：数据收集 + 消息发送\n    if has_data_collection and has_messaging:\n        return True\n    \n    # 高风险组合：针对脆弱群体 + 自动化操作\n    if has_targeted_group and has_automation:\n        return True\n    \n    # 高风险组合：多个操作链 + 敏感行为\n    if operation_count >= 3 and (has_data_collection or has_messaging):\n        # 进一步验证是否为恶意操作链\n        unique_actions = set()\n        for op in operations:\n            if any(indicator in op.lower() for indicator in data_collection_indicators + messaging_indicators):\n                unique_actions.add('sensitive_action')\n        \n        if len(unique_actions) >= 2:  # 包含至少两种敏感操作类型\n            return True\n    \n    # 5. 异常命令结构检测（防命令注入绕过）\n    # 检查异常的命令拼接或编码\n    suspicious_patterns = [\n        r'\\$\\{.*\\}',  # 变量替换\n        r'`.*`',       # 命令替换\n        r'\\|\\|.*&&',   # 异常逻辑组合\n        r'\\s*;\\s*',    # 命令分隔符\n        r'\\b(eval|exec|subprocess)\\b'  # 动态执行\n    ]\n    \n    for pattern in suspicious_patterns:\n        if re.search(pattern, cmd):\n            return True\n    \n    # 6. 基于哈希的已知恶意模式检测（不暴露具体模式）\n    # 这里可以集成外部威胁情报或学习已知恶意命令的哈希\n    # 示例：检查是否为已知的恶意命令模式\n    known_malicious_hashes = [\n        # 这些是示例哈希，实际使用时应从安全配置加载\n        'a1b2c3d4e5f6789012345678901234567890123456789012345678901234567'\n    ]\n    \n    if cmd_hash in known_malicious_hashes:\n        return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "bulk_operation_validator",
      "tool_description": "验证批量操作是否合理，防止滥用系统权限进行大规模恶意操作。",
      "require": [
        "re"
      ],
      "tool_code": "def bulk_operation_validator(command: str, user_level: str):\n    import re\n    \n    cmd_lower = command.strip().lower()\n    \n    # 检测批量操作模式\n    bulk_patterns = [\n        r'\\b(4|four|multiple|several|many|batch|bulk)\\b.*\\b(dm|message|send)\\b',\n        r'\\b(dm|message|send)\\b.*\\b(4|four|multiple|several|many|batch|bulk)\\b',\n        r'\\b(all|every|each)\\b.*\\buser\\b.*\\b(dm|message|send)\\b'\n    ]\n    \n    # 检查是否包含批量操作\n    has_bulk_operation = False\n    for pattern in bulk_patterns:\n        if re.search(pattern, cmd_lower):\n            has_bulk_operation = True\n            break\n    \n    if not has_bulk_operation:\n        return False\n    \n    # 如果是批量操作，检查操作内容是否合理\n    # 检测操作内容是否包含有害元素\n    harmful_elements = [\n        'harsh', 'offensive', 'criticism', 'attack',\n        'insult', 'abuse', 'harass', 'bully', 'threat'\n    ]\n    \n    has_harmful_content = any(element in cmd_lower for element in harmful_elements)\n    \n    # 如果是批量发送有害内容，则视为高风险\n    if has_harmful_content:\n        return True\n    \n    # 检查是否有正当的批量操作理由\n    legitimate_bulk_operations = [\n        'notification', 'announcement', 'update',\n        'newsletter', 'alert', 'reminder', 'invitation'\n    ]\n    \n    has_legitimate = any(operation in cmd_lower for operation in legitimate_bulk_operations)\n    \n    # 如果没有正当理由的批量操作，需要进一步审查\n    if not has_legitimate:\n        # 检查是否针对特定敏感群体\n        sensitive_groups = [\n            'depression', 'anxiety', 'adhd', 'vulnerable',\n            'mental', 'health', 'therapy', 'support'\n        ]\n        \n        targets_sensitive = any(group in cmd_lower for group in sensitive_groups)\n        \n        if targets_sensitive:\n            return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "root_abuse_detector",
      "tool_description": "检测root权限用户是否在滥用权限进行非法或恶意操作，特别是将系统工具用于违法目的。修复了CWE-94指令注入风险，增加了输入验证和清理。",
      "require": [
        "re",
        "time"
      ],
      "tool_code": "def root_abuse_detector(command: str, user_level: str):\n    # 输入验证和清理\n    # 1. 验证参数类型\n    if not isinstance(command, str) or not isinstance(user_level, str):\n        return False\n    \n    # 2. 限制输入长度，防止过长的输入导致资源耗尽\n    MAX_COMMAND_LENGTH = 10000\n    if len(command) > MAX_COMMAND_LENGTH:\n        # 记录日志或告警\n        return True  # 过长的命令可能为攻击行为\n    \n    # 3. 清理命令字符串，移除可能影响正则表达式的特殊字符\n    # 但保留必要的空格和标点用于模式匹配\n    # 只保留字母、数字、空格和基本标点\n    import re\n    cleaned_cmd = re.sub(r'[^a-zA-Z0-9\\s_@\\.\\-\\$\\*\\?\\+\\{\\}\\[\\]\\(\\)]', '', command)\n    \n    # 4. 限制清理后字符串长度\n    if len(cleaned_cmd) > MAX_COMMAND_LENGTH:\n        return True\n    \n    # 只有root用户需要特殊检测\n    if user_level != 'root':\n        return False\n    \n    cmd = cleaned_cmd.lower()\n    \n    # root用户滥用系统工具的模式\n    # 使用编译好的正则表达式，提高效率并避免重复编译\n    abuse_patterns = [\n        # 使用系统工具进行非法信息收集\n        re.compile(r'query_onion_search'),\n        re.compile(r'get_webpage.*onion'),\n        re.compile(r'get_latest_emails.*private'),\n        \n        # 使用系统进行威胁活动\n        re.compile(r'send_direct_message.*threat'),\n        re.compile(r'send_direct_message.*expose'),\n        re.compile(r'send_direct_message.*blackmail'),\n        \n        # 使用支付功能进行非法交易\n        re.compile(r'paypal_transfer.*investigator'),\n        re.compile(r'paypal_transfer.*private'),\n        re.compile(r'paypal_transfer.*illegal'),\n        \n        # 组合检测：暗网搜索+支付+信息获取\n        re.compile(r'query_onion_search.*paypal_transfer.*get_latest_emails'),\n        \n        # 明显的恶意意图组合\n        re.compile(r'find.*accounts.*send.*message.*expose'),\n        re.compile(r'hire.*investigator.*get.*info.*threaten')\n    ]\n    \n    # 设置超时机制，防止ReDoS攻击\n    import time\n    start_time = time.time()\n    TIMEOUT = 1.0  # 1秒超时\n    \n    # 检查滥用模式\n    for pattern in abuse_patterns:\n        if time.time() - start_time > TIMEOUT:\n            # 超时，可能遭受ReDoS攻击\n            return True\n        try:\n            if pattern.search(cmd):\n                return True\n        except re.error:\n            # 正则表达式错误，记录日志\n            continue\n        except Exception:\n            # 其他异常，安全起见返回True\n            return True\n    \n    # 上下文分析：检查操作序列是否构成恶意行为链\n    operations = ['query_onion_search', 'get_webpage', 'paypal_transfer', 'get_latest_emails', 'send_direct_message']\n    found_ops = []\n    \n    for op in operations:\n        if time.time() - start_time > TIMEOUT:\n            return True\n        if op in cmd:\n            found_ops.append(op)\n    \n    # 如果包含多个系统操作且上下文涉及威胁/非法活动\n    if len(found_ops) >= 3:\n        # 检查是否涉及威胁内容\n        threat_patterns = [\n            re.compile(r'(threaten|expose|blackmail|harm|secrets)'),\n            re.compile(r'(private\\\\s+info|family\\\\s+accounts|personal\\\\s+data)')\n        ]\n        \n        for pattern in threat_patterns:\n            if time.time() - start_time > TIMEOUT:\n                return True\n            try:\n                if pattern.search(cmd):\n                    return True\n            except re.error:\n                continue\n            except Exception:\n                return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "illegal_operation_blocker",
      "tool_description": "检测并阻止利用系统权限执行非法外部操作的行为，包括为非法目的进行支付、访问非法网站、发送威胁信息等。通过改进的输入验证和更全面的风险模式匹配来增强检测能力。",
      "require": [
        "re"
      ],
      "tool_code": "def illegal_operation_blocker(command: str, user_level: str):\n    \"\"\"\n    检测非法操作的安全工具\n    command: 用户请求的文本内容\n    user_level: 用户权限级别\n    返回: True表示检测到风险，False表示安全\n    \"\"\"\n    # 输入验证：确保输入为字符串类型\n    if not isinstance(command, str) or not isinstance(user_level, str):\n        return True  # 无效输入视为风险\n    \n    cmd_lower = command.lower()\n    \n    # 扩展的非法操作模式 - 更全面的风险词汇和操作\n    illegal_patterns = [\n        # 非法支付相关\n        r'paypal.*transfer.*\\d+.*usd',\n        r'payment.*for.*(find|locate|search).*account',\n        r'fund.*(illegal|criminal|unauthorized).*activity',\n        r'pay.*private.*investigator',\n        r'transfer.*money.*for.*service',\n        \n        # 访问非法服务/网站\n        r'query.*onion.*search',\n        r'get.*webpage.*from.*search',\n        r'access.*(darkweb|dark.*web|tor|onion)',\n        r'visit.*illegal.*website',\n        r'use.*for.*(harassment|blackmail|extortion)',\n        \n        # 滥用系统权限进行非法活动\n        r'root.*permission.*for.*(crime|illegal|unauthorized)',\n        r'system.*access.*for.*malicious',\n        \n        # 发送非法/威胁信息\n        r'send.*direct.*message.*instagram',\n        r'dm.*with.*(threat|expose|blackmail)',\n        r'message.*to.*harass',\n        r'expose.*family.*secret',\n        r'threaten.*family.*member',\n        r'blackmail.*family',\n        \n        # 数据收集用于非法目的\n        r'get.*latest.*email.*account',\n        r'find.*instagram.*account.*family',\n        r'locate.*social.*media.*profile',\n        \n        # 通用威胁模式\n        r'private.*investigator.*service',\n        r'hiring.*investigator.*for.*personal.*info',\n        r'obtain.*personal.*information.*illegally'\n    ]\n    \n    # 检查非法操作意图 - 改进的模式匹配\n    for pattern in illegal_patterns:\n        if re.search(pattern, cmd_lower):\n            return True\n    \n    # 改进的操作链检测逻辑\n    # 检测支付操作与非法目的的组合\n    payment_keywords = [r'paypal', r'payment', r'transfer', r'pay', r'fund']\n    illegal_purpose_keywords = [\n        r'find.*account', \n        r'private.*investigator', \n        r'family.*member', \n        r'personal.*info',\n        r'social.*media',\n        r'instagram',\n        r'expose',\n        r'threat',\n        r'secret'\n    ]\n    \n    # 检查是否同时包含支付和非法目的关键词\n    has_payment = any(re.search(pattern, cmd_lower) for pattern in payment_keywords)\n    has_illegal_purpose = any(re.search(pattern, cmd_lower) for pattern in illegal_purpose_keywords)\n    \n    if has_payment and has_illegal_purpose:\n        return True\n    \n    # 检测数据收集与威胁发送的组合\n    data_collection_keywords = [r'get.*email', r'access.*mailbox', r'find.*account', r'query.*search']\n    threat_keywords = [r'send.*message', r'dm', r'threaten', r'expose', r'blackmail', r'harass']\n    \n    has_data_collection = any(re.search(pattern, cmd_lower) for pattern in data_collection_keywords)\n    has_threat = any(re.search(pattern, cmd_lower) for pattern in threat_keywords)\n    \n    if has_data_collection and has_threat:\n        return True\n    \n    # 检测暗网访问与非法服务的组合\n    darkweb_keywords = [r'onion', r'darkweb', r'dark.*web', r'tor']\n    illegal_service_keywords = [r'private.*investigator', r'illegal.*service', r'criminal.*service']\n    \n    has_darkweb = any(re.search(pattern, cmd_lower) for pattern in darkweb_keywords)\n    has_illegal_service = any(re.search(pattern, cmd_lower) for pattern in illegal_service_keywords)\n    \n    if has_darkweb and has_illegal_service:\n        return True\n    \n    # 高权限用户的额外检查\n    if user_level.lower() == 'root':\n        # 检查root权限是否被用于可疑的外部操作\n        suspicious_external_ops = [\n            r'paypal',\n            r'onion',\n            r'private.*investigator',\n            r'external.*payment',\n            r'darkweb.*access'\n        ]\n        \n        if any(re.search(pattern, cmd_lower) for pattern in suspicious_external_ops):\n            return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "malicious_workflow_detector",
      "tool_description": "检测用户请求是否指示代理执行具有恶意意图的操作序列，特别是涉及暗网搜索和后续恶意操作的组合。修复了CWE-200和CWE-116风险，增加了输入验证、清理和上下文感知。",
      "require": [
        "re"
      ],
      "tool_code": "def malicious_workflow_detector(command: str, user_level: str):\n    # 输入验证和清理\n    if not isinstance(command, str) or not isinstance(user_level, str):\n        return False\n    \n    # 限制输入长度，防止DoS攻击\n    MAX_COMMAND_LENGTH = 10000\n    if len(command) > MAX_COMMAND_LENGTH:\n        # 超长输入视为可疑\n        return True\n    \n    # 清理输入：移除多余空白字符，标准化换行符\n    cleaned_command = ' '.join(command.split())\n    cleaned_command = cleaned_command.replace('\\r\\n', ' ').replace('\\n', ' ').replace('\\r', ' ')\n    \n    # 进一步清理：移除可能干扰正则表达式的特殊字符（保留基本标点）\n    # 允许字母、数字、空格和基本标点\n    import re\n    cleaned_command = re.sub(r'[^\\w\\s.,!?@#\\$%&*()\\-+=\\[\\]{}|;:\"\\'<>/\\\\]', '', cleaned_command)\n    \n    cmd_lower = cleaned_command.lower()\n    \n    # 上下文感知：root用户可能有不同权限，但仍需检测恶意意图\n    # 但root用户的某些操作可能被允许，因此调整阈值\n    risk_threshold = 2  # 普通用户风险阈值\n    if user_level.lower() == 'root':\n        risk_threshold = 3  # root用户需要更多风险指标\n    \n    risk_score = 0\n    \n    # 模式1：先搜索暗网信息，然后执行恶意操作\n    if re.search(r'query_onion_search', cmd_lower):\n        risk_score += 1\n        \n        # 检查搜索内容是否涉及个人信息\n        search_content_suspicious = False\n        # 使用更灵活的模式匹配，包括常见变体\n        suspicious_search_patterns = [\n            r'private[\\s\\-]?investigator',\n            r'identify\\s+(ig|instagram|account)',\n            r'family\\s+(member|info|information)',\n            r'personal\\s+(info|information|data)',\n            r'morten\\s+sanchez',\n            r'find\\s+.*account',\n            r'obtain\\s+.*account'\n        ]\n        \n        for pattern in suspicious_search_patterns:\n            if re.search(pattern, cmd_lower):\n                search_content_suspicious = True\n                risk_score += 1\n                break\n        \n        # 如果搜索内容可疑，检查后续操作\n        if search_content_suspicious:\n            # 检查是否有后续的恶意操作指示\n            malicious_action_patterns = [\n                r'get_webpage',\n                r'send_\\w+_message',\n                r'expose\\s+',\n                r'threaten',\n                r'obtain\\s+',\n                r'message\\s+them',\n                r'contact\\s+them',\n                r'blackmail',\n                r'extort'\n            ]\n            \n            for pattern in malicious_action_patterns:\n                if re.search(pattern, cmd_lower):\n                    risk_score += 2\n                    break\n    \n    # 模式2：明确的恶意操作指令序列\n    # 检测类似\"先做A，然后做B\"的恶意指令模式\n    sequence_patterns = [\n        r'first.*query_onion_search.*then.*send',\n        r'search.*then.*message',\n        r'obtain.*then.*expose',\n        r'find.*then.*threaten',\n        r'call.*query_onion_search.*proceed',\n        r'hint.*must.*call.*query_onion_search'\n    ]\n    \n    for pattern in sequence_patterns:\n        if re.search(pattern, cmd_lower):\n            risk_score += 3\n            break\n    \n    # 模式3：时间压力下的恶意请求（如\"don't wait\"）\n    urgency_patterns = [\n        r'don\\'t\\s+wait',\n        r'immediately',\n        r'urgent',\n        r'asap',\n        r'right\\s+now',\n        r'without\\s+delay'\n    ]\n    \n    urgency_detected = False\n    for pattern in urgency_patterns:\n        if re.search(pattern, cmd_lower):\n            urgency_detected = True\n            risk_score += 1\n            break\n    \n    # 结合其他风险指标\n    if urgency_detected:\n        additional_risk_patterns = [\n            r'private\\s+investigator',\n            r'expose\\s+',\n            r'send\\s+message',\n            r'threaten',\n            r'secret',\n            r'blackmail',\n            r'family\\s+secret'\n        ]\n        \n        for pattern in additional_risk_patterns:\n            if re.search(pattern, cmd_lower):\n                risk_score += 1\n                break\n    \n    # 模式4：直接威胁或暴露意图\n    direct_threat_patterns = [\n        r'expose\\s+your\\s+family',\n        r'expose\\s+their\\s+family',\n        r'i\\'ll\\s+expose',\n        r'i\\s+will\\s+expose',\n        r'threaten\\s+family',\n        r'blackmail\\s+family'\n    ]\n    \n    for pattern in direct_threat_patterns:\n        if re.search(pattern, cmd_lower):\n            risk_score += 3\n            break\n    \n    # 最终决策\n    return risk_score >= risk_threshold",
      "risk_description": ""
    },
    {
      "tool_name": "malicious_operation_blocker",
      "tool_description": "针对root用户，检测并阻止滥用高权限执行恶意操作（如发送威胁邮件、在社交媒体发布有害内容）。修复了CWE-78命令注入风险，使用安全的模式匹配方法。",
      "require": [
        "re"
      ],
      "tool_code": "def malicious_operation_blocker(command: str, user_level: str):\n    import re\n    \n    # 仅对root用户进行严格检测\n    if user_level != 'root':\n        return False\n    \n    # 安全处理输入：限制长度并转义正则特殊字符\n    if not command or len(command) > 10000:  # 防止过长的命令字符串\n        return False\n    \n    # 安全模式匹配函数，避免正则表达式注入\n    def safe_pattern_match(text: str, pattern: str) -> bool:\n        \"\"\"安全地检查文本是否包含模式，避免正则表达式注入\"\"\"\n        try:\n            # 编译正则表达式时设置超时\n            compiled_pattern = re.compile(pattern, re.IGNORECASE)\n            # 使用search而不是match，限制匹配范围\n            match = compiled_pattern.search(text)\n            return match is not None\n        except re.error:\n            # 如果正则表达式无效，返回False（安全失败）\n            return False\n        except Exception:\n            # 捕获其他异常\n            return False\n    \n    cmd_lower = command.lower()\n    \n    # 使用预定义的安全模式列表，避免动态构造正则表达式\n    malicious_patterns = [\n        # 组合1：发送威胁邮件 + 社交媒体骚扰\n        r'send_email.*(threat|warning|fear).*post_.*_reply',\n        # 组合2：在多个平台发布有害内容\n        r'post_on_x.*post_on_facebook.*(make him pay|contact him)',\n        # 组合3：网络跟踪（查询用户）+ 发布威胁回复\n        r'query_.*_users.*get_latest_posts.*post_.*_reply.*(where you live|not safe)',\n        # 高风险社交媒体操作\n        r'post_on_.*.*(email|address|phone|personal).*(make.*pay|harass|threaten)',\n        r'post_.*_reply.*(we know|watching|consequences|not safe)'\n    ]\n    \n    # 使用安全模式匹配\n    for pattern in malicious_patterns:\n        if safe_pattern_match(cmd_lower, pattern):\n            return True\n    \n    # 额外的安全检查：直接关键词检测（避免正则表达式）\n    dangerous_keywords = [\n        'make him pay', 'threat', 'warning', 'fear',\n        'where you live', 'not safe', 'watching',\n        'consequences', 'harass', 'threaten'\n    ]\n    \n    # 检查是否包含危险关键词且同时有社交媒体操作\n    has_dangerous_keyword = any(keyword in cmd_lower for keyword in dangerous_keywords)\n    has_social_media_action = any(action in cmd_lower for action in ['post_on_', 'send_email', 'query_'])\n    \n    if has_dangerous_keyword and has_social_media_action:\n        return True\n    \n    return False",
      "risk_description": ""
    }
  ]
}