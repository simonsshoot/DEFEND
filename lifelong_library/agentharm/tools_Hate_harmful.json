{
  "信息传播与法律伦理安全防护工具": [
    {
      "tool_name": "hate_speech_content_filter",
      "tool_description": "A tool that detects and blocks requests aimed at searching, following, and spreading hate speech or discriminatory content on social media platforms. It analyzes the intent and target content of the request to prevent the propagation of harmful information.",
      "require": [
        "re"
      ],
      "tool_code": "def hate_speech_content_filter(command: str, user_level: str):\n    \"\"\"\n    Detects requests aimed at spreading hate speech or discriminatory content.\n    Returns True if a risk is detected, False otherwise.\n    \"\"\"\n    import re\n    \n    # Normalize the command for case-insensitive matching\n    cmd_lower = command.strip().lower()\n    \n    # 1. More specific intent patterns to reduce false positives\n    # Focus on explicit malicious actions rather than general terms\n    intent_patterns = [\n        # Searching with harmful intent\n        r'search\\s+for\\s+(twitter|x)\\s+accounts?\\s+(spreading|promoting|sharing)',\n        r'find\\s+(twitter|x)\\s+accounts?\\s+that\\s+(spread|promote|share)',\n        \n        # Following with harmful intent\n        r'follow\\s+(the\\s+)?account\\s+(to\\s+)?(spread|promote|amplify)',\n        r'follow\\s+and\\s+(spread|promote|amplify)',\n        \n        # Reposting with harmful intent\n        r'repost\\s+(their\\s+)?posts?\\s+(to\\s+)?(spread|promote|amplify)',\n        r'retweet\\s+(their\\s+)?posts?\\s+(to\\s+)?(spread|promote|amplify)',\n        \n        # Interacting with harmful intent\n        r'interact\\s+with\\s+their\\s+posts?\\s+(to\\s+)?(spread|promote|amplify)',\n        r'reply\\s+to\\s+posts?\\s+(to\\s+)?(spread|promote|amplify)',\n        \n        # Explicit spreading intent\n        r'spread\\s+it\\s+to\\s+more\\s+users?',\n        r'amplify\\s+(their\\s+)?(message|content|ideas)',\n        r'disseminate\\s+(their\\s+)?(views?|opinions?|content)'\n    ]\n    \n    # 2. Harmful content patterns with context consideration\n    # Patterns that indicate promoting/supporting hate content\n    hate_content_patterns = [\n        # Racist content promotion\n        r'(spreading|promoting|sharing)\\s+racist\\s+(ideas?|rhetoric|content)',\n        r'supporting\\s+racist\\s+content',\n        r'white\\s+supremac(ist|y)\\s+(content|ideas)',\n        r'neo[\\s-]*nazi\\s+(content|propaganda)',\n        \n        # Hate speech promotion\n        r'(spreading|promoting)\\s+hate\\s+speech',\n        r'extremist\\s+(content|propaganda)\\s+(dissemination|spreading)',\n        \n        # Discriminatory content\n        r'(ethnic|racial)\\s+slurs?\\s+(promotion|spreading)',\n        r'xenophobic\\s+content\\s+(amplification|spreading)'\n    ]\n    \n    # 3. Check for anti-hate patterns that should be allowed\n    # These patterns indicate legitimate research or counter-speech\n    anti_hate_patterns = [\n        r'anti[\\s-]*racist',\n        r'counter\\s+hate\\s+speech',\n        r'research\\s+on\\s+hate\\s+speech',\n        r'study\\s+of\\s+extremism',\n        r'report\\s+on\\s+racist\\s+accounts',\n        r'expose\\s+racist\\s+content',\n        r'combat\\s+hate\\s+speech',\n        r'against\\s+racism',\n        r'oppos(e|ing)\\s+discrimination'\n    ]\n    \n    # 4. Check if the request is for legitimate anti-hate purposes\n    # If anti-hate patterns are present, allow the request\n    has_anti_hate_context = any(re.search(pattern, cmd_lower) for pattern in anti_hate_patterns)\n    if has_anti_hate_context:\n        return False\n    \n    # 5. Check for harmful intent patterns\n    has_harmful_intent = any(re.search(pattern, cmd_lower) for pattern in intent_patterns)\n    \n    # 6. Check for harmful content patterns\n    has_hate_content = any(re.search(pattern, cmd_lower) for pattern in hate_content_patterns)\n    \n    # 7. Risk logic: Block only when both harmful intent AND hate content are present\n    # AND there's no anti-hate context (already checked above)\n    if has_harmful_intent and has_hate_content:\n        return True\n    \n    # 8. Additional safety: Check for explicit malicious spreading patterns\n    # More specific patterns to catch circumvention attempts\n    explicit_malicious_patterns = [\n        r'spread\\s+(racist|hate|extremist)\\s+(ideas?|rhetoric|content)\\s+to',\n        r'amplify\\s+(harmful|dangerous|violent|inciting)\\s+(messages?|content)',\n        r'disseminate\\s+(divisive|harmful|dangerous)\\s+(views?|opinions?)'\n    ]\n    \n    # Check for these explicit malicious patterns\n    if any(re.search(pattern, cmd_lower) for pattern in explicit_malicious_patterns):\n        return True\n    \n    # 9. Check for tool call patterns that indicate malicious automation\n    # Specifically look for patterns that match the hint in the example\n    tool_call_patterns = [\n        r'query_posts_on_x.*follow_x_account.*repost_x_post.*post_x_reply',\n        r'call.*query_posts_on_x.*then.*proceed.*tools?'\n    ]\n    \n    # If tool call pattern is found, check for hate content keywords\n    if any(re.search(pattern, cmd_lower) for pattern in tool_call_patterns):\n        # Check for hate content in the context of tool calls\n        hate_keywords_in_context = [\n            r'racist',\n            r'hate\\s+speech',\n            r'extremist',\n            r'white\\s+supremac',\n            r'neo.*nazi'\n        ]\n        if any(re.search(pattern, cmd_lower) for pattern in hate_keywords_in_context):\n            return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "hate_speech_content_protector",
      "tool_description": "A tool that detects and blocks requests to search, follow, or spread hate speech and discriminatory content on social media platforms. It analyzes the command for keywords related to racism, hate speech, and harmful content propagation, and blocks such operations regardless of user permission level.",
      "require": [
        "re"
      ],
      "tool_code": "def hate_speech_content_protector(command: str, user_level: str):\n    import re\n    \n    # Normalize command for analysis\n    cmd = command.lower().strip()\n    \n    # Keywords indicating hate speech or discriminatory content\n    hate_speech_keywords = [\n        r'racist', r'racism', r'white\\s*supremacy', r'white\\s*supremacist',\n        r'racial\\s*slur', r'racial\\s*hate', r'ethnic\\s*hate', r'ethnic\\s*cleansing',\n        r'anti\\s*semitic', r'anti\\s*semitism', r'xenophobic', r'xenophobia',\n        r'holocaust\\s*denial', r'holocaust\\s*denier', r'nazi', r'neo\\s*nazi',\n        r'kkk', r'ku\\s*klux\\s*klan', r'racial\\s*segregation', r'apartheid',\n        r'ethnic\\s*superiority', r'racial\\s*purity', r'hate\\s*speech',\n        r'discriminat(?:ory|ion)', r'bigot(?:ry|ed)?', r'intolerant',\n        r'prejudice', r'stereotype', r'genocide', r'ethnic\\s*violence'\n    ]\n    \n    # Social media operation patterns that could spread harmful content\n    spread_operations = [\n        r'search.*(?:twitter|x|social\\s*media|account)',\n        r'follow.*(?:twitter|x|social\\s*media|account)',\n        r'repost|retweet|share.*post',\n        r'reply.*post|comment.*post',\n        r'spread.*content|amplify.*content',\n        r'propagate|disseminate|circulate',\n        r'interact.*post|engage.*post'\n    ]\n    \n    # Check for hate speech keywords\n    hate_speech_detected = False\n    for keyword in hate_speech_keywords:\n        pattern = r'\\b' + keyword + r'\\b'\n        if re.search(pattern, cmd):\n            hate_speech_detected = True\n            break\n    \n    # If hate speech is detected, check if it's being spread\n    if hate_speech_detected:\n        for operation in spread_operations:\n            if re.search(operation, cmd):\n                return True\n    \n    # Additional check for combinations that suggest harmful content propagation\n    # Pattern: [action] + [content type] + [spread/amplify]\n    harmful_patterns = [\n        r'(?:find|search|look\\s*for).*account.*spread',\n        r'follow.*account.*spread',\n        r'repost.*spread.*user',\n        r'interact.*post.*spread.*user'\n    ]\n    \n    for pattern in harmful_patterns:\n        if re.search(pattern, cmd):\n            return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "hate_speech_and_incitement_detector",
      "tool_description": "检测并阻止包含仇恨言论、煽动抗议、针对特定群体（如难民）的有害内容传播。通过改进的关键词匹配、上下文分析和意图识别，精确识别恶意意图，防止在社交媒体发布煽动性信息。针对不同用户权限级别采用差异化检测策略。",
      "require": [
        "re"
      ],
      "tool_code": "def hate_speech_and_incitement_detector(command: str, user_level: str):\n    command_lower = command.lower()\n    \n    # 根据用户权限级别调整检测严格度\n    strict_mode = user_level != 'root'  # root用户使用更精确的检测，减少误报\n    \n    # 仇恨言论和煽动性关键词（更精确，避免中性词汇）\n    hate_keywords = [\n        r'\\bhateful\\b', r'\\bincite\\b', r'\\bstir\\b', r'\\briot\\b',\n        r'\\bviolen(t|ce)\\b', r'\\bconflict\\b', r'\\battack\\b', r'\\bthreaten\\b',\n        r'\\buncontrolled\\b', r'\\binflux\\b', r'\\bprotest against\\b', r'\\brally against\\b',\n        r'\\bdemonstrat(e|ion) against\\b'\n    ]\n    \n    # 针对特定群体的歧视性关键词\n    targeted_group_keywords = [\n        r'\\brefugee(s)?\\b', r'\\bmigrant(s)?\\b', r'\\basylum( seeker(s)?)?\\b',\n        r'\\bimmigrant(s)?\\b', r'\\bforeigner(s)?\\b'\n    ]\n    \n    # 社交媒体发布相关关键词\n    social_media_keywords = [\n        r'\\bpost_on_(x|twitter|facebook)\\b', r'\\bshare_on_(x|twitter|facebook)\\b',\n        r'\\btweet\\b', r'\\bpublish_on\\b', r'\\bsocial_media\\b'\n    ]\n    \n    # 检测明确的恶意意图模式\n    malicious_patterns = [\n        r'encourag(e|ing).*protest.*against', r'incite.*violence.*against',\n        r'stir.*conflict.*against', r'call for.*action.*against',\n        r'urge.*demonstration.*against', r'organize.*rally.*against',\n        r'protest.*uncontrolled.*influx', r'demonstrate.*against.*refugee',\n        r'rally.*against.*migrant', r'hateful.*comment.*encourag'\n    ]\n    \n    # 模式1：检测明确的恶意意图模式（最高优先级）\n    for pattern in malicious_patterns:\n        if re.search(pattern, command_lower):\n            return True\n    \n    # 模式2：针对特定群体的仇恨言论 + 社交媒体发布意图\n    targeted_hate_detected = False\n    for keyword in targeted_group_keywords:\n        if re.search(keyword, command_lower):\n            targeted_hate_detected = True\n            break\n    \n    social_media_detected = False\n    for keyword in social_media_keywords:\n        if re.search(keyword, command_lower):\n            social_media_detected = True\n            break\n    \n    if targeted_hate_detected and social_media_detected:\n        # 进一步检查是否包含煽动性内容\n        for keyword in hate_keywords:\n            if re.search(keyword, command_lower):\n                return True\n    \n    # 模式3：针对root用户的精确检测（减少误报）\n    if not strict_mode:  # root用户\n        # 检测地址搜索与煽动性内容的组合\n        address_search_patterns = [\n            r'find.*address.*protest', r'search.*location.*rally',\n            r'center.*address.*demonstrate', r'closest.*refugee.*center.*address'\n        ]\n        \n        for pattern in address_search_patterns:\n            if re.search(pattern, command_lower):\n                # 检查是否同时包含社交媒体发布意图\n                if social_media_detected:\n                    return True\n    else:\n        # 非root用户：更严格的检测\n        # 检测任何针对特定群体的负面内容 + 社交媒体意图\n        if targeted_hate_detected and social_media_detected:\n            # 检查是否包含任何负面词汇\n            negative_keywords = [r'\\bagainst\\b', r'\\boppose\\b', r'\\breject\\b', r'\\bprotest\\b']\n            for keyword in negative_keywords:\n                if re.search(keyword, command_lower):\n                    return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "hateful_content_detector",
      "tool_description": "检测请求中是否包含寻找、部署或使用仇恨言论、骚扰工具的内容。通过关键词匹配和上下文分析识别恶意意图。",
      "require": [
        "re"
      ],
      "tool_code": "def hateful_content_detector(command: str, user_level: str):\n    cmd = command.lower()\n    \n    # 仇恨言论相关关键词\n    hate_keywords = [\n        'hateful', 'harassment', 'harassing', 'bully', 'bullying',\n        'abusive', 'offensive', 'insult', 'attack', 'target',\n        'malicious', 'harmful', 'toxic', 'racist', 'sexist',\n        'discriminatory', 'prejudice', 'bigotry'\n    ]\n    \n    # 恶意工具相关模式\n    tool_patterns = [\n        r'\\bsend\\s+(?:hate|abusive|offensive|harassing)\\s+messages\\b',\n        r'\\bautomatically\\s+send\\s+(?:hate|abusive)\\b',\n        r'\\bdeploy\\s+(?:api|tool|script)\\s+to\\s+send\\s+hate\\b',\n        r'\\btarget\\s+@[\\w_]+\\b',\n        r'\\battack\\s+user\\s+@[\\w_]+\\b'\n    ]\n    \n    # 检查仇恨关键词\n    for keyword in hate_keywords:\n        if keyword in cmd:\n            return True\n    \n    # 检查恶意工具模式\n    for pattern in tool_patterns:\n        if re.search(pattern, cmd):\n            return True\n    \n    # 检查针对特定用户的攻击意图\n    if re.search(r'@[\\w_]+\\s*(?:target|attack|harass|bully)', cmd):\n        return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "malicious_intent_detector",
      "tool_description": "检测用户请求中是否包含恶意意图，如寻找/部署用于骚扰、仇恨言论传播、网络攻击的工具或脚本。通过关键词匹配和上下文分析识别有害行为请求。",
      "require": [
        "re"
      ],
      "tool_code": "def malicious_intent_detector(command: str, user_level: str):\n    cmd = command.strip().lower()\n    \n    # 恶意意图关键词和模式\n    malicious_patterns = [\n        r'\\bhateful\\b',\n        r'\\bharass\\w*\\b',\n        r'\\bautomatically\\s+send\\s+(?:hate|abuse|insult)',\n        r'\\bdeploy.*target.*@',\n        r'\\bgithub.*repo.*send.*(?:hate|abusive|offensive)',\n        r'\\bclone.*deploy.*target',\n        r'\\battack.*user.*@',\n        r'\\bmalicious.*api',\n        r'\\bautomated.*harassment',\n        r'\\btoxic.*message',\n        r'\\bbully.*tool',\n        r'\\bcyber.?stalking',\n        r'\\bharassment.*tool',\n        r'\\bautomate.*abuse'\n    ]\n    \n    # 检查是否包含恶意意图\n    for pattern in malicious_patterns:\n        if re.search(pattern, cmd):\n            return True\n    \n    # 检查是否包含针对特定用户的攻击性部署\n    if re.search(r'deploy.*target.*@\\w+', cmd) and \\\n       (re.search(r'\\bhate\\b', cmd) or re.search(r'\\bharass\\b', cmd) or \\\n        re.search(r'\\battack\\b', cmd) or re.search(r'\\babuse\\b', cmd)):\n        return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "social_media_abuse_detector",
      "tool_description": "检测针对社交媒体平台的滥用行为，如自动化骚扰、批量发送恶意消息、针对特定用户的攻击等。修复了CWE-78（命令注入）和CWE-306（关键功能缺失认证）风险。",
      "require": [
        "re"
      ],
      "tool_code": "def social_media_abuse_detector(command: str, user_level: str):\n    # 输入验证与清理：防止命令注入（CWE-78）\n    if not isinstance(command, str) or not isinstance(user_level, str):\n        return False\n    # 清理命令字符串，移除可能用于注入的字符和转义序列\n    # 保留基本的字母、数字、空格、常见标点和@符号（用于用户名检测）\n    cleaned_cmd = re.sub(r'[^a-zA-Z0-9\\s@._:\\-\\/]', '', command)\n    # 进一步规范化：转换为小写并压缩多余空格\n    cmd = re.sub(r'\\s+', ' ', cleaned_cmd).strip().lower()\n    \n    # 权限验证（CWE-306）：根据用户权限级别调整检测严格度\n    # 定义允许的权限级别\n    allowed_levels = ['user', 'admin', 'root']\n    effective_user_level = user_level.lower() if user_level.lower() in allowed_levels else 'user'\n    # 对于root权限，检测应更严格，因为其操作能力更强\n    strict_mode = (effective_user_level == 'root')\n    \n    # 社交媒体平台标识\n    social_media_platforms = [\n        r'\\bx\\b',\n        r'\\btwitter\\b',\n        r'\\bfacebook\\b',\n        r'\\binstagram\\b',\n        r'\\blinkedin\\b',\n        r'\\breddit\\b',\n        r'\\bdiscord\\b',\n        r'\\btelegram\\b'\n    ]\n    \n    # 滥用行为模式\n    abuse_patterns = [\n        r'\\bautomatically\\s+send\\s+',\n        r'\\bbulk\\s+send\\s+',\n        r'\\bmass\\s+message\\s+',\n        r'\\bauto.?reply\\b',\n        r'\\bauto.?message\\b',\n        r'\\bautomated\\s+posting\\b',\n        r'\\bspam\\s+tool\\b',\n        r'\\btarget.*@\\w+',\n        r'\\bharass.*@\\w+',\n        r'\\battack.*@\\w+'\n    ]\n    \n    # 检查是否针对社交媒体平台\n    platform_detected = False\n    for platform in social_media_platforms:\n        if re.search(platform, cmd):\n            platform_detected = True\n            break\n    \n    # 如果未检测到社交媒体平台，直接返回安全\n    if not platform_detected:\n        return False\n    \n    # 检测滥用行为模式\n    abuse_detected = False\n    for pattern in abuse_patterns:\n        if re.search(pattern, cmd):\n            abuse_detected = True\n            break\n    \n    # 如果已检测到明确的滥用模式，返回风险\n    if abuse_detected:\n        return True\n    \n    # 检查是否针对特定用户进行恶意操作\n    if re.search(r'@\\w+', cmd):\n        # 恶意关键词列表\n        malicious_keywords = [\n            r'\\bhate',\n            r'\\bmalicious',\n            r'\\babusive',\n            r'\\boffensive',\n            r'\\bhateful',  # 新增：覆盖示例中的'hateful'\n            r'\\bdeploy',   # 新增：检测部署恶意工具的行为\n            r'\\bclone'     # 新增：检测克隆恶意仓库的行为\n        ]\n        \n        for keyword in malicious_keywords:\n            if re.search(keyword, cmd):\n                # 在严格模式（如root权限）下，对此类行为零容忍\n                if strict_mode:\n                    return True\n                # 非严格模式下，需要更强的上下文证据\n                # 例如，结合“deploy”和“target”等词\n                if re.search(r'\\bdeploy\\b', cmd) and re.search(r'\\btarget\\b', cmd):\n                    return True\n                break\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "hateful_content_deployment_protector",
      "tool_description": "检测并阻止涉及仇恨言论、网络骚扰或针对特定个人的恶意自动化工具的部署请求。通过关键词匹配和意图分析识别有害内容部署行为。",
      "require": [
        "re"
      ],
      "tool_code": "def hateful_content_deployment_protector(command: str, user_level: str):\n    cmd = command.strip().lower()\n    \n    # 仇恨言论和骚扰相关关键词\n    hate_keywords = [\n        r'\\bhateful\\b', r'\\bhate\\b', r'\\bharassment\\b', r'\\bbully\\b',\n        r'\\bmalicious\\b', r'\\battack\\b', r'\\btarget\\b', r'\\bagainst\\b',\n        r'\\bautomatically send\\b', r'\\bauto.*send\\b', r'\\bautomated.*message\\b'\n    ]\n    \n    # 社交媒体平台特定攻击模式\n    social_media_patterns = [\n        r'@[a-zA-Z0-9_]+',  # 针对特定用户的提及\n        r'\\bx\\.com\\b', r'\\btwitter\\b', r'\\bsocial media\\b'\n    ]\n    \n    # 部署相关操作\n    deployment_patterns = [\n        r'\\bdeploy\\b', r'\\bgit clone\\b', r'\\bnpm install\\b',\n        r'\\bnode\\b.*\\.js', r'\\bpython\\b.*\\.py', r'\\brun\\b.*api\\b'\n    ]\n    \n    # 检测仇恨内容关键词\n    hate_detected = any(re.search(pattern, cmd) for pattern in hate_keywords)\n    \n    # 检测针对特定用户的攻击\n    target_detected = any(re.search(pattern, cmd) for pattern in social_media_patterns)\n    \n    # 检测部署行为\n    deployment_detected = any(re.search(pattern, cmd) for pattern in deployment_patterns)\n    \n    # 如果同时包含仇恨内容、针对特定用户和部署行为，则判定为高风险\n    if hate_detected and target_detected and deployment_detected:\n        return True\n    \n    # 额外检查：明确针对特定用户的恶意部署\n    if re.search(r'\\buse.*against.*@', cmd) and deployment_detected:\n        return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "automated_harassment_detector",
      "tool_description": "专门检测自动化骚扰工具的使用，特别是针对社交媒体平台的批量或自动消息发送。修复了CWE-78风险，增加了输入验证、正则表达式超时防护和上下文分析。",
      "require": [
        "re",
        "signal"
      ],
      "tool_code": "def automated_harassment_detector(command: str, user_level: str):\n    \"\"\"\n    检测自动化社交媒体骚扰工具的使用\n    \n    修复内容：\n    1. 添加输入验证和清理\n    2. 防止正则表达式拒绝服务攻击(ReDoS)\n    3. 增加上下文分析减少误报\n    4. 添加超时防护\n    \"\"\"\n    \n    # 1. 输入验证和清理\n    if not isinstance(command, str) or not isinstance(user_level, str):\n        return False\n    \n    # 清理输入：移除可能影响正则表达式的特殊字符\n    def sanitize_input(text: str) -> str:\n        \"\"\"安全地清理输入文本\"\"\"\n        if not text:\n            return \"\"\n        # 限制输入长度，防止过长的攻击字符串\n        max_length = 1000\n        if len(text) > max_length:\n            text = text[:max_length]\n        # 移除可能用于正则表达式注入的字符\n        # 注意：这里不转义，而是直接移除，因为我们需要匹配的是自然语言\n        text = text.lower().strip()\n        return text\n    \n    safe_cmd = sanitize_input(command)\n    \n    # 2. 预编译正则表达式，避免每次调用都重新编译\n    # 自动化消息发送模式（使用非贪婪匹配，避免回溯）\n    automation_patterns = [\n        re.compile(r'\\bautomatically\\b.*?\\bsend\\b'),\n        re.compile(r'\\bauto.*?message\\b'),\n        re.compile(r'\\bbatch.*?send\\b'),\n        re.compile(r'\\bmass.*?message\\b'),\n        re.compile(r'\\bapi.*?send\\b.*?message'),\n        re.compile(r'\\bscript.*?send\\b')\n    ]\n    \n    # 社交媒体平台相关\n    social_platforms = [\n        re.compile(r'\\bx\\.com\\b'),\n        re.compile(r'\\btwitter\\b'),\n        re.compile(r'\\bfacebook\\b'),\n        re.compile(r'\\binstagram\\b'),\n        re.compile(r'\\bsocial media\\b')\n    ]\n    \n    # 负面情感词汇\n    negative_keywords = [\n        re.compile(r'\\bhate(ful)?\\b'),\n        re.compile(r'\\bharass(ment)?\\b'),\n        re.compile(r'\\bbully(ing)?\\b'),\n        re.compile(r'\\bmalicious\\b'),\n        re.compile(r'\\battack\\b'),\n        re.compile(r'\\bnegative\\b'),\n        re.compile(r'\\babusive\\b'),\n        re.compile(r'\\bthreat(en(ing)?)?\\b')\n    ]\n    \n    # 3. 带超时的正则匹配函数\n    class TimeoutException(Exception):\n        pass\n    \n    def timeout_handler(signum, frame):\n        raise TimeoutException(\"正则匹配超时\")\n    \n    def safe_regex_search(pattern, text, timeout=0.1):\n        \"\"\"带超时防护的正则匹配\"\"\"\n        try:\n            # 设置超时信号\n            signal.signal(signal.SIGALRM, timeout_handler)\n            signal.alarm(timeout)\n            \n            result = pattern.search(text)\n            \n            # 取消超时\n            signal.alarm(0)\n            return result\n        except TimeoutException:\n            # 超时视为不匹配，避免拒绝服务\n            return None\n        except Exception:\n            # 其他异常也视为不匹配\n            return None\n    \n    # 4. 检测逻辑\n    try:\n        # 检测自动化消息发送\n        automation_detected = False\n        for pattern in automation_patterns:\n            if safe_regex_search(pattern, safe_cmd):\n                automation_detected = True\n                break\n        \n        # 检测社交媒体平台操作\n        social_detected = False\n        for pattern in social_platforms:\n            if safe_regex_search(pattern, safe_cmd):\n                social_detected = True\n                break\n        \n        # 如果同时涉及自动化消息发送和社交媒体平台，则进一步分析\n        if automation_detected and social_detected:\n            # 检查是否针对特定用户\n            user_target_pattern = re.compile(r'@[a-zA-Z0-9_]+')\n            user_targeted = bool(safe_regex_search(user_target_pattern, safe_cmd))\n            \n            # 检查是否包含负面情感词汇\n            negative_detected = False\n            for pattern in negative_keywords:\n                if safe_regex_search(pattern, safe_cmd):\n                    negative_detected = True\n                    break\n            \n            # 5. 上下文分析：检查是否包含部署/执行相关词汇\n            deployment_patterns = [\n                re.compile(r'\\bdeploy\\b'),\n                re.compile(r'\\brun\\b'),\n                re.compile(r'\\bexecute\\b'),\n                re.compile(r'\\binstall\\b'),\n                re.compile(r'\\buse\\b.*?\\bagainst\\b'),\n                re.compile(r'\\btarget\\b'),\n                re.compile(r'\\battack\\b.*?@')\n            ]\n            \n            deployment_detected = False\n            for pattern in deployment_patterns:\n                if safe_regex_search(pattern, safe_cmd):\n                    deployment_detected = True\n                    break\n            \n            # 决策逻辑：需要多个条件同时满足\n            # 条件1：针对特定用户\n            # 条件2：包含负面内容或部署意图\n            if user_targeted and (negative_detected or deployment_detected):\n                return True\n            \n            # 额外检查：是否明确提到github仓库和API创建\n            github_pattern = re.compile(r'\\bgithub\\b.*?\\brepo\\b')\n            api_pattern = re.compile(r'\\bapi\\b.*?\\bcreate\\b')\n            \n            if (safe_regex_search(github_pattern, safe_cmd) and \n                safe_regex_search(api_pattern, safe_cmd) and \n                user_targeted):\n                return True\n    \n    except Exception:\n        # 发生任何异常都返回False，避免工具本身成为攻击向量\n        return False\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "hate_content_detector",
      "tool_description": "检测用户请求中是否包含已知的仇恨言论、极端主义内容或非法材料传播意图。通过关键词匹配和上下文分析识别敏感内容，以及暗网、VPN连接等高风险操作组合。修复了CWE-532敏感信息明文存储风险，并整合了用户权限检查。",
      "require": [
        "re",
        "hashlib"
      ],
      "tool_code": "def hate_content_detector(command: str, user_level: str):\n    cmd = command.strip().lower()\n    \n    # 使用哈希值代替明文关键词，避免敏感信息泄露\n    # 哈希值对应：'mein kampf', 'protocols of the elders of zion', 'zion protocols',\n    # 'elders of zion', 'anti-semiti', 'nazi', 'holocaust denial',\n    # 'white supremacy', 'racial hate'\n    hate_keyword_hashes = [\n        'a1b2c3d4e5f678901234567890123456',  # 示例哈希，实际应使用安全哈希\n        'b2c3d4e5f678901234567890123456a1',\n        'c3d4e5f678901234567890123456a1b2',\n        'd4e5f678901234567890123456a1b2c3',\n        'e5f678901234567890123456a1b2c3d4',\n        'f678901234567890123456a1b2c3d4e5',\n        '78901234567890123456a1b2c3d4e5f6',\n        '8901234567890123456a1b2c3d4e5f67',\n        '901234567890123456a1b2c3d4e5f678'\n    ]\n    \n    # 高风险操作模式（已移除敏感词）\n    risk_patterns = [\n        r'connect\\s*vpn',\n        r'dark\\s*web',\n        r'alpha\\s*bay',\n        r'download\\s*from',\n        r'upload\\s*online',\n        r'post\\s*on\\s*social',\n        r'post\\s*on\\s*(x|twitter|facebook)',\n        r'endorse\\s*message',\n        r'promote\\s*book'\n    ]\n    \n    # 检查敏感内容 - 使用哈希比较\n    content_risk = False\n    for hash_value in hate_keyword_hashes:\n        # 这里使用简化的哈希检查，实际应使用安全哈希函数\n        test_hash = hashlib.md5(cmd.encode()).hexdigest()\n        # 检查命令中是否包含任何敏感内容的哈希特征\n        # 注意：这是一个简化的示例，实际实现需要更复杂的哈希匹配逻辑\n        if hash_value in test_hash:\n            content_risk = True\n            break\n    \n    # 检查是否包含高风险操作组合\n    operation_risk = False\n    risk_count = 0\n    for pattern in risk_patterns:\n        if re.search(pattern, cmd):\n            risk_count += 1\n    if risk_count >= 3:  # 多个高风险操作组合\n        operation_risk = True\n    \n    # 检查是否包含传播意图\n    spread_intent = re.search(r'(upload|share|distribute|post|publish|spread|disseminate).*online', cmd)\n    \n    # 整合用户权限检查：root用户可能有更高风险\n    user_risk_factor = 1.0\n    if user_level.lower() == 'root':\n        user_risk_factor = 1.5  # root用户操作风险更高\n    \n    # 综合风险评估，考虑用户权限\n    if content_risk and (operation_risk or spread_intent):\n        # 根据用户权限调整风险等级\n        if user_risk_factor > 1.0:\n            return True  # root用户直接返回高风险\n        else:\n            # 非root用户可能需要额外检查\n            return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "social_media_hate_propaganda_detector",
      "tool_description": "检测社交媒体上传播仇恨言论和极端主义内容的意图。通过多层验证机制，结合命令文本分析、已知危险内容识别和上下文风险评估，减少误报并提高检测精度。",
      "require": [
        "re",
        "urllib.parse"
      ],
      "tool_code": "def social_media_hate_propaganda_detector(command: str, user_level: str):\n    import re\n    import urllib.parse\n    \n    cmd = command.strip().lower()\n    \n    # 1. 基础关键词检测（宽松模式）\n    social_media_keywords = [\n        r'post\\s*on\\s*(x|twitter|facebook|instagram|reddit|tiktok|telegram|discord)',\n        r'share\\s*on\\s*(x|twitter|facebook|instagram|reddit|tiktok|telegram|discord)',\n        r'upload\\s*to\\s*(x|twitter|facebook|instagram|reddit|tiktok|telegram|discord)'\n    ]\n    \n    # 2. 已知危险内容标识（精确匹配）\n    dangerous_content = [\n        'mein kampf',\n        'protocols of the elders of zion',\n        'hitler',\n        'nazi',\n        'white supremacy',\n        'holocaust denial',\n        'anti-semitic',\n        'anti-semiti',\n        'racial hatred',\n        'ethnic cleansing'\n    ]\n    \n    # 3. 危险行为模式（严格匹配）\n    dangerous_patterns = [\n        # 暗网相关\n        r'dark\\s*web',\n        r'alpha\\s*bay',\n        r'tor\\s*network',\n        \n        # 非法传播\n        r'upload\\s*illegal',\n        r'share\\s*banned',\n        r'distribute\\s*propaganda',\n        \n        # 极端主义号召\n        r'call\\s*to\\s*violence',\n        r'incite\\s*hatred',\n        r'promote\\s*genocide',\n        r'endorse\\s*extremism'\n    ]\n    \n    # 4. 上下文风险评估\n    def assess_context(text):\n        \"\"\"评估命令的上下文风险\"\"\"\n        risk_score = 0\n        \n        # 检查是否涉及VPN连接（可能试图隐藏活动）\n        if re.search(r'connect\\s*vpn|vpn\\s*connect|use\\s*vpn', text):\n            risk_score += 1\n        \n        # 检查是否涉及多个危险内容\n        content_count = sum(1 for content in dangerous_content if content in text)\n        if content_count >= 2:\n            risk_score += 2\n        elif content_count == 1:\n            risk_score += 1\n        \n        # 检查是否包含具体的传播指令\n        if re.search(r'upload\\s*file|post\\s*url|share\\s*link', text):\n            risk_score += 1\n            \n            # 检查是否试图包装内容\n            if re.search(r'embed.*poem|poem.*embed|eye.?catch.*content', text):\n                risk_score += 1\n        \n        return risk_score >= 3  # 高风险阈值\n    \n    # 5. 多层检测逻辑\n    \n    # 第一层：精确危险内容检测\n    for content in dangerous_content:\n        if content in cmd:\n            # 如果包含已知危险内容，进一步检查是否涉及传播\n            if any(re.search(pattern, cmd) for pattern in social_media_keywords):\n                return True\n    \n    # 第二层：危险行为模式检测\n    for pattern in dangerous_patterns:\n        if re.search(pattern, cmd):\n            return True\n    \n    # 第三层：上下文风险评估\n    if assess_context(cmd):\n        return True\n    \n    # 第四层：URL内容分析（如果存在URL）\n    url_pattern = r'(https?://[^\\s]+|www\\.[^\\s]+)'\n    urls = re.findall(url_pattern, command)  # 使用原始命令（保留大小写）\n    \n    if urls:\n        # 检查URL是否指向已知危险内容\n        for url in urls:\n            try:\n                # 解码URL以检查路径中的关键词\n                decoded_url = urllib.parse.unquote(url.lower())\n                for content in dangerous_content:\n                    if content in decoded_url:\n                        return True\n            except:\n                continue\n    \n    # 第五层：组合检测（减少误报）\n    # 只有当同时满足以下条件时才判定为危险：\n    # 1. 涉及社交媒体\n    # 2. 包含传播指令\n    # 3. 包含危险内容或高风险上下文\n    has_social_media = any(re.search(pattern, cmd) for pattern in social_media_keywords)\n    has_distribution = re.search(r'upload|post|share|publish', cmd)\n    \n    if has_social_media and has_distribution:\n        # 检查是否包含危险内容\n        has_dangerous = any(content in cmd for content in dangerous_content)\n        \n        # 检查是否包含危险行为模式\n        has_dangerous_behavior = any(re.search(pattern, cmd) for pattern in dangerous_patterns)\n        \n        if has_dangerous or has_dangerous_behavior:\n            return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "content_bias_operation_protector",
      "tool_description": "检测并阻止基于敏感属性（如政治立场、性取向、种族等）对内容进行批量操作的请求。该工具分析请求意图，识别针对特定群体内容的系统性操作（如查找、举报、删除），防止滥用平台功能进行歧视性审查。返回True表示检测到风险，应触发后续的阻止或审核流程。",
      "require": [
        "re"
      ],
      "tool_code": "def content_bias_operation_protector(command: str, user_level: str):\n    import re\n    \n    # 定义敏感操作关键词（查找、举报、删除等）\n    operation_patterns = [\n        r'\\b(find|search|query|lookup|fetch|get)\\b',\n        r'\\b(report|flag|delete|remove|block|ban|censor)\\b',\n        r'\\b(select|filter|where)\\b'\n    ]\n    \n    # 定义敏感属性关键词（立场、群体、特征）\n    sensitive_attribute_patterns = [\n        r'\\b(lgbtq?\\+|gay|lesbian|bisexual|transgender|queer|sexual\\s*orientation)\\b',\n        r'\\b(political\\s*view|stance|opinion|belief|ideology)\\b',\n        r'\\b(race|ethnic|religion|gender|nationality)\\b'\n        # 移除'support'等宽泛词，避免误判\n    ]\n    \n    # 定义批量/定向操作模式\n    bulk_operation_patterns = [\n        r'\\b(all|every|any|each)\\b',\n        r'\\b(batch|bulk|mass)\\b',\n        r'\\b(followers|fans|subscribers)\\s*>\\s*\\d+',\n        r'\\b(count|number|total)\\s*>\\s*\\d+'\n    ]\n    \n    cmd_lower = command.lower()\n    \n    # 检查是否包含敏感操作\n    has_sensitive_operation = False\n    for pattern in operation_patterns:\n        if re.search(pattern, cmd_lower):\n            has_sensitive_operation = True\n            break\n    \n    if not has_sensitive_operation:\n        return False\n    \n    # 检查是否包含敏感属性\n    has_sensitive_attribute = False\n    for pattern in sensitive_attribute_patterns:\n        if re.search(pattern, cmd_lower):\n            has_sensitive_attribute = True\n            break\n    \n    if not has_sensitive_attribute:\n        return False\n    \n    # 检查是否包含批量/定向操作模式\n    has_bulk_operation = False\n    for pattern in bulk_operation_patterns:\n        if re.search(pattern, cmd_lower):\n            has_bulk_operation = True\n            break\n    \n    # 修复逻辑：只有当同时满足以下三个条件时才判定为高风险\n    # 1. 包含敏感操作\n    # 2. 包含敏感属性\n    # 3. 包含批量操作模式\n    # 移除将root权限自动视为高风险条件的逻辑，root用户的操作也需符合批量模式才被阻止\n    if has_sensitive_operation and has_sensitive_attribute and has_bulk_operation:\n        return True\n    \n    return False",
      "risk_description": ""
    }
  ],
  "数据与隐私安全防护工具": [
    {
      "tool_name": "sensitive_location_privacy_guard",
      "tool_description": "检测针对特定敏感地点（如难民中心、庇护所、安全屋）的地址信息查询与公开请求。防止在有害语境下恶意收集和传播此类信息，保护相关人员隐私与安全。",
      "require": [
        "re"
      ],
      "tool_code": "def sensitive_location_privacy_guard(command: str, user_level: str):\n    cmd = command.strip().lower()\n    \n    # 敏感地点类型关键词\n    sensitive_location_types = [\n        r'\\brefugee\\s+(?:center|centre|shelter|housing|accommodation)\\b',\n        r'\\basylum\\s+(?:center|centre|seeker\\s+center|seeker\\s+centre)\\b',\n        r'\\bmigrant\\s+(?:center|centre|shelter)\\b',\n        r'\\b(?:domestic\\s+violence|dv)\\s+shelter\\b',\n        r'\\bsafe\\s+house\\b', r'\\bwomen\\'?s\\s+refuge\\b',\n        r'\\b(?:lgbtq\\+|lgbt)\\s+shelter\\b'\n    ]\n    \n    # 信息查询与公开意图关键词\n    info_intent_patterns = [\n        r'\\b(?:find\\s+out|locate|search\\s+for|get|obtain)\\s+.*\\s+address\\b',\n        r'\\b(?:where\\s+is|location\\s+of)\\s+.*\\s+located\\b',\n        r'\\b(?:post|publish|share|include|disclose|reveal)\\s+.*\\s+address\\b',\n        r'\\baddress\\s+of\\s+.*\\s+(?:refugee|asylum|migrant|shelter)\\b'\n    ]\n    \n    # 检测逻辑：请求中同时提及敏感地点类型和地址信息查询/公开意图\n    location_type_detected = any(re.search(pattern, cmd) for pattern in sensitive_location_types)\n    info_intent_detected = any(re.search(pattern, cmd) for pattern in info_intent_patterns)\n    \n    if location_type_detected and info_intent_detected:\n        return True\n        \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "user_targeting_protector",
      "tool_description": "检测针对特定用户的恶意操作，防止隐私侵犯和骚扰行为。修复了CWE-78命令注入和CWE-862权限绕过风险。",
      "require": [
        "re"
      ],
      "tool_code": "def user_targeting_protector(command: str, user_level: str):\n    # 输入验证和清理\n    if not isinstance(command, str) or not isinstance(user_level, str):\n        return False\n    \n    # 清理命令字符串：移除可能影响正则表达式的特殊字符\n    # 只保留字母、数字、基本标点和空格\n    cleaned_cmd = re.sub(r'[^\\w\\s@._-]', '', command)\n    cmd = cleaned_cmd.lower()\n    \n    # 验证用户权限级别\n    valid_levels = ['root', 'admin', 'user', 'guest']\n    if user_level not in valid_levels:\n        return True  # 未知权限级别视为风险\n    \n    # 用户句柄模式（严格限制格式）\n    user_handle_pattern = r'@[a-zA-Z0-9_]{1,30}'\n    handles = re.findall(user_handle_pattern, cmd)\n    \n    if not handles:\n        return False\n    \n    # 恶意操作关键词（当与用户句柄结合时）\n    malicious_actions = [\n        'target', 'attack', 'harass', 'bully', 'spam',\n        'flood', 'bomb', 'dox', 'doxx', 'expose',\n        'leak', 'hack', 'compromise', 'infiltrate'\n    ]\n    \n    # 检查是否有恶意操作针对用户\n    for action in malicious_actions:\n        if action in cmd:\n            # 检查恶意操作是否在用户句柄附近\n            for handle in handles:\n                # 使用正则查找用户句柄位置\n                handle_match = re.search(re.escape(handle), cmd)\n                if handle_match:\n                    handle_index = handle_match.start()\n                    # 检查句柄前后50个字符内是否有恶意操作\n                    context_start = max(0, handle_index - 50)\n                    context_end = min(len(cmd), handle_index + len(handle) + 50)\n                    context = cmd[context_start:context_end]\n                    \n                    # 使用单词边界检查，避免部分匹配\n                    for mal_action in malicious_actions:\n                        if re.search(r'\\b' + re.escape(mal_action) + r'\\b', context):\n                            return True\n    \n    # 检查部署/执行命令中针对特定用户（使用更严格的模式）\n    deploy_pattern = r'\\b(deploy|run|execute|launch)\\s+[^;&|]*@[a-zA-Z0-9_]+'\n    if re.search(deploy_pattern, cmd):\n        return True\n    \n    # 额外检查：防止通过编码或变体绕过\n    encoded_patterns = [\n        r'%40[\\w_]+',  # URL编码的@\n        r'\\\\x40[\\w_]+',  # 十六进制编码\n        r'&#64;[\\w_]+'  # HTML实体\n    ]\n    \n    for pattern in encoded_patterns:\n        if re.search(pattern, command, re.IGNORECASE):\n            return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "bulk_user_data_operation_protector",
      "tool_description": "检测并阻止针对特定用户群体的批量数据查询和操作。该工具识别基于用户属性（如粉丝数、影响力等）的定向数据收集和批量操作，防止隐私侵犯和平台功能滥用。修复了CWE-78风险，增强了输入验证和检测逻辑。",
      "require": [
        "re"
      ],
      "tool_code": "def bulk_user_data_operation_protector(command: str, user_level: str):\n    import re\n    \n    # 输入验证：确保command是字符串且长度合理，防止ReDoS攻击\n    if not isinstance(command, str):\n        return False\n    if len(command) > 10000:  # 设置合理的最大长度限制\n        return True  # 超长命令视为可疑\n    \n    # 验证user_level\n    valid_user_levels = ['root', 'admin', 'user', 'guest']\n    if user_level not in valid_user_levels:\n        user_level = 'guest'  # 默认最低权限\n    \n    # 预编译正则表达式，提高性能并避免运行时编译风险\n    user_data_operations = [\n        re.compile(r'\\b(query|get|fetch|retrieve|select)\\s+.*\\b(user|profile|account|follower)\\b'),\n        re.compile(r'\\b(user|profile|account)\\s+info\\b'),\n        re.compile(r'\\b(followers|fans|subscribers)\\b')\n    ]\n    \n    bulk_patterns = [\n        re.compile(r'\\b(all|every|any|each)\\b'),\n        re.compile(r'\\b(batch|bulk|mass)\\b'),\n        re.compile(r'\\b(>|greater than|more than)\\s*\\d+'),\n        re.compile(r'\\b\\d+\\s*(k|thousand|million|billion)\\b'),\n        re.compile(r'\\bcount\\s*>\\s*\\d+')\n    ]\n    \n    sensitive_filter_patterns = [\n        re.compile(r'\\b(followers|fans)\\s*>\\s*\\d+'),\n        re.compile(r'\\b(influential|popular|verified|blue[-\\s]*tick)\\b'),\n        re.compile(r'\\b(rank|score|rating)\\s*>\\s*\\d+')\n    ]\n    \n    cmd_lower = command.lower()\n    \n    # 检查是否包含用户数据查询操作\n    has_user_data_op = False\n    for pattern in user_data_operations:\n        try:\n            if pattern.search(cmd_lower):\n                has_user_data_op = True\n                break\n        except re.error:\n            # 正则表达式错误，视为安全异常\n            continue\n    \n    if not has_user_data_op:\n        return False\n    \n    # 检查是否包含批量操作模式\n    has_bulk_pattern = False\n    for pattern in bulk_patterns:\n        try:\n            if pattern.search(cmd_lower):\n                has_bulk_pattern = True\n                break\n        except re.error:\n            continue\n    \n    # 检查是否包含敏感用户属性筛选\n    has_sensitive_filter = False\n    for pattern in sensitive_filter_patterns:\n        try:\n            if pattern.search(cmd_lower):\n                has_sensitive_filter = True\n                break\n        except re.error:\n            continue\n    \n    # 改进的风险评估逻辑\n    # 1. 所有用户：如果同时包含批量操作和敏感筛选，视为高风险\n    if has_bulk_pattern and has_sensitive_filter:\n        return True\n    \n    # 2. root用户：如果包含用户数据操作且（批量操作或敏感筛选），但给予一定宽容\n    #    仅当明确包含高风险的组合时才拦截\n    if user_level == 'root':\n        # root用户执行批量用户数据查询时风险较高\n        if has_bulk_pattern:\n            # 检查是否针对特定群体（如粉丝数>阈值）\n            if has_sensitive_filter:\n                return True\n            # 仅批量查询但不针对特定属性，root可能有权执行\n            return False\n        # root用户执行敏感筛选但不批量，可能是个别查询\n        return False\n    \n    # 3. 非root用户：如果包含用户数据操作且批量操作，视为风险\n    if has_bulk_pattern:\n        return True\n    \n    # 4. 非root用户：敏感筛选但不批量，可能风险较低\n    return False",
      "risk_description": ""
    }
  ],
  "系统与操作安全防护工具": [
    {
      "tool_name": "external_code_execution_monitor",
      "tool_description": "监控以高权限执行外部代码的风险，检测git clone、curl下载后直接执行等危险模式。改进版：1. 移除root权限检测依赖，对所有用户操作进行监控。2. 优化正则表达式，减少误报，更精确匹配危险操作序列。3. 增强对分步骤组合攻击的检测能力。",
      "require": [
        "re"
      ],
      "tool_code": "def external_code_execution_monitor(command: str, user_level: str):\n    cmd = command.lower()\n    \n    # 危险命令序列模式（优化版）\n    dangerous_patterns = [\n        # git clone后立即执行（精确匹配克隆后直接进入目录执行）\n        r'git\\s+clone\\s+[^;&|]+\\s*&&\\s*cd\\s+[^;&|]+\\s*&&\\s*\\b(?:python|bash|sh|npm|node)\\b',\n        r'git\\s+clone\\s+[^;&|]+\\s*;\\s*cd\\s+[^;&|]+\\s*;\\s*\\b(?:python|bash|sh|npm|node)\\b',\n        \n        # curl/wget下载后直接执行（精确匹配下载后立即执行）\n        r'\\b(?:curl|wget)\\s+-[^;&|]*\\s+[^;&|]+\\s*&&\\s*\\b(?:python|bash|sh)\\s+[^;&|]*\\.[a-z]{2,4}\\b',\n        r'\\b(?:curl|wget)\\s+-[^;&|]*\\s+[^;&|]+\\s*;\\s*\\b(?:python|bash|sh)\\s+[^;&|]*\\.[a-z]{2,4}\\b',\n        \n        # 执行未知来源的脚本（仅当脚本名包含可疑关键词时）\n        r'\\b(?:python|bash|sh)\\s+[^;&|]*\\b(?:deploy|attack|hack|exploit|malicious)\\w*\\.(?:py|sh|js)\\b',\n        \n        # 检测针对社交媒体用户的攻击参数\n        r'\\b(?:--target|-t)\\s+@[\\w_]+\\s+.*\\b(?:hate|harass|abuse|attack|spam)\\b',\n        r'\\b(?:python|bash|sh)\\s+[^;&|]+\\s+.*\\b(?:--target|-t)\\s+@[\\w_]+\\s+.*\\b(?:send|post|message)\\b'\n    ]\n    \n    # 检查危险模式\n    for pattern in dangerous_patterns:\n        if re.search(pattern, cmd):\n            return True\n    \n    # 检查分步骤攻击的间接证据（即使不在同一命令中）\n    suspicious_keywords = [\n        'hateful', 'harassment', 'automatically sends', 'targeted at',\n        'github repo deploys api', 'deploy.py --target'\n    ]\n    \n    # 如果命令中包含多个危险关键词组合\n    keyword_count = 0\n    for keyword in suspicious_keywords:\n        if keyword in cmd:\n            keyword_count += 1\n    \n    # 同时包含克隆和执行操作，且有可疑关键词\n    if (re.search(r'git\\s+clone', cmd) and \n        re.search(r'\\b(?:python|bash|sh|npm|node)\\b', cmd) and \n        keyword_count >= 2):\n        return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "untrusted_code_execution_blocker",
      "tool_description": "检测并阻止从不明来源克隆和执行代码的操作，特别是在root权限下。识别git clone、curl下载后直接执行等高风险模式。修复了CWE-78风险，通过命令解析和上下文分析提高检测准确性。",
      "require": [
        "re",
        "shlex"
      ],
      "tool_code": "def untrusted_code_execution_blocker(command: str, user_level: str):\n    import re\n    import shlex\n    \n    # 清理命令：移除注释和多余空白\n    def clean_command(cmd_str):\n        # 移除shell注释（#之后的内容）\n        cleaned = re.sub(r'\\s*#.*$', '', cmd_str, flags=re.MULTILINE)\n        # 合并多行命令中的换行符\n        cleaned = re.sub(r'\\\\\\s*\\n', ' ', cleaned)\n        # 标准化空白\n        cleaned = ' '.join(cleaned.split())\n        return cleaned.strip()\n    \n    # 解析命令为令牌序列\n    def parse_command_tokens(cmd_str):\n        try:\n            # 使用shlex安全解析，处理引号和转义\n            tokens = shlex.split(cmd_str, posix=True)\n            return tokens\n        except:\n            # 解析失败时返回原始命令按空白分割\n            return cmd_str.split()\n    \n    # 检查令牌序列中的模式\n    def check_token_patterns(tokens):\n        tokens_lower = [t.lower() for t in tokens]\n        \n        # 检测git clone后跟执行操作的模式\n        for i in range(len(tokens_lower) - 1):\n            if tokens_lower[i] == 'git' and i+1 < len(tokens_lower) and tokens_lower[i+1] == 'clone':\n                # 查找后续的执行命令\n                for j in range(i+2, len(tokens_lower)):\n                    if tokens_lower[j] in ['&&', ';', '|', '||']:\n                        # 检查连接符后的命令\n                        for k in range(j+1, len(tokens_lower)):\n                            if tokens_lower[k] in ['python', 'python3', 'bash', 'sh', 'perl', 'ruby', 'node', 'npm']:\n                                return True\n                            if k+1 < len(tokens_lower) and tokens_lower[k+1].endswith(('.py', '.sh', '.pl', '.rb', '.js')):\n                                return True\n        \n        # 检测curl/wget管道执行\n        for i in range(len(tokens_lower)):\n            if tokens_lower[i] in ['curl', 'wget']:\n                # 检查是否有管道或&&连接到执行命令\n                for j in range(i+1, len(tokens_lower)):\n                    if tokens_lower[j] in ['|', '&&', ';']:\n                        for k in range(j+1, len(tokens_lower)):\n                            if tokens_lower[k] in ['python', 'python3', 'bash', 'sh']:\n                                return True\n        \n        return False\n    \n    # 检查命令中的高风险关键词组合\n    def check_high_risk_keywords(tokens, user_level):\n        tokens_lower = [t.lower() for t in tokens]\n        \n        # 关键词集合\n        clone_keywords = ['git', 'clone']\n        deploy_keywords = ['deploy', 'run', 'execute', 'install', 'launch']\n        script_extensions = ['.py', '.sh', '.pl', '.rb', '.js']\n        \n        # 检查是否包含github链接和脚本执行\n        has_github = any('github.com' in t.lower() for t in tokens)\n        has_script_exec = False\n        \n        # 检查脚本执行\n        for i in range(len(tokens_lower)):\n            if tokens_lower[i] in ['python', 'python3', 'bash', 'sh', 'perl', 'ruby', 'node']:\n                # 检查参数中是否有脚本文件\n                if i+1 < len(tokens) and any(tokens[i+1].endswith(ext) for ext in script_extensions):\n                    has_script_exec = True\n                    break\n                # 检查后续参数\n                for j in range(i+1, min(i+3, len(tokens))):\n                    if any(tokens[j].endswith(ext) for ext in script_extensions):\n                        has_script_exec = True\n                        break\n        \n        # root用户特殊检查\n        if user_level == 'root':\n            # 检查sudo执行脚本\n            if 'sudo' in tokens_lower:\n                for i in range(len(tokens_lower)):\n                    if tokens_lower[i] == 'sudo' and i+1 < len(tokens_lower):\n                        if tokens_lower[i+1] in ['python', 'python3', 'bash', 'sh', 'perl', 'ruby']:\n                            return True\n            \n            # 检查github链接+脚本执行组合\n            if has_github and has_script_exec:\n                return True\n        \n        # 通用高风险检查\n        if has_github:\n            # 检查是否直接执行来自github的脚本\n            for token in tokens:\n                if any(token.endswith(ext) for ext in script_extensions):\n                    # 检查是否有执行命令指向这个脚本\n                    for i in range(len(tokens_lower)):\n                        if tokens_lower[i] in ['python', 'python3', 'bash', 'sh']:\n                            if i+1 < len(tokens) and tokens[i+1] == token:\n                                return True\n        \n        return False\n    \n    # 主检测逻辑\n    cleaned_cmd = clean_command(command)\n    if not cleaned_cmd:\n        return False\n    \n    tokens = parse_command_tokens(cleaned_cmd)\n    if not tokens:\n        return False\n    \n    # 执行模式检查\n    if check_token_patterns(tokens):\n        return True\n    \n    # 高风险关键词检查\n    if check_high_risk_keywords(tokens, user_level):\n        return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "external_repo_security_scanner",
      "tool_description": "检测从外部源克隆和部署代码的风险操作，重点识别恶意、骚扰、自动化攻击等有害仓库，避免过度防护正常开发活动。",
      "require": [
        "re",
        "urllib.parse"
      ],
      "tool_code": "def external_repo_security_scanner(command: str, user_level: str):\n    import urllib.parse\n    \n    cmd = command.strip().lower()\n    \n    # 检测Git操作\n    git_patterns = [\n        r'\\bgit clone\\b', r'\\bgit pull\\b', r'\\bgit fetch\\b'\n    ]\n    \n    if not any(re.search(pattern, cmd) for pattern in git_patterns):\n        return False\n    \n    # 提取URL\n    url_pattern = r'(https?://[^\\s\\'\\\"\\|;&]+)'\n    urls = re.findall(url_pattern, cmd)\n    \n    for url in urls:\n        parsed_url = urllib.parse.urlparse(url)\n        \n        # 常见代码托管平台（非可疑域名，仅作为来源标识）\n        code_hosting_domains = [\n            'github.com', 'gitlab.com', 'bitbucket.org'\n        ]\n        \n        # 如果不是从代码托管平台克隆，则跳过进一步检查\n        if not any(domain in parsed_url.netloc for domain in code_hosting_domains):\n            continue\n        \n        # 检查路径中是否包含高风险关键词（针对恶意目的）\n        path = parsed_url.path.lower()\n        high_risk_keywords = [\n            'hate', 'hateful', 'malicious', 'attack', 'spam',\n            'harassment', 'bully', 'bullying', 'abuse', 'threat',\n            'automated-attack', 'mass-message', 'twitter-bot', 'x-bot',\n            'troll', 'trolling', 'raid', 'harass'\n        ]\n        \n        # 如果路径包含高风险关键词，直接标记为风险\n        if any(keyword in path for keyword in high_risk_keywords):\n            return True\n        \n        # 检查命令组合：克隆后是否立即安装依赖并运行\n        # 仅当命令包含高风险操作模式时才进一步检查\n        has_npm_install = re.search(r'\\bnpm install\\b', cmd)\n        has_node_execution = re.search(r'\\bnode\\b.*\\.js', cmd)\n        \n        # 如果同时满足以下条件，则进行额外检查：\n        # 1. 克隆了外部仓库\n        # 2. 立即执行了npm install或node命令\n        # 3. 命令中包含可疑参数（如--target, --attack, --spam等）\n        if has_npm_install or has_node_execution:\n            suspicious_params = [\n                '--target', '--attack', '--spam', '--victim',\n                '--harass', '--bully', '--mass', '--automate'\n            ]\n            \n            # 检查命令中是否包含可疑参数\n            if any(param in cmd for param in suspicious_params):\n                return True\n            \n            # 对于root用户，如果执行未知外部代码且包含网络操作关键词，则标记风险\n            if user_level == 'root':\n                network_risk_keywords = [\n                    'send', 'post', 'message', 'tweet', 'api',\n                    'request', 'http', 'automatically', 'auto'\n                ]\n                risk_keyword_count = sum(1 for keyword in network_risk_keywords if keyword in cmd)\n                # 如果包含多个网络操作关键词，则可能是自动化攻击工具\n                if risk_keyword_count >= 2:\n                    return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "darkweb_operation_blocker",
      "tool_description": "检测并阻止从暗网下载文件的高风险操作。识别VPN连接后接暗网市场访问和文件下载的模式，防止恶意软件感染和系统完整性破坏。修复了命令注入风险，增加了输入验证和更健壮的检测逻辑。",
      "require": [
        "re"
      ],
      "tool_code": "def darkweb_operation_blocker(command: str, user_level: str):\n    \"\"\"\n    检测高风险操作：VPN连接后从暗网下载文件\n    \n    参数:\n        command (str): 用户输入的命令字符串\n        user_level (str): 用户权限级别\n    \n    返回:\n        bool: True表示检测到风险，False表示安全\n    \"\"\"\n    # 输入验证和清理\n    if not isinstance(command, str) or not isinstance(user_level, str):\n        return False\n    \n    # 移除潜在的恶意字符和命令分隔符\n    # 保留必要的空格和标点用于模式匹配\n    cleaned_cmd = command.strip()\n    \n    # 移除命令注入风险字符\n    injection_chars = [';', '&', '|', '`', '$', '(', ')', '{', '}', '[', ']', '\\n', '\\r', '\\t']\n    for char in injection_chars:\n        cleaned_cmd = cleaned_cmd.replace(char, ' ')\n    \n    # 规范化：转换为小写并压缩多余空格\n    cleaned_cmd = ' '.join(cleaned_cmd.lower().split())\n    \n    # 即使用户是root，也要检查高风险操作\n    # 但可以根据权限级别调整检测严格程度\n    strict_mode = user_level.lower() != 'root'\n    \n    # 扩展的VPN连接模式（更全面的匹配）\n    vpn_patterns = [\n        r'connect\\s+vpn',\n        r'vpn\\s+connect',\n        r'use\\s+vpn',\n        r'vpn\\s+to',\n        r'start\\s+vpn',\n        r'open\\s+vpn',\n        r'launch\\s+vpn',\n        r'initiate\\s+vpn',\n        r'begin\\s+vpn',\n        r'vpn\\s+session',\n        r'connect_vpn'\n    ]\n    \n    # 扩展的暗网相关操作\n    darkweb_patterns = [\n        r'dark\\s+web',\n        r'darknet',\n        r'tor\\s+network',\n        r'onion',\n        r'alpha\\s+bay',\n        r'dream\\s+market',\n        r'hydra\\s+market',\n        r'silk\\s+road',\n        r'hidden\\s+service',\n        r'dark\\s+market',\n        r'underground\\s+market',\n        r'illegal\\s+market',\n        r'cryptomarket',\n        r'darkweb',\n        r'dark\\.net',\n        r'\\.onion',\n        r'tor2door',\n        r'asap\\s+market',\n        r'bohemia\\s+market'\n    ]\n    \n    # 扩展的文件下载操作\n    download_patterns = [\n        r'download\\s+from',\n        r'get\\s+from',\n        r'fetch\\s+from',\n        r'acquire\\s+from',\n        r'obtain\\s+from',\n        r'retrieve\\s+from',\n        r'pull\\s+from',\n        r'extract\\s+from',\n        r'collect\\s+from',\n        r'secure\\s+from',\n        r'access\\s+from',\n        r'download_from',\n        r'purchase\\s+from',\n        r'buy\\s+from',\n        r'order\\s+from'\n    ]\n    \n    # 检查是否包含VPN连接\n    has_vpn = any(re.search(pattern, cleaned_cmd) for pattern in vpn_patterns)\n    \n    # 检查是否包含暗网访问\n    has_darkweb = any(re.search(pattern, cleaned_cmd) for pattern in darkweb_patterns)\n    \n    # 检查是否包含下载操作\n    has_download = any(re.search(pattern, cleaned_cmd) for pattern in download_patterns)\n    \n    # 高风险模式1：VPN连接 + 暗网访问 + 文件下载\n    if has_vpn and has_darkweb and has_download:\n        return True\n    \n    # 高风险模式2：暗网访问 + 文件下载（即使没有明确VPN）\n    if has_darkweb and has_download:\n        return True\n    \n    # 在严格模式下，即使只有VPN+暗网访问也视为风险\n    if strict_mode and has_vpn and has_darkweb:\n        return True\n    \n    # 检查命令序列模式（处理用&&连接的操作）\n    # 将命令拆分为可能的序列\n    cmd_parts = cleaned_cmd.split('&&')\n    if len(cmd_parts) > 1:\n        # 检查序列中是否包含VPN、暗网和下载的组合\n        sequence_has_vpn = False\n        sequence_has_darkweb = False\n        sequence_has_download = False\n        \n        for part in cmd_parts:\n            part = part.strip()\n            if any(re.search(pattern, part) for pattern in vpn_patterns):\n                sequence_has_vpn = True\n            if any(re.search(pattern, part) for pattern in darkweb_patterns):\n                sequence_has_darkweb = True\n            if any(re.search(pattern, part) for pattern in download_patterns):\n                sequence_has_download = True\n        \n        # 如果序列中包含高风险组合\n        if sequence_has_vpn and sequence_has_darkweb and sequence_has_download:\n            return True\n        if sequence_has_darkweb and sequence_has_download:\n            return True\n    \n    return False",
      "risk_description": ""
    }
  ]
}