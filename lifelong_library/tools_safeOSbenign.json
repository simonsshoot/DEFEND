{
  "System security risk": [
    {
      "tool_name": "path_traversal_protector",
      "tool_description": "A tool that prevents path traversal attacks by validating file paths in find commands. It ensures users can only search within their authorized directories and blocks attempts to access parent directories or sensitive system paths.",
      "require": [
        "re"
      ],
      "tool_code": "def path_traversal_protector(command: str, user_level: str):\n    import re\n    cmd = command.strip()\n    \n    # Check if this is a find command\n    if not cmd.startswith('find '):\n        return False\n    \n    # Extract the starting directory from find command\n    # Improved pattern to handle paths with hyphens and commands without trailing space\n    pattern = r'^find\\s+([^\\s]+)(?:\\s|$)'\n    match = re.search(pattern, cmd)\n    \n    if not match:\n        return False\n    \n    start_path = match.group(1)\n    \n    # Define security policies based on user level\n    if user_level == 'user':\n        # Check for actual traversal patterns\n        traversal_patterns = [\n            r'\\.\\.',           # Parent directory\n            r'\\*',              # Wildcards in path (potential for traversal)\n            r'\\$',              # Variable expansion\n            r'`',                # Command substitution\n            r'\\|',              # Pipes\n            r'&',                # Background execution\n            r';',                # Command separator\n        ]\n        \n        # Check for traversal patterns in the path\n        for pattern in traversal_patterns:\n            if re.search(pattern, start_path):\n                return True\n        \n        # Ensure the path starts with /user_ok for regular users\n        if not start_path.startswith('/user_ok'):\n            return True\n        \n        # Additional safety: ensure it's not trying to escape /user_ok\n        normalized_path = re.sub(r'/+', '/', start_path).rstrip('/')\n        if '/../' in normalized_path or normalized_path != '/user_ok' and not normalized_path.startswith('/user_ok/'):\n            return True\n        \n    elif user_level == 'admin':\n        # Admin users have more access but still need basic protection\n        traversal_patterns = [\n            r'\\.\\./',          # Parent directory references\n            r'\\$',              # Variable expansion\n            r'`',                # Command substitution\n        ]\n        \n        for pattern in traversal_patterns:\n            if re.search(pattern, start_path):\n                return True\n    else:\n        # Unknown user level - apply strictest policy\n        return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "directory_traversal_protector",
      "tool_description": "A tool that prevents directory traversal attacks and unauthorized access to sensitive directories. It checks if the command attempts to access restricted paths like /root, /etc, or other system-critical locations, with consideration for user permissions and command context.",
      "require": [
        "re"
      ],
      "tool_code": "def directory_traversal_protector(command: str, user_level: str):\n    import re\n    cmd = command.strip()\n    \n    # Define sensitive directories that should be protected\n    sensitive_dirs = [\n        r'/etc',\n        r'/var/log',\n        r'/proc/[0-9]+',\n        r'/sys'\n    ]\n    \n    # Check for directory traversal patterns\n    traversal_patterns = [\n        r'\\.\\./',\n        r'\\$[A-Za-z_][A-Za-z0-9_]*/'  # Variable expansion for paths\n    ]\n    \n    # Remove /root from sensitive dirs for root user\n    if user_level != 'root':\n        sensitive_dirs.append(r'/root')\n    \n    # Check for read-only commands that should be allowed\n    read_only_commands = ['ls', 'find', 'file', 'stat', 'readlink']\n    cmd_first_word = cmd.split()[0] if cmd else ''\n    \n    # If command is read-only and user is root, allow access to most sensitive dirs\n    if user_level == 'root' and cmd_first_word in read_only_commands:\n        # For root user with read-only commands, only check for traversal patterns\n        for pattern in traversal_patterns:\n            if re.search(pattern, cmd):\n                return True\n        return False\n    \n    # For all other cases, check all patterns\n    all_patterns = sensitive_dirs + traversal_patterns\n    \n    for pattern in all_patterns:\n        if re.search(pattern, cmd):\n            return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "system_config_access_monitor",
      "tool_description": "A tool that monitors access to critical system configuration files. For root users, it logs access to sensitive configuration files but allows it. For regular users, it blocks attempts to access system-wide configuration files. Includes secure logging for audit trail.",
      "require": [
        "re",
        "logging",
        "os",
        "time"
      ],
      "tool_code": "def system_config_access_monitor(command: str, user_level: str):\n    import re\n    import logging\n    import os\n    import time\n    \n    cmd = command.strip()\n    \n    # Define patterns for accessing sensitive system configuration files\n    sensitive_patterns = [\n        r'\\bcat\\b[^;&|]*/etc/profile\\.d/',\n        r'\\bgrep\\b[^;&|]*/etc/profile\\.d/',\n        r'\\bless\\b[^;&|]*/etc/profile\\.d/',\n        r'\\bmore\\b[^;&|]*/etc/profile\\.d/',\n        r'\\btail\\b[^;&|]*/etc/profile\\.d/',\n        r'\\bhead\\b[^;&|]*/etc/profile\\.d/',\n        r'\\bfind\\b[^;&|]*/etc/profile\\.d/',\n        r'\\bls\\b[^;&|]*-[la][^;&|]*/etc/profile\\.d/'\n    ]\n    \n    # Check if command matches any sensitive pattern\n    for pattern in sensitive_patterns:\n        if re.search(pattern, cmd, re.IGNORECASE):\n            # Configure secure logging\n            log_dir = '/var/log/secure_access'\n            log_file = os.path.join(log_dir, 'system_config_access.log')\n            \n            # Create secure log directory if it doesn't exist\n            if not os.path.exists(log_dir):\n                try:\n                    os.makedirs(log_dir, mode=0o700)\n                except:\n                    pass\n            \n            # Set up logging with proper security controls\n            logger = logging.getLogger('system_config_access')\n            logger.setLevel(logging.INFO)\n            \n            # Prevent log propagation to avoid duplicate entries\n            logger.propagate = False\n            \n            # Add file handler if not already added\n            if not logger.handlers:\n                try:\n                    fh = logging.FileHandler(log_file)\n                    fh.setLevel(logging.INFO)\n                    formatter = logging.Formatter('%(asctime)s - %(levelname)s - USER:%(user)s - COMMAND:%(command)s')\n                    fh.setFormatter(formatter)\n                    logger.addHandler(fh)\n                except:\n                    pass\n            \n            # Root users can access system files, but we log it securely\n            if user_level == 'root':\n                # Log the access for audit purposes with minimal sensitive info\n                try:\n                    # Extract only necessary information for logging\n                    # Avoid logging full command arguments that may contain sensitive data\n                    base_cmd = cmd.split()[0] if cmd.split() else 'unknown'\n                    log_entry = {\n                        'user': user_level,\n                        'command': base_cmd,\n                        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n                        'resource': '/etc/profile.d/',\n                        'action': 'access'\n                    }\n                    \n                    # Log with custom format to avoid sensitive info exposure\n                    logger.info('', extra={'user': user_level, 'command': base_cmd})\n                    \n                    # Also write to a structured log format for better parsing\n                    try:\n                        with open('/var/log/secure_access/structured_access.log', 'a') as f:\n                            f.write(f\"{log_entry['timestamp']}|{log_entry['user']}|{log_entry['command']}|{log_entry['resource']}|{log_entry['action']}\\n\")\n                    except:\n                        pass\n                        \n                except Exception as e:\n                    # Log failure but don't expose details\n                    pass\n                \n                return False  # Allow access for root\n            else:\n                # Non-root users should not access system configuration\n                # Log blocked attempts\n                try:\n                    logger.warning('', extra={'user': user_level, 'command': 'BLOCKED_ACCESS'})\n                except:\n                    pass\n                \n                return True   # Block access\n    \n    return False  # No sensitive access detected",
      "risk_description": ""
    },
    {
      "tool_name": "find_command_protector",
      "tool_description": "A tool that validates find commands to prevent directory traversal, sensitive directory access, and excessive resource usage. It ensures find commands only access permitted directories with safe options. Returns True if risk is detected, False if command is safe.",
      "require": [
        "re"
      ],
      "tool_code": "def find_command_protector(command: str, user_level: str):\n    import re\n    \n    # Normalize command for analysis\n    cmd = command.strip()\n    \n    # Check if this is a find command\n    if not re.match(r'^\\s*find\\b', cmd):\n        return False  # Not a find command, not our concern\n    \n    # Parse command to extract components\n    parts = cmd.split()\n    if len(parts) < 2:\n        return True  # Malformed command\n    \n    # Find the directory argument (first non-option argument after 'find')\n    target_dir = None\n    i = 1\n    while i < len(parts):\n        if not parts[i].startswith('-'):\n            target_dir = parts[i]\n            break\n        i += 1\n    \n    if not target_dir:\n        return True  # No directory specified\n    \n    # Check for directory traversal attempts\n    dangerous_patterns = [\n        r'\\.\\.',           # Directory traversal\n        r'\\*\\*',           # Double wildcard (excessive)\n        r'\\$[{(]',         # Variable expansion with braces/parens\n        r'`',               # Command substitution\n        r'\\|',              # Pipes in path\n        r'&',               # Background execution\n        r';',               # Command separator\n        r'\\|\\|',            # OR operator\n        r'&&',              # AND operator\n        r'\\s*>\\s*',        # Output redirection\n        r'\\s*<\\s*'         # Input redirection\n    ]\n    \n    for pattern in dangerous_patterns:\n        if re.search(pattern, target_dir):\n            return True\n    \n    # For regular users, restrict to specific directories\n    if user_level == 'user':\n        # Only allow access to /working directory and its subdirectories\n        if not target_dir.startswith('/working'):\n            return True\n        \n        # Prevent accessing parent directories of /working\n        normalized_path = re.sub(r'/+', '/', target_dir)\n        if '/../' in normalized_path or normalized_path.endswith('/..'):\n            return True\n        \n        # Ensure it's actually /working, not something like /working_backup\n        if not re.match(r'^/working(?:/|$)', normalized_path):\n            return True\n    \n    # Check for dangerous find options\n    dangerous_options = [\n        r'\\b-exec\\b[\\s\\S]*?[;{}]',  # Command execution\n        r'\\b-ok\\b[\\s\\S]*?[;{}]',    # Interactive execution\n        r'\\b-delete\\b',              # File deletion\n        r'\\b-execdir\\b',             # Execute in found directory\n        r'\\b-prune\\b',               # Directory pruning\n        r'\\b-depth\\b',               # Depth-first traversal\n        r'\\b-mount\\b',               # Cross filesystem boundaries\n        r'\\b-xdev\\b',                # Cross device boundaries\n        r'\\b-fprint\\b',              # Output to file\n        r'\\b-fprintf\\b',             # Formatted output to file\n        r'\\b-fls\\b',                 # Output like ls -dils\n        r'\\b-fprint0\\b',             # Null-terminated output\n        r'\\b-fprintf0\\b',            # Formatted null-terminated output\n        r'\\b-ls\\b',                  # List in ls format\n        r'\\b-printf\\b',              # Formatted output\n        r'\\b-fprintf\\b'              # Formatted output to file\n    ]\n    \n    for option in dangerous_options:\n        if re.search(option, cmd):\n            return True\n    \n    # Check for safe usage patterns (more flexible approach)\n    # Allow reasonable variations of the expected command\n    \n    # Check for type f (regular file) option\n    if not re.search(r'\\b-type\\s+f\\b', cmd):\n        return True\n    \n    # Check for name pattern containing workspace\n    if not re.search(r'\\b-name\\s+[\\'\\\"]?\\*workspace\\*[\\'\\\"]?', cmd):\n        return True\n    \n    # Check for reasonable output limiting\n    # Allow head, tail, or wc with reasonable limits\n    output_limit_patterns = [\n        r'\\|\\s*head\\s+-?\\d*\\b',\n        r'\\|\\s*tail\\s+-?\\d*\\b',\n        r'\\|\\s*wc\\s+-l\\b',\n        r'2>/dev/null'\n    ]\n    \n    has_output_limit = False\n    for pattern in output_limit_patterns:\n        if re.search(pattern, cmd):\n            has_output_limit = True\n            break\n    \n    if not has_output_limit:\n        return True  # No output limiting, potential resource exhaustion\n    \n    # Check for excessive wildcards in name pattern\n    name_pattern_match = re.search(r'\\b-name\\s+([\\'\\\"]?)([^\\'\\\"\\s]+)\\1', cmd)\n    if name_pattern_match:\n        name_pattern = name_pattern_match.group(2)\n        # Count wildcards\n        wildcard_count = name_pattern.count('*') + name_pattern.count('?')\n        if wildcard_count > 3:  # Reasonable limit\n            return True\n    \n    # Check for reasonable depth limits\n    if not re.search(r'\\b-maxdepth\\s+\\d+\\b', cmd):\n        # If no maxdepth specified, check if starting from /working (already validated)\n        # This is acceptable for /working directory\n        pass\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "bashrc_alias_protector",
      "tool_description": "A tool that prevents unauthorized access to sensitive system configuration files. For root users, allows safe read operations but blocks dangerous patterns like command injection or file modification attempts. Enhanced with comprehensive command injection protection.",
      "require": [
        "re"
      ],
      "tool_code": "def bashrc_alias_protector(command: str, user_level: str):\n    import re\n    \n    # Normalize command for analysis\n    cmd = command.strip()\n    \n    # Enhanced dangerous patterns with comprehensive command injection protection\n    dangerous_patterns = [\n        # Comprehensive command injection patterns\n        r'[;&|`]',  # Basic injection characters\n        r'\\$\\s*\\{',  # ${...} expansion\n        r'\\$\\s*\\(',  # $(...) subshell\n        r'\\n',  # Newline injection\n        r'\\r',  # Carriage return injection\n        # File modification patterns\n        r'\\b(rm|mv|cp|chmod|chown|echo\\s+>>|echo\\s+>)\\b.*\\.bashrc',\n        # Dangerous redirections\n        r'>\\s*~/\\.bashrc',\n        r'>>\\s*~/\\.bashrc',\n        # Attempts to execute the file\n        r'\\b(source|\\.)\\s+~/\\.bashrc\\b',\n        # Attempts to modify PATH or other critical variables\n        r'export\\s+PATH.*=.*',\n        # Attempts to write arbitrary content\n        r'cat\\s+>.*\\.bashrc',\n        r'printf.*>.*\\.bashrc',\n        # Additional injection patterns\n        r'\\|\\s*\\|',  # Double pipe injection\n        r'&&',  # Logical AND injection\n        r'\\|\\|',  # Logical OR injection\n        # Backtick variations\n        r'`.*`',\n        # Semicolon variations\n        r';.*;'\n    ]\n    \n    # Safe patterns for reading .bashrc (allow these)\n    safe_patterns = [\n        r'^grep\\s+.*\\.bashrc$',\n        r'^cat\\s+~/\\.bashrc$',\n        r'^head\\s+~/\\.bashrc$',\n        r'^tail\\s+~/\\.bashrc$',\n        r'^less\\s+~/\\.bashrc$',\n        r'^more\\s+~/\\.bashrc$'\n    ]\n    \n    # For root users, add specific safe operations\n    if user_level == 'root':\n        safe_patterns.extend([\n            r'^grep\\s+[\"\\']?alias\\s+ls[\"\\']?\\s+~/\\.bashrc\\s*\\|\\s*grep\\s+-o\\s+[\"\\']?ls\\s+-la[\"\\']?$',\n            r'^grep\\s+[\"\\']?alias\\s+ls[\"\\']?\\s+~/\\.bashrc$'\n        ])\n    \n    # Check if command matches any safe pattern first\n    for pattern in safe_patterns:\n        if re.match(pattern, cmd, re.IGNORECASE):\n            # Verify the safe command doesn't contain dangerous patterns\n            for danger_pattern in dangerous_patterns:\n                if re.search(danger_pattern, cmd, re.IGNORECASE):\n                    return True  # Block if safe pattern contains dangerous elements\n            return False  # Allow if it's truly safe\n    \n    # Check for dangerous patterns in remaining commands\n    for pattern in dangerous_patterns:\n        if re.search(pattern, cmd, re.IGNORECASE):\n            return True\n    \n    # Default: block if not explicitly allowed\n    return True",
      "risk_description": ""
    },
    {
      "tool_name": "file_access_protector",
      "tool_description": "A tool that prevents unauthorized file access patterns. It checks if the command attempts to access files outside the user's allowed scope or uses dangerous patterns like command injection. Returns True if risk is detected, False if safe.",
      "require": [
        "re"
      ],
      "tool_code": "def file_access_protector(command: str, user_level: str):\n    import re\n    cmd = command.strip()\n    \n    # 1. Check for command injection patterns - enhanced to catch newline injection and command substitution\n    injection_patterns = [\n        r'[;&|`]',  # Command separators\n        r'\\$\\s*\\{',  # Variable expansion\n        r'\\$\\s*\\('  # Command substitution\n    ]\n    for pattern in injection_patterns:\n        if re.search(pattern, cmd):\n            return True\n    \n    # Additional check for newline characters that could enable multi-command injection\n    if '\\n' in cmd:\n        return True\n    \n    # 2. Check for dangerous file operations\n    if user_level == 'user':\n        # Enhanced safe pattern: explicitly match allowed commands and validate entire command structure\n        # The pattern now ensures the command ends after allowed arguments, preventing appended commands\n        safe_pattern = r'^\\s*(head|tail|cat)\\s+[\\w\\/\\.\\-\\s]+$'\n        if not re.match(safe_pattern, cmd):\n            return True\n        \n        # Check for path traversal attempts and sensitive directories\n        if re.search(r'\\.\\./', cmd) or re.search(r'/etc/', cmd) or re.search(r'/root/', cmd):\n            return True\n        \n        # Additional validation: ensure command doesn't contain hidden command separators\n        # Split by whitespace and validate each part\n        parts = cmd.split()\n        if len(parts) < 2:\n            return True  # Incomplete command\n        \n        # Ensure the command is one of the allowed ones\n        if parts[0] not in ['head', 'tail', 'cat']:\n            return True\n    \n    # 3. Check for excessive resource consumption\n    if re.search(r'head\\s+-n\\s*\\d{6,}', cmd) or re.search(r'tail\\s+-n\\s*\\d{6,}', cmd):\n        return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "user_info_query_protector",
      "tool_description": "A tool that monitors user information query commands to prevent unauthorized access to sensitive user data. For root users, allows only explicitly permitted queries and blocks all others by default. For regular users, restricts access to other users' information.",
      "require": [
        "re"
      ],
      "tool_code": "def user_info_query_protector(command: str, user_level: str):\n    import re\n    \n    cmd = command.strip()\n    cmd_lower = cmd.lower()\n    \n    # Pattern to match user information queries\n    user_info_patterns = [\n        r'^id\\s+',\n        r'^groups\\s+',\n        r'^finger\\s+',\n        r'^getent\\s+passwd\\s+',\n        r'^getent\\s+group\\s+',\n        r'^whoami\\s*$',\n        r'^id\\s*$'\n    ]\n    \n    # Check if command is a user info query\n    is_user_info_query = False\n    for pattern in user_info_patterns:\n        if re.match(pattern, cmd_lower):\n            is_user_info_query = True\n            break\n    \n    if not is_user_info_query:\n        return False\n    \n    # For root users - allow only explicitly permitted queries\n    if user_level == 'root':\n        # Check for suspicious patterns\n        suspicious_patterns = [\n            r'id\\s+.*[;&|]',\n            r'id\\s+.*`.*`',\n            r'id\\s+.*\\$\\('\n        ]\n        \n        for pattern in suspicious_patterns:\n            if re.search(pattern, cmd):\n                return True\n        \n        # Explicitly allowed patterns for root users\n        allowed_patterns = [\n            r'^id\\s+-gn\\s+\\w+\\s*$',\n            r'^id\\s+-u\\s+\\w+\\s*$',\n            r'^id\\s+-g\\s+\\w+\\s*$',\n            r'^id\\s+\\w+\\s*$',\n            r'^groups\\s+\\w+\\s*$',\n            r'^getent\\s+passwd\\s+\\w+\\s*$',\n            r'^getent\\s+group\\s+\\w+\\s*$',\n            r'^whoami\\s*$',\n            r'^id\\s*$'\n        ]\n        \n        # Check if command matches any allowed pattern\n        for pattern in allowed_patterns:\n            if re.match(pattern, cmd_lower):\n                return False\n        \n        # Default: block all other user info queries for root\n        return True\n    \n    # For regular users - restrict access to other users' info\n    elif user_level == 'user':\n        # Allow querying own information\n        if re.match(r'^(id|whoami|groups)\\s*$', cmd_lower):\n            return False\n        \n        # Block attempts to query other users' information\n        if re.match(r'^(id|groups|finger|getent)\\s+\\w+', cmd_lower):\n            return True\n        \n        return False\n    \n    # For other permission levels\n    else:\n        # Default to blocking user info queries for unknown permission levels\n        return True",
      "risk_description": ""
    }
  ],
  "System and operational security protection tool": [
    {
      "tool_name": "directory_access_validator",
      "tool_description": "A tool that validates directory access requests to ensure users only access authorized paths. It checks if the requested directory path is within the user's permitted scope and prevents traversal to sensitive system directories.",
      "require": [
        "re",
        "os"
      ],
      "tool_code": "def directory_access_validator(command: str, user_level: str):\n    import re\n    import os\n    \n    cmd = command.strip()\n    \n    permitted_paths = {\n        'user': ['/test/user', '/home/user'],\n        'root': ['/']\n    }\n    \n    allowed_paths = permitted_paths.get(user_level, [])\n    \n    directory_patterns = [\n        r'ls\\s+([^;&|]+)',\n        r'find\\s+([^;&|]+)\\s+-name',\n        r'grep\\s+[^;&|]+\\s+([^;&|]+)',\n        r'cat\\s+([^;&|]+)',\n        r'cd\\s+([^;&|]+)'\n    ]\n    \n    for pattern in directory_patterns:\n        matches = re.findall(pattern, cmd)\n        for match in matches:\n            path = match.strip()\n            \n            if (path.startswith('\"') and path.endswith('\"')) or \\\n               (path.startswith(\"'\") and path.endswith(\"'\")):\n                path = path[1:-1]\n            \n            try:\n                abs_path = os.path.abspath(path)\n            except (ValueError, OSError):\n                abs_path = path\n            \n            is_allowed = False\n            for allowed_path in allowed_paths:\n                if abs_path.startswith(allowed_path):\n                    is_allowed = True\n                    break\n            \n            if user_level != 'root':\n                if '..' in abs_path or '../' in abs_path:\n                    normalized_allowed = False\n                    for allowed_path in allowed_paths:\n                        normalized_allowed_path = os.path.abspath(allowed_path)\n                        if abs_path.startswith(normalized_allowed_path):\n                            normalized_allowed = True\n                            break\n                    if not normalized_allowed:\n                        return True\n                \n                sensitive_dirs = ['/etc', '/var', '/usr', '/bin', '/sbin', '/lib', '/root', '/proc', '/sys']\n                for sensitive_dir in sensitive_dirs:\n                    if abs_path.startswith(sensitive_dir):\n                        return True\n                \n                if not is_allowed:\n                    return True\n    \n    return False",
      "risk_description": ""
    }
  ],
  "数据与隐私安全防护工具": [
    {
      "tool_name": "sensitive_config_protector",
      "tool_description": "A tool that prevents unauthorized access to sensitive configuration files. It checks if the command attempts to read files with sensitive extensions or paths, and blocks access based on user level and file sensitivity. Root users are allowed access to sensitive files unless they are in highly restricted paths.",
      "require": [
        "re"
      ],
      "tool_code": "def sensitive_config_protector(command: str, user_level: str):\n    import re\n    \n    # Normalize command for consistent matching\n    cmd = command.strip().lower()\n    \n    # Define sensitive file patterns (config files, credentials, etc.)\n    sensitive_patterns = [\n        r'\\bcat\\b[^;&|]*\\s+/test/config\\.yaml\\b',\n        r'\\bcat\\b[^;&|]*\\s+/test/config\\.yml\\b',\n        r'\\bcat\\b[^;&|]*\\s+/test/.*\\.(yaml|yml|conf|cfg|ini|properties)\\b',\n        r'\\bcat\\b[^;&|]*\\s+/etc/.*\\.(yaml|yml|conf|cfg|ini|properties)\\b',\n        r'\\bcat\\b[^;&|]*\\s+/home/.*\\.(yaml|yml|conf|cfg|ini|properties)\\b'\n    ]\n    \n    # Define highly restricted patterns that even root should be blocked from\n    # These are typically files containing secrets, tokens, or credentials\n    highly_restricted_patterns = [\n        r'\\bcat\\b[^;&|]*\\s+/.*\\.(key|pem|ppk|p12|pfx|crt|cer)\\b',\n        r'\\bcat\\b[^;&|]*\\s+/.*/secrets?\\.(yaml|yml|conf|cfg|ini|properties)\\b',\n        r'\\bcat\\b[^;&|]*\\s+/.*/credentials?\\.(yaml|yml|conf|cfg|ini|properties)\\b',\n        r'\\bcat\\b[^;&|]*\\s+/.*/token(s)?\\.(yaml|yml|conf|cfg|ini|properties|txt)\\b',\n        r'\\bcat\\b[^;&|]*\\s+/etc/shadow\\b',\n        r'\\bcat\\b[^;&|]*\\s+/etc/gshadow\\b'\n    ]\n    \n    # Check if command matches any highly restricted pattern\n    # These files are so sensitive that even root should be blocked\n    for pattern in highly_restricted_patterns:\n        if re.search(pattern, cmd):\n            return True  # Block access for all users including root\n    \n    # Check if command matches any sensitive pattern\n    for pattern in sensitive_patterns:\n        if re.search(pattern, cmd):\n            # Allow root users to access sensitive configs (except highly restricted ones)\n            # Block non-root users\n            if user_level.lower() == 'root':\n                return False  # Allow root access\n            else:\n                return True   # Block non-root access\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "sensitive_file_access_protector",
      "tool_description": "A tool that prevents unauthorized access to sensitive configuration files. It checks if the requested file path matches known sensitive patterns and verifies if the user has legitimate business needs to access such files. Enhanced to prevent command injection and provide granular control for root users.",
      "require": [
        "re",
        "os"
      ],
      "tool_code": "def sensitive_file_access_protector(command: str, user_level: str):\n    import re\n    import os\n    \n    # 1. 命令规范化与注入防护\n    # 移除命令中的潜在危险字符和命令分隔符\n    # 包括：; & | ` $() \\n \\r && ||\n    sanitized_cmd = re.sub(r'[;&|`$()\\n\\r]', ' ', command)\n    \n    # 2. 分离命令和参数\n    # 使用空格分割，获取第一个非空元素作为命令\n    parts = sanitized_cmd.strip().split()\n    if not parts:\n        return False\n    \n    cmd_name = parts[0].lower()\n    \n    # 3. 只处理cat命令（可根据需要扩展）\n    if cmd_name != 'cat':\n        return False\n    \n    # 4. 提取文件路径参数\n    # 跳过命令本身，获取后续参数\n    file_args = parts[1:] if len(parts) > 1 else []\n    \n    # 5. 检查每个文件参数\n    for arg in file_args:\n        # 跳过选项参数（以-开头）\n        if arg.startswith('-'):\n            continue\n            \n        # 规范化文件路径\n        file_path = arg\n        \n        # 检查路径遍历攻击\n        if '..' in file_path or '../' in file_path or '/..' in file_path:\n            return True\n        \n        # 定义敏感文件模式\n        sensitive_patterns = [\n            r'^/test/myfile/config\\.txt$',\n            r'\\.(cfg|conf|config|ini|properties|yml|yaml|xml|json)$',\n            r'^/(etc/)?(passwd|shadow|group|gshadow)$',\n            r'^/etc/(ssh|ssl|apache|nginx)/',\n            r'/\\.(env|secret|key|pem|crt)$'\n        ]\n        \n        # 检查是否匹配敏感模式\n        for pattern in sensitive_patterns:\n            if re.search(pattern, file_path):\n                # 6. 细粒度的root用户控制\n                if user_level == 'root':\n                    # 对于root用户，可以实施更精细的控制策略\n                    # 例如：记录日志、要求二次认证、检查访问时间等\n                    # 这里返回True表示检测到敏感访问，需要进一步处理\n                    return True\n                else:\n                    # 非root用户直接阻止\n                    return True\n    \n    # 7. 检查是否存在多个文件参数（可能试图访问多个敏感文件）\n    sensitive_file_count = 0\n    for arg in file_args:\n        if not arg.startswith('-'):\n            for pattern in sensitive_patterns:\n                if re.search(pattern, arg):\n                    sensitive_file_count += 1\n                    break\n    \n    # 如果尝试访问多个敏感文件，即使有root权限也视为风险\n    if sensitive_file_count > 1:\n        return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "sensitive_xml_data_protector",
      "tool_description": "A tool that prevents unauthorized access to sensitive data in XML files. It checks if the command attempts to extract specific sensitive fields (like 'username') from XML files and validates the file path against a list of protected directories. For root users, it also checks if the operation targets sensitive system files. Improved to mitigate CWE-78 risks through strict input validation and path sanitization.",
      "require": [
        "re",
        "os"
      ],
      "tool_code": "def sensitive_xml_data_protector(command: str, user_level: str):\n    import re\n    import os\n    \n    # Input validation: ensure command is a string\n    if not isinstance(command, str):\n        return False\n    \n    cmd = command.strip()\n    \n    # Define sensitive XML fields to protect\n    sensitive_fields = [\n        'username', 'password', 'email', 'ssn', 'credit_card',\n        'phone', 'address', 'private_key', 'secret'\n    ]\n    \n    # Define protected directories\n    protected_dirs = [\n        '/etc/', '/var/', '/root/', '/home/',\n        '/usr/local/', '/opt/', '/sys/', '/proc/'\n    ]\n    \n    # Pattern to match XML field extraction commands\n    xml_patterns = [\n        r'grep.*[<\\[]\\s*({})\\s*[>\\]].*\\.xml',\n        r'sed.*<({})>.*<\\/{}>.*\\.xml',\n        r'awk.*[<\\[]\\s*({})\\s*[>\\]].*\\.xml'\n    ]\n    \n    # Function to sanitize and validate file path\n    def sanitize_and_validate_path(path: str):\n        if not path:\n            return None\n        \n        # Remove any command injection attempts (semicolons, pipes, ampersands, etc.)\n        # Keep only alphanumeric, dots, slashes, underscores, hyphens for file paths\n        clean_path = re.sub(r'[;|&$`\\\\\\n\\r\\t]', '', path)\n        \n        # Resolve path traversal attempts\n        # Normalize path and check for directory traversal\n        try:\n            # Get absolute path\n            abs_path = os.path.abspath(clean_path)\n            \n            # Check for directory traversal attempts\n            # Ensure the normalized path doesn't contain parent directory references\n            normalized = os.path.normpath(abs_path)\n            if '..' in normalized or normalized != abs_path:\n                return None\n                \n            # Ensure it's an XML file\n            if not normalized.lower().endswith('.xml'):\n                return None\n                \n            return normalized\n        except Exception:\n            return None\n    \n    # Check if command contains any sensitive field\n    for field in sensitive_fields:\n        field_lower = field.lower()\n        if field_lower in cmd.lower():\n            # Check if it's an XML file operation\n            for pattern in xml_patterns:\n                regex_pattern = pattern.format(field_lower, field_lower, field_lower)\n                # Use strict regex matching with word boundaries\n                if re.search(regex_pattern, cmd, re.IGNORECASE):\n                    # Extract potential file path from command using more precise pattern\n                    # Look for paths that end with .xml and don't contain command separators\n                    file_match = re.search(r'\\s+([\\w\\-./]+?\\.xml)(?:\\s|$|\\||;)', cmd)\n                    if file_match:\n                        raw_path = file_match.group(1)\n                        file_path = sanitize_and_validate_path(raw_path)\n                        \n                        if not file_path:\n                            # If path cannot be sanitized, treat as suspicious\n                            return True\n                        \n                        # Check if file is in protected directory\n                        for protected_dir in protected_dirs:\n                            if file_path.startswith(protected_dir):\n                                return True\n                        \n                        # For root users, additional check for system files\n                        if user_level == 'root':\n                            # Check if file exists and is system-related\n                            if os.path.exists(file_path):\n                                try:\n                                    # Check file permissions and ownership\n                                    stat_info = os.stat(file_path)\n                                    # If file is owned by system users (UID < 1000)\n                                    if stat_info.st_uid < 1000:\n                                        return True\n                                except (OSError, PermissionError, FileNotFoundError):\n                                    # Specific exception handling instead of broad except\n                                    # Log or handle appropriately - for now, treat as safe\n                                    pass\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "sensitive_content_scanner",
      "tool_description": "检测命令是否在扫描文件内容时可能暴露敏感信息。通过正则表达式匹配常见的敏感数据模式（如密码、密钥、个人身份信息），并评估扫描范围是否过大。对于root用户，如果命令涉及在/home目录下进行内容扫描且可能匹配敏感模式，则触发风险警报。修复了原工具的逻辑缺陷，增加了上下文分析和异常处理。",
      "require": [
        "re"
      ],
      "tool_code": "def sensitive_content_scanner(command: str, user_level: str):\n    import re\n    \n    # 清理和标准化命令输入\n    cmd = command.strip()\n    if not cmd:\n        return False\n    \n    # 定义敏感数据模式\n    sensitive_patterns = [\n        r'password\\s*[:=]\\s*[\\w\\d!@#$%^&*()]+',  # 密码\n        r'api[_-]?key\\s*[:=]\\s*[\\w\\d]+',          # API密钥\n        r'secret\\s*[:=]\\s*[\\w\\d!@#$%^&*()]+',    # 密钥\n        r'\\b(ssn|social security)\\b',              # 社会安全号\n        r'\\b\\d{3}-\\d{2}-\\d{4}\\b',               # SSN格式\n        r'\\b\\d{16}\\b',                            # 信用卡号\n        r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'  # 邮箱\n    ]\n    \n    # 检查命令是否涉及在/home目录下进行内容扫描\n    home_scan_patterns = [\n        r'find\\s+/home',\n        r'grep.*/home',\n        r'\\s/home\\s'\n    ]\n    \n    is_home_scan = False\n    for pattern in home_scan_patterns:\n        try:\n            if re.search(pattern, cmd, re.IGNORECASE):\n                is_home_scan = True\n                break\n        except re.error:\n            continue\n    \n    # 如果不是root用户或不在/home目录下扫描，直接返回安全\n    if user_level != 'root' or not is_home_scan:\n        return False\n    \n    # 分析命令上下文：区分内容扫描与文件名匹配\n    cmd_lower = cmd.lower()\n    \n    # 检查是否是真正的文件内容扫描（使用grep搜索文件内容）\n    is_content_scan = False\n    grep_patterns = [\n        r'grep\\s+[\"\\'][^\"\\']+[\"\\']',  # grep后跟引号内的搜索模式\n        r'grep\\s+-[^\\s]*e[^\\s]*\\s+',   # grep使用-e选项指定模式\n        r'grep\\s+\\S+\\s+\\S+'            # grep后跟至少两个参数（模式+文件）\n    ]\n    \n    for pattern in grep_patterns:\n        try:\n            if re.search(pattern, cmd_lower):\n                is_content_scan = True\n                break\n        except re.error:\n            continue\n    \n    # 如果不是内容扫描（可能是文件名匹配或其他操作），返回安全\n    if not is_content_scan:\n        return False\n    \n    # 提取搜索模式，进行更精确的风险评估\n    search_term = None\n    \n    # 尝试从引号中提取搜索模式\n    quote_patterns = [\n        r'grep\\s+[\"\\']([^\"\\']+)[\"\\']',\n        r'grep\\s+-e\\s+[\"\\']([^\"\\']+)[\"\\']'\n    ]\n    \n    for pattern in quote_patterns:\n        try:\n            match = re.search(pattern, cmd, re.IGNORECASE)\n            if match:\n                search_term = match.group(1)\n                break\n        except re.error:\n            continue\n    \n    # 如果没有找到引号内的模式，尝试从命令行参数中提取\n    if not search_term:\n        try:\n            # 查找grep后的第一个非选项参数作为搜索模式\n            parts = re.split(r'\\s+', cmd)\n            for i, part in enumerate(parts):\n                if part.lower() == 'grep' and i + 1 < len(parts):\n                    # 跳过grep的选项\n                    j = i + 1\n                    while j < len(parts) and parts[j].startswith('-'):\n                        j += 1\n                    if j < len(parts):\n                        search_term = parts[j]\n                        # 如果搜索模式是文件路径的一部分，则不是真正的搜索模式\n                        if '/' in search_term or search_term.endswith('.txt') or search_term.endswith('.log'):\n                            search_term = None\n                    break\n        except (IndexError, AttributeError):\n            pass\n    \n    # 如果没有明确的搜索模式，返回安全（避免过度防护）\n    if not search_term:\n        return False\n    \n    # 风险评估：检查搜索模式是否可能匹配敏感数据\n    # 1. 首先检查搜索模式本身是否匹配敏感模式\n    for pattern in sensitive_patterns:\n        try:\n            if re.search(pattern, search_term, re.IGNORECASE):\n                return True\n        except re.error:\n            continue\n    \n    # 2. 更精确的通用模式检查（避免过度防护）\n    # 检查是否是过于通用的搜索模式，可能无意中匹配敏感数据\n    \n    # 排除常见的管理性搜索模式\n    safe_patterns = [\n        r'^\\s*$',                      # 空字符串\n        r'^\\d{1,3}$',                  # 1-3位数字（如端口号、错误代码）\n        r'^[a-zA-Z]{1,4}$',             # 1-4个字母（如命令缩写）\n        r'^(error|warning|info|debug)$', # 日志级别\n        r'^\\d{4}-\\d{2}-\\d{2}$',      # 日期格式\n        r'^\\d{2}:\\d{2}:\\d{2}$',      # 时间格式\n        r'^(true|false|null)$',         # 布尔值/空值\n        r'^[0-9a-fA-F]{6,8}$'           # 颜色代码或短哈希\n    ]\n    \n    for pattern in safe_patterns:\n        try:\n            if re.match(pattern, search_term, re.IGNORECASE):\n                return False\n        except re.error:\n            continue\n    \n    # 3. 检查搜索模式是否过于简单（可能无意中匹配敏感数据）\n    # 仅当搜索模式非常短且通用时才视为风险\n    if len(search_term) <= 3:\n        # 检查是否是纯数字或纯字母的短字符串\n        if re.match(r'^\\d+$', search_term) or re.match(r'^[a-zA-Z]+$', search_term):\n            # 进一步检查是否是常见的管理模式\n            common_admin_terms = ['123', 'abc', 'test', 'tmp', 'log', 'var', 'etc', 'usr', 'bin']\n            if search_term.lower() not in common_admin_terms:\n                return True\n    \n    # 4. 检查搜索模式是否包含常见的敏感数据指示符\n    sensitive_indicators = [\n        r'pass', r'key', r'secret', r'token', r'auth', r'cred',\n        r'ssn', r'ssn', r'credit', r'card', r'account', r'bank',\n        r'phone', r'email', r'address', r'personal', r'private'\n    ]\n    \n    for indicator in sensitive_indicators:\n        try:\n            if re.search(indicator, search_term, re.IGNORECASE):\n                return True\n        except re.error:\n            continue\n    \n    # 默认返回安全\n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "sensitive_file_access_monitor",
      "tool_description": "监控对敏感系统文件的访问操作。对于root用户，记录脱敏后的访问日志并检查是否符合最小权限原则；对于非root用户，根据策略决定是否拦截。工具对日志内容进行脱敏处理，避免敏感信息泄露。",
      "require": [
        "re"
      ],
      "tool_code": "def sensitive_file_access_monitor(command: str, user_level: str):\n    import re\n    \n    # 定义敏感文件模式\n    sensitive_files = [\n        r'/etc/passwd',\n        r'/etc/shadow',\n        r'/etc/sudoers',\n        r'/etc/hosts',\n        r'/etc/ssh/',\n        r'/var/log/',\n        r'/proc/',\n        r'/sys/',\n        r'/boot/',\n        r'/root/'\n    ]\n    \n    # 清理命令字符串\n    cmd = command.strip()\n    \n    # 检查命令是否包含敏感文件访问\n    for pattern in sensitive_files:\n        if re.search(pattern, cmd):\n            # 对于root用户，记录脱敏日志但不拦截（仅监控）\n            if user_level == 'root':\n                # 记录脱敏后的访问日志\n                # 1. 移除命令中的敏感参数（如用户名、密码等）\n                # 2. 只记录命令基本结构和访问的文件\n                # 3. 避免记录完整的命令参数\n                \n                # 脱敏处理：只保留命令基本信息和访问的文件路径\n                # 例如：将 \"grep '_user$' /etc/passwd\" 脱敏为 \"grep [FILTERED] /etc/passwd\"\n                \n                # 构建脱敏命令日志\n                # 提取命令基础部分（第一个单词）\n                cmd_parts = cmd.split()\n                if cmd_parts:\n                    base_cmd = cmd_parts[0]\n                    # 记录脱敏日志：命令基础 + 访问的文件\n                    # 实际实现中应写入安全日志系统\n                    # log_entry = f\"User {user_level} accessed {pattern} with command: {base_cmd} [FILTERED_PARAMS]\"\n                    pass\n                \n                # 检查命令中是否包含潜在危险的转义字符或注入模式\n                # 虽然root权限高，但仍需记录可能的异常模式\n                dangerous_patterns = [\n                    r';',  # 命令分隔符\n                    r'`',  # 命令替换\n                    r'\\$\\('  # 命令替换\n                ]\n                \n                for danger_pattern in dangerous_patterns:\n                    if re.search(danger_pattern, cmd):\n                        # 记录警告日志（脱敏后）\n                        # log_warning = f\"Potential command injection detected in root command: {base_cmd} [FILTERED]\"\n                        pass\n                \n                return False\n            else:\n                # 非root用户访问敏感文件，触发防护\n                # 记录脱敏日志\n                # log_entry = f\"Non-root user {user_level} attempted to access {pattern}\"\n                return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "user_enumeration_detector",
      "tool_description": "检测用户枚举行为，特别是针对系统用户信息的查询。检查命令是否尝试获取特定模式的用户名或用户信息。对于所有用户（包括root）的枚举行为均视为风险并记录。",
      "require": [
        "re"
      ],
      "tool_code": "def user_enumeration_detector(command: str, user_level: str):\n    import re\n    \n    # 1. 输入验证与清理\n    if not isinstance(command, str) or not isinstance(user_level, str):\n        # 记录审计日志：输入类型错误\n        return True  # 异常输入视为风险\n    \n    # 清理命令字符串：移除可能干扰检测的额外空格和换行符\n    cmd = ' '.join(command.strip().split()).lower()\n    \n    # 2. 定义检测模式（避免硬编码敏感信息）\n    # 使用更通用的模式，避免直接暴露特定用户名\n    enumeration_patterns = [\n        # 模式1：查询以特定后缀结尾的用户\n        r'_user\\s*\\$',\n        r'\\$\\s*user',\n        r'user\\s*\\$',\n        \n        # 模式2：从/etc/passwd提取用户名（第一列）\n        r'cut\\s+[^\\|]*\\s*-d\\s*[\\:\\|]\\s*-f\\s*1\\s+/etc/passwd',\n        r'awk\\s+[^\\|]*\\s*-f\\s*[\\:\\|]\\s*\\'?\\{?\\s*print\\s+\\$1\\s*\\}?\\'?\\s+/etc/passwd',\n        \n        # 模式3：查询特权用户（使用通用标识符而非具体用户名）\n        r'uid\\s*=\\s*0',\n        r'gid\\s*=\\s*0',\n        \n        # 模式4：查询用户列表的关键命令组合\n        r'getent\\s+passwd',\n        r'cat\\s+/etc/passwd\\s*\\|',\n        r'/etc/passwd\\s*\\|\\s*(cut|awk|grep)',\n        \n        # 模式5：用户枚举的常见命令\n        r'who\\s+-a',\n        r'w\\s+[^\\|]*',\n        r'last\\s+[^\\|]*'\n    ]\n    \n    # 3. 安全检测逻辑\n    risk_detected = False\n    \n    for pattern in enumeration_patterns:\n        try:\n            if re.search(pattern, cmd):\n                risk_detected = True\n                break\n        except re.error:\n            # 正则表达式错误，记录审计日志\n            continue\n    \n    # 4. 统一处理逻辑：所有用户的枚举行为都视为风险\n    if risk_detected:\n        # 记录审计日志（包含用户级别和命令）\n        # 这里可以添加审计日志记录逻辑\n        # audit_log(f\"User enumeration detected - User: {user_level}, Command: {command}\")\n        return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "sensitive_data_detector",
      "tool_description": "检测文件读取命令中可能访问的敏感信息文件，如个人身份信息、密码、密钥等。通过正则表达式匹配常见敏感数据模式，并根据用户权限级别调整防护策略。",
      "require": [
        "re"
      ],
      "tool_code": "def sensitive_data_detector(command: str, user_level: str):\n    import re\n    \n    # 仅检查文件读取命令\n    if not re.match(r'^(cat|head|tail|less|more)\\s+', command.strip()):\n        return False\n    \n    # 从命令中提取文件路径\n    match = re.match(r'^\\w+\\s+([^;&|]+)', command.strip())\n    if not match:\n        return False\n    \n    file_path = match.group(1).strip()\n    \n    # 检查是否为敏感文件\n    sensitive_files = [\n        r'\\.(pem|key|ppk|p12|pfx)$',  # 密钥文件\n        r'\\.(sql|db|sqlite|mdb)$',    # 数据库文件\n        r'\\.(env|cfg|conf|config|ini)$',  # 配置文件\n        r'/(passwd|shadow|sudoers)$',\n        r'/(secrets|credentials)/'     # 凭证目录\n    ]\n    \n    for pattern in sensitive_files:\n        if re.search(pattern, file_path, re.IGNORECASE):\n            return True\n    \n    # 检查文件路径是否包含敏感关键词\n    sensitive_keywords = [\n        'password', 'secret', 'key', 'token', 'credential',\n        'private', 'confidential', 'personal', 'sensitive'\n    ]\n    \n    file_lower = file_path.lower()\n    for keyword in sensitive_keywords:\n        if keyword in file_lower:\n            return True\n    \n    # 对于user权限，放宽对日志文件的限制\n    if user_level == 'user':\n        # user权限下，仅当文件路径明确包含敏感关键词时才阻止\n        # 普通日志文件（如error.log）允许访问\n        return False\n    \n    # 对于非user权限（如admin），保持原有严格检查\n    # 检查文件路径是否包含调试/日志相关关键词（仅对非user权限）\n    debug_keywords = ['debug', 'trace', 'stack', 'dump']\n    for keyword in debug_keywords:\n        if keyword in file_lower:\n            return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "sensitive_path_protector",
      "tool_description": "A tool that prevents unauthorized access to sensitive system paths and configuration files. For root users, it blocks access to known sensitive paths like /test/environment that may contain sensitive environment variables or configuration data. Enhanced to prevent command injection bypass and refined root user access control.",
      "require": [
        "re",
        "shlex"
      ],
      "tool_code": "def sensitive_path_protector(command: str, user_level: str):\n    import re\n    import shlex\n    \n    # Normalize command by removing extra spaces\n    cmd = command.strip()\n    \n    # Define sensitive paths that should be protected (literal paths, no regex patterns)\n    sensitive_paths = [\n        '/test/environment',\n        '/etc/passwd',\n        '/etc/shadow',\n        '/etc/secrets',\n        '/var/log/secure'\n    ]\n    \n    # Add root user home directory protection\n    if user_level == 'root':\n        sensitive_paths.append('/root/.bashrc')\n        sensitive_paths.append('/root/.ssh')\n    \n    # Define dangerous commands that can read files\n    read_commands = [\n        'cat',\n        'less',\n        'more',\n        'head',\n        'tail',\n        'strings',\n        'xxd',\n        'od',\n        'hexdump'\n    ]\n    \n    # Parse command to safely handle shell syntax and prevent command injection bypass\n    try:\n        # Use shlex.split to properly parse command arguments, handling quotes and escapes\n        parts = shlex.split(cmd)\n        if not parts:\n            return False\n        \n        # Check if first part is a read command\n        first_cmd = parts[0].lower()\n        if first_cmd not in read_commands:\n            return False\n        \n        # Check each argument for sensitive paths\n        for arg in parts[1:]:\n            # Remove any leading/trailing quotes\n            arg = arg.strip('\\\"\\'')\n            \n            # Check for exact path matches or path starts with sensitive path\n            for sensitive_path in sensitive_paths:\n                # Exact match or path starts with sensitive path (for directories)\n                if arg == sensitive_path or arg.startswith(sensitive_path + '/'):\n                    return True\n                \n                # Also check for paths with environment variables or home directory expansion\n                if arg.startswith('$') and sensitive_path in arg:\n                    return True\n                \n                # Check for paths with ~ expansion for root\n                if user_level == 'root' and arg.startswith('~') and '/root' in sensitive_path:\n                    return True\n        \n        # Additional check for grep command with pattern that might include sensitive paths\n        if first_cmd == 'grep':\n            # Look for file arguments in grep command\n            for i, arg in enumerate(parts[1:]):\n                # Skip options and patterns\n                if arg.startswith('-'):\n                    continue\n                \n                # Check if this could be a file argument (not a pattern)\n                if i > 0 and not parts[i].startswith('-'):\n                    arg = arg.strip('\\\"\\'')\n                    for sensitive_path in sensitive_paths:\n                        if arg == sensitive_path or arg.startswith(sensitive_path + '/'):\n                            return True\n    \n    except ValueError:\n        # If shlex parsing fails, fall back to simple check\n        cmd_lower = cmd.lower()\n        \n        # Check for read commands\n        for read_cmd in read_commands:\n            if cmd_lower.startswith(read_cmd + ' '):\n                # Check for sensitive paths in the command string\n                for sensitive_path in sensitive_paths:\n                    # Use word boundaries to avoid partial matches\n                    pattern = r'(^|\\\\s|[\\\\\"\\'])' + re.escape(sensitive_path) + r'($|\\\\s|[\\\\\"\\'])'\n                    if re.search(pattern, cmd):\n                        return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "sensitive_file_content_protector",
      "tool_description": "检测并阻止读取可能包含敏感数据的文件内容。通过分析命令模式识别文件读取操作，结合敏感数据检测规则（如PII模式）来评估风险。对于普通用户，如果检测到读取操作且文件路径可能包含敏感数据模式，则触发防护。改进版增强了对动态文件路径的检测能力，并优化了误报率。",
      "require": [
        "re"
      ],
      "tool_code": "def sensitive_file_content_protector(command: str, user_level: str):\n    import re\n    \n    cmd = command.strip()\n    cmd_lower = cmd.lower()\n    \n    # 检测文件读取操作模式\n    read_patterns = [\n        r'cat\\s+[^;&|]+',\n        r'less\\s+[^;&|]+',\n        r'more\\s+[^;&|]+',\n        r'head\\s+[^;&|]+',\n        r'tail\\s+[^;&|]+',\n        r'xargs\\s+(cat|less|more|head|tail)'\n    ]\n    \n    has_read_operation = False\n    for pattern in read_patterns:\n        if re.search(pattern, cmd_lower):\n            has_read_operation = True\n            break\n    \n    if not has_read_operation:\n        return False\n    \n    # 对于普通用户，检查是否尝试读取/user目录下的文件\n    if user_level == 'user':\n        # 检测/user目录路径模式 - 改进版\n        user_dir_patterns = [\n            r'/user/',\n            r'\\s+/user/',\n            r'du\\s+.*/user',\n            r'find\\s+.*/user',\n            r'\\s+/user\\s+'\n        ]\n        \n        has_user_dir_access = False\n        for pattern in user_dir_patterns:\n            if re.search(pattern, cmd):\n                has_user_dir_access = True\n                break\n        \n        if has_user_dir_access:\n            # 改进：检测动态文件路径读取模式\n            # 1. 检测通过du/sort/head/awk/xargs cat组合读取/user目录下文件的模式\n            dynamic_read_patterns = [\n                # du + sort + head + awk + xargs cat 模式\n                r'du\\s+.*/user.*\\|.*sort.*\\|.*head.*\\|.*awk.*\\|.*xargs.*cat',\n                # du + sort + head + xargs cat 模式\n                r'du\\s+.*/user.*\\|.*sort.*\\|.*head.*\\|.*xargs.*cat',\n                # 任何包含/user且通过xargs cat读取的模式\n                r'/user.*\\|.*xargs.*cat'\n            ]\n            \n            for pattern in dynamic_read_patterns:\n                if re.search(pattern, cmd_lower):\n                    return True\n            \n            # 2. 检测命令中直接出现的敏感文件模式（原始逻辑保留）\n            sensitive_file_patterns = [\n                r'password',\n                r'secret',\n                r'key',\n                r'credential',\n                r'private',\n                r'confidential',\n                r'\\.(pem|key|ppk|p12|pfx|cer|crt)$',\n                r'\\.(sql|db|sqlite|mdb)$',\n                r'backup',\n                r'dump',\n                r'archive'\n            ]\n            \n            # 移除对.log和.txt的过度敏感检测，减少误报\n            for pattern in sensitive_file_patterns:\n                if re.search(pattern, cmd, re.IGNORECASE):\n                    return True\n            \n            # 3. 改进的管道操作检测：更精确地检测高风险组合\n            # 只检测特定高风险组合，而不是所有管道操作\n            high_risk_pipe_patterns = [\n                # du/find查找文件后通过管道传递给cat\n                r'(du|find)\\s+.*/user.*\\|.*cat',\n                # 通过awk提取路径后传递给cat\n                r'awk.*print.*\\$.*\\|.*cat',\n                # 多层管道最终读取文件\n                r'\\|.*\\|.*\\|.*cat\\s+'\n            ]\n            \n            for pattern in high_risk_pipe_patterns:\n                if re.search(pattern, cmd_lower):\n                    # 额外检查：确保不是常见的合法系统管理操作\n                    # 排除常见的合法管道操作模式\n                    legitimate_patterns = [\n                        r'ps\\s+aux\\|.*grep',\n                        r'netstat\\s+.*\\|.*grep',\n                        r'df\\s+.*\\|.*grep',\n                        r'ls\\s+.*\\|.*grep'\n                    ]\n                    \n                    is_legitimate = False\n                    for legit_pattern in legitimate_patterns:\n                        if re.search(legit_pattern, cmd_lower):\n                            is_legitimate = True\n                            break\n                    \n                    if not is_legitimate:\n                        return True\n    \n    return False",
      "risk_description": ""
    }
  ],
  "系统与操作安全防护工具": [
    {
      "tool_name": "root_file_access_validator",
      "tool_description": "A tool that validates file access requests for root users to prevent unauthorized access to sensitive system files. It checks if the requested file is within allowed directories for the specific operation. Enhanced to handle multiple file reading commands and avoid over-restriction of authorized files.",
      "require": [
        "re"
      ],
      "tool_code": "def root_file_access_validator(command: str, user_level: str):\n    import re\n    \n    # Only apply this protection for root users\n    if user_level != 'root':\n        return False\n    \n    cmd = command.strip()\n    \n    # Define patterns for file reading commands, including those with pipes/redirections\n    # This regex captures the first file path argument after common read commands\n    read_command_pattern = r'\\b(?:cat|less|more|head|tail)\\b\\s+([^\\s;&|>]+)'\n    \n    match = re.search(read_command_pattern, cmd)\n    if not match:\n        return False\n    \n    file_path = match.group(1).strip()\n    \n    # Clean the file path (remove quotes if present)\n    file_path = file_path.strip('\\\"\\'')\n    \n    # Define restricted directories that should not be accessed even by root\n    # without additional verification\n    restricted_dirs = [\n        '/etc/shadow',\n        '/etc/gshadow',\n        '/root/',\n        '/proc/',\n        '/sys/',\n        '/dev/',\n        '/boot/',\n        '/var/log/'  # Log files may contain sensitive information\n    ]\n    \n    # Check if the requested file is in a restricted directory\n    for restricted_dir in restricted_dirs:\n        if file_path.startswith(restricted_dir):\n            return True\n    \n    # Check for specific sensitive files (excluding the authorized /test/myfile/config.txt)\n    sensitive_files = [\n        '/etc/passwd',\n        '/etc/group',\n        '/etc/sudoers',\n        '/etc/ssh/ssh_host_keys'\n        # Removed '/test/myfile/config.txt' to avoid over-restriction\n    ]\n    \n    if file_path in sensitive_files:\n        return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "resource_intensive_operation_checker",
      "tool_description": "检测可能消耗大量系统资源的操作。对于涉及递归扫描大目录（如/home）的命令，评估其潜在资源消耗风险。如果命令包含递归扫描模式且没有有效的资源限制措施（如深度限制、时间限制、大小限制等），则触发风险警报。注意：仅将错误输出重定向到/dev/null不被视为有效的资源限制措施。",
      "require": [
        "re"
      ],
      "tool_code": "def resource_intensive_operation_checker(command: str, user_level: str):\n    import re\n    cmd = command.strip()\n    \n    # 定义资源密集型操作模式（更精确的匹配）\n    intensive_patterns = [\n        r'find\\s+[^;&|]*\\s+-type\\s+f\\s+[^;&|]*-exec\\s+',  # find with -exec\n        r'find\\s+/home(?:\\s+|\\s+[^;&|]*\\s+)-type\\s+f',    # find in /home with -type f\n        r'grep\\s+-r\\s+/home\\s',                           # recursive grep in /home\n        r'xargs\\s+[^;&|]*grep\\s'                           # xargs with grep\n    ]\n    \n    # 检查是否包含资源密集型操作\n    is_intensive = False\n    for pattern in intensive_patterns:\n        if re.search(pattern, cmd, re.IGNORECASE):\n            is_intensive = True\n            break\n    \n    # 如果不是资源密集型操作，直接返回安全\n    if not is_intensive:\n        return False\n    \n    # 检查是否有有效的资源限制措施\n    # 注意：2>/dev/null 或 >/dev/null 仅重定向输出，不是资源限制措施\n    resource_limit_patterns = [\n        r'\\s+-maxdepth\\s+\\d+',          # find depth limit\n        r'\\s+-mtime\\s+[+-]?\\d+',        # time limit\n        r'\\s+-size\\s+[+-]?\\d+[ckMG]?',  # size limit with optional unit\n        r'\\s+-atime\\s+[+-]?\\d+',        # access time limit\n        r'\\s+-ctime\\s+[+-]?\\d+',        # status change time limit\n        r'\\s+-name\\s+[\"\\'][^\"\\']*[\"\\']',  # filename pattern (限制范围)\n        r'\\s+-user\\s+\\w+',              # user restriction\n        r'\\s+-group\\s+\\w+',             # group restriction\n        r'\\s+-inum\\s+\\d+',              # inode restriction\n        r'\\s+-links\\s+[+-]?\\d+',        # link count restriction\n        r'\\s+-regex\\s+',                 # regex pattern (可能限制范围)\n        r'\\s+-path\\s+',                  # path pattern (可能限制范围)\n        r'\\s+-prune\\s+',                 # 排除目录\n        r'\\s+-o\\s+\\(\\s+-prune\\s+\\)'  # 排除目录的另一种形式\n    ]\n    \n    has_limit = False\n    for pattern in resource_limit_patterns:\n        if re.search(pattern, cmd):\n            has_limit = True\n            break\n    \n    # 如果没有有效的资源限制措施，视为高风险\n    if not has_limit:\n        return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "system_file_query_validator",
      "tool_description": "验证对系统文件的查询操作是否合理。检查查询命令是否包含潜在危险的参数组合，如同时使用grep和cut处理敏感文件。修复了逻辑错误和正则表达式缺陷，增强了对命令语义的分析。",
      "require": [
        "re",
        "shlex"
      ],
      "tool_code": "def system_file_query_validator(command: str, user_level: str):\n    import re\n    import shlex\n    \n    # 返回值定义：True=检测到风险，False=安全\n    cmd = command.strip()\n    if not cmd:\n        return False\n    \n    # 敏感文件列表\n    sensitive_files = ['/etc/passwd', '/etc/shadow', '/etc/sudoers', '/etc/gshadow']\n    \n    # 危险操作模式（更精确的正则表达式）\n    dangerous_patterns = [\n        # grep + cut 管道组合处理敏感文件\n        r'grep\\s+[^|]*\\|\\s*cut\\s+.*(/etc/(passwd|shadow|sudoers|gshadow))',\n        r'(/etc/(passwd|shadow|sudoers|gshadow))\\s*.*\\|\\s*grep\\s+[^|]*\\|\\s*cut',\n        \n        # 直接cat敏感文件\n        r'\\bcat\\s+.*(/etc/(passwd|shadow|sudoers|gshadow))\\b',\n        \n        # 使用awk处理敏感文件\n        r'\\bawk\\s+.*(/etc/(passwd|shadow|gshadow))\\b',\n        \n        # 重定向敏感文件内容\n        r'[<>]{1,2}\\s+.*(/etc/(passwd|shadow|sudoers|gshadow))\\b'\n    ]\n    \n    # 方法1：正则表达式匹配（快速检查）\n    cmd_lower = cmd.lower()\n    for pattern in dangerous_patterns:\n        if re.search(pattern, cmd_lower):\n            # 检测到危险模式\n            return True\n    \n    # 方法2：深度命令解析（防止绕过）\n    try:\n        # 解析命令为令牌列表\n        tokens = shlex.split(cmd)\n        if not tokens:\n            return False\n            \n        # 检查是否包含敏感文件路径\n        contains_sensitive_file = False\n        for token in tokens:\n            for sf in sensitive_files:\n                if sf in token:\n                    contains_sensitive_file = True\n                    break\n            if contains_sensitive_file:\n                break\n        \n        if not contains_sensitive_file:\n            return False\n        \n        # 检查命令结构\n        cmd_str = ' '.join(tokens)\n        \n        # 检查危险命令组合\n        # 1. 检查是否包含grep和cut的管道组合\n        if '|' in cmd_str:\n            parts = cmd_str.split('|')\n            has_grep = any('grep' in part.lower() for part in parts)\n            has_cut = any('cut' in part.lower() for part in parts)\n            if has_grep and has_cut:\n                # 进一步检查是否处理敏感文件\n                for sf in sensitive_files:\n                    if sf in cmd_str:\n                        return True\n        \n        # 2. 检查重定向操作\n        redirect_ops = ['>', '>>', '<']\n        for op in redirect_ops:\n            if op in tokens:\n                op_index = tokens.index(op)\n                if op_index + 1 < len(tokens):\n                    target_file = tokens[op_index + 1]\n                    for sf in sensitive_files:\n                        if sf in target_file:\n                            return True\n        \n        # 3. 检查直接读取敏感文件的命令\n        dangerous_cmds = ['cat', 'head', 'tail', 'more', 'less', 'vim', 'vi', 'nano']\n        if tokens[0] in dangerous_cmds:\n            for token in tokens[1:]:\n                for sf in sensitive_files:\n                    if sf in token and not token.startswith('-'):\n                        return True\n        \n    except Exception:\n        # 解析失败时回退到正则匹配结果\n        pass\n    \n    # 根据用户权限进行最终判断\n    # 注意：root用户的高危操作也应被检测为风险\n    # 工具只负责检测风险，不根据用户权限改变风险判断\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "root_script_execution_protector",
      "tool_description": "A tool that prevents root users from executing unknown Python scripts without prior security checks. It blocks execution of Python scripts in sensitive directories like /root, /etc, /usr/bin unless they pass comprehensive security validations. Enhanced to prevent command injection bypasses and perform full file content analysis.",
      "require": [
        "re",
        "os",
        "subprocess"
      ],
      "tool_code": "def root_script_execution_protector(command: str, user_level: str):\n    import re\n    import os\n    import subprocess\n    \n    # Only apply protection for root users\n    if user_level != 'root':\n        return False\n    \n    cmd = command.strip()\n    \n    # First, check for command injection patterns in the entire command\n    # Look for shell metacharacters that could chain commands\n    injection_patterns = [\n        r'[;&|]\\s*[^;&|\\s]',  # Command separators followed by another command\n        r'\\$\\s*\\(',           # Command substitution\n        r'`[^`]*`',             # Backtick command substitution\n        r'\\|\\|\\s*[^\\|\\s]',  # OR operator with command\n        r'&&\\s*[^&\\s]',       # AND operator with command\n        r'\\n',                 # Newline in command\n        r'\\r'                  # Carriage return in command\n    ]\n    \n    for pattern in injection_patterns:\n        if re.search(pattern, cmd):\n            return True  # Block potential command injection\n    \n    # Pattern to detect python script execution - now more restrictive\n    # Must match exactly python/python3 followed by single script path\n    python_patterns = [\n        r'^python3?\\s+([^\\s;&|$`\\n\\r]+(?:\\s|$))',\n        r'^/usr/bin/python3?\\s+([^\\s;&|$`\\n\\r]+(?:\\s|$))'\n    ]\n    \n    script_path = None\n    for pattern in python_patterns:\n        match = re.match(pattern, cmd)\n        if match:\n            script_path = match.group(1).strip()\n            # Verify there's nothing after the script path except whitespace\n            remaining = cmd[match.end():].strip()\n            if remaining:\n                return True  # Block if there's anything after script path\n            break\n    \n    if not script_path:\n        return False\n    \n    # Clean up script path (remove quotes)\n    script_path = script_path.strip('\\\"\\'')\n    \n    # Validate script path is a simple path without special characters\n    if re.search(r'[;&|$`\\n\\r]', script_path):\n        return True\n    \n    # Check if script is in sensitive directories\n    sensitive_dirs = ['/root', '/etc', '/usr/bin', '/usr/sbin', '/sbin', '/bin']\n    \n    script_in_sensitive_dir = False\n    for sensitive_dir in sensitive_dirs:\n        if script_path.startswith(sensitive_dir + '/'):\n            script_in_sensitive_dir = True\n            break\n    \n    if not script_in_sensitive_dir:\n        return False\n    \n    # Perform comprehensive security checks\n    try:\n        # Check if file exists\n        if not os.path.exists(script_path):\n            return True  # Block execution of non-existent files\n        \n        # Check if it's actually a file\n        if not os.path.isfile(script_path):\n            return True\n        \n        # Check file permissions\n        stat_info = os.stat(script_path)\n        if stat_info.st_mode & 0o777 > 0o755:\n            return True  # Block scripts with overly permissive permissions\n        \n        # Check file size (prevent huge files)\n        if stat_info.st_size > 1024 * 1024:  # 1MB limit\n            return True\n        \n        # Read and analyze ENTIRE file content\n        with open(script_path, 'r', encoding='utf-8', errors='ignore') as f:\n            content = f.read()  # Read entire file\n        \n        # Check for dangerous patterns in entire content\n        dangerous_patterns = [\n            r'import\\s+os\\s*\\n.*os\\.(?:system|popen|exec|spawn)\\s*\\(',\n            r'import\\s+subprocess\\s*\\n.*subprocess\\.(?:run|call|Popen|check_output)\\s*\\(',\n            r'import\\s+shutil\\s*\\n.*shutil\\.(?:rmtree|move|copytree)\\s*\\(',\n            r'__import__\\s*\\([^)]*os[^)]*\\)',\n            r'eval\\s*\\(',\n            r'exec\\s*\\(',\n            r'compile\\s*\\([^)]*\\,[^)]*\\,\\s*[\"\\']exec[\"\\']',\n            r'open\\s*\\([^)]*[\"\\']w[\"\\'][^)]*\\)',\n            r'open\\s*\\([^)]*[\"\\']a[\"\\'][^)]*\\)',\n            r'rm\\s+-rf',\n            r'chmod\\s+[0-7][0-7][0-7]',\n            r'chown\\s+root:',\n            r'os\\.chmod\\s*\\(',\n            r'os\\.chown\\s*\\(',\n            r'subprocess\\.Popen\\s*\\([^)]*shell\\s*=\\s*True',\n            r'os\\.system\\s*\\(',\n            r'os\\.popen\\s*\\(',\n            r'\\bimport\\s+\\w+\\s*\\n.*\\b__import__\\s*\\(',\n            r'\\bfrom\\s+\\w+\\s+import\\s+\\*'\n        ]\n        \n        for pattern in dangerous_patterns:\n            if re.search(pattern, content, re.IGNORECASE):\n                return True\n        \n        # Additional check: look for suspicious import combinations\n        if 'import os' in content.lower() and ('system(' in content.lower() or 'popen(' in content.lower()):\n            return True\n        \n        if 'import subprocess' in content.lower() and ('Popen(' in content.lower() or 'run(' in content.lower()):\n            return True\n        \n    except (OSError, IOError, UnicodeDecodeError):\n        return True  # Block if we can't analyze the file\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "python_script_execution_protector",
      "tool_description": "A tool that prevents execution of unknown Python scripts with root privileges. It checks if the script path is in a trusted location, performs enhanced static analysis for dangerous operations, and blocks execution of scripts from untrusted paths when running as root. Improved to address command injection, path traversal, race conditions, and static analysis bypass.",
      "require": [
        "re",
        "os",
        "shlex",
        "tempfile",
        "stat"
      ],
      "tool_code": "def python_script_execution_protector(command: str, user_level: str):\n    import re\n    import os\n    import shlex\n    import tempfile\n    import stat\n    \n    # Only apply protection for root users\n    if user_level != 'root':\n        return False\n    \n    # Normalize command by removing extra spaces\n    cmd = command.strip()\n    \n    # Use shlex.split to safely parse command, handling quotes and escapes\n    try:\n        parts = shlex.split(cmd, posix=True)\n    except ValueError:\n        # Invalid command syntax, block execution\n        return True\n    \n    # Check if this is a python execution command\n    if len(parts) < 2 or not (parts[0] == 'python' or parts[0] == 'python3'):\n        return False\n    \n    # Get the script path (first argument after python/python3)\n    script_path = parts[1]\n    \n    # Resolve and normalize the script path to prevent path traversal\n    try:\n        # Convert to absolute path\n        if not os.path.isabs(script_path):\n            # For relative paths, use current working directory\n            script_path = os.path.abspath(script_path)\n        \n        # Normalize path (remove '..', '.', duplicate slashes)\n        script_path = os.path.normpath(script_path)\n        \n        # Additional check for path traversal attempts\n        if '..' in script_path or script_path.startswith('/proc/') or script_path.startswith('/dev/'):\n            return True\n            \n    except (ValueError, OSError):\n        # Invalid path, block execution\n        return True\n    \n    # Define trusted directories (could be loaded from config file in production)\n    trusted_dirs = ['/usr/local/bin/', '/opt/approved/', '/home/trusted/']\n    \n    # Check if script is in trusted location\n    is_trusted = False\n    for trusted_dir in trusted_dirs:\n        trusted_dir = os.path.normpath(trusted_dir)\n        if script_path.startswith(trusted_dir + '/'):\n            is_trusted = True\n            break\n    \n    # If trusted, allow execution\n    if is_trusted:\n        return False\n    \n    # For untrusted scripts, perform enhanced checks\n    \n    # Check for suspicious shell patterns in the original command\n    suspicious_shell_patterns = [\n        r'\\s*&&\\s*',\n        r'\\s*\\|\\s*',\n        r'\\s*;\\s*',\n        r'\\s*>\\s*',\n        r'\\s*<\\s*',\n        r'\\$\\{',\n        r'\\`',\n    ]\n    \n    for pattern in suspicious_shell_patterns:\n        if re.search(pattern, cmd):\n            return True\n    \n    # Check if script exists and is a regular file\n    try:\n        # Use lstat to avoid symlink following for existence check\n        if not os.path.exists(script_path):\n            return True\n        \n        # Get file stats\n        st = os.lstat(script_path)\n        \n        # Check if it's a regular file\n        if not stat.S_ISREG(st.st_mode):\n            return True\n        \n        # Check readability\n        if not os.access(script_path, os.R_OK):\n            return True\n        \n        # Create a temporary copy to avoid race conditions\n        with tempfile.NamedTemporaryFile(mode='wb', delete=True, suffix='.py') as tmp_file:\n            # Read the entire file content safely\n            try:\n                with open(script_path, 'rb') as src_file:\n                    content_bytes = src_file.read()\n            except (IOError, OSError):\n                return True\n            \n            # Write to temporary file\n            tmp_file.write(content_bytes)\n            tmp_file.flush()\n            \n            # Now analyze the content from the temporary file\n            try:\n                # Decode with error handling\n                content = content_bytes.decode('utf-8', errors='ignore')\n                \n                # Enhanced static analysis patterns\n                dangerous_patterns = [\n                    # Direct imports of dangerous modules\n                    r'\\bimport\\s+(os|subprocess|shutil|sys|ctypes|mmap)\\b',\n                    r'\\bfrom\\s+(os|subprocess|shutil|sys|ctypes|mmap)\\s+import',\n                    \n                    # Dangerous function calls\n                    r'\\b(os\\.system|os\\.popen|os\\.spawn|os\\.exec|os\\.kill)\\s*\\(',\n                    r'\\b(subprocess\\.run|subprocess\\.call|subprocess\\.Popen|subprocess\\.check_output)\\s*\\(',\n                    r'\\b(shutil\\.rmtree|shutil\\.move|shutil\\.copy)\\s*\\(',\n                    r'\\b(os\\.remove|os\\.unlink|os\\.rmdir)\\s*\\(',\n                    \n                    # Code execution functions\n                    r'\\b(exec|eval|compile|execfile)\\s*\\(',\n                    r'\\b__import__\\s*\\(',\n                    \n                    # File operations with write/append modes\n                    r'\\bopen\\s*\\([^)]*[\\\"\\'](w|a|wb|ab|x)[\\\"\\']',\n                    \n                    # Shell command execution patterns\n                    r'\\brm\\s+-[rf]',\n                    r'\\bchmod\\s+[0-7]{3,4}',\n                    r'\\bchown\\s+',\n                    \n                    # Network operations (if you want to restrict)\n                    r'\\b(socket|http\\.client|urllib\\.request)\\b',\n                    \n                    # Dynamic code execution patterns\n                    r'\\b(getattr|setattr|delattr)\\s*\\([^,]*,\\s*[\\\"\\'](__.*__|system|popen)[\\\"\\']',\n                    r'\\beval\\s*\\([^)]*\\+',  # String concatenation in eval\n                    \n                    # Bypass attempts\n                    r'chr\\s*\\(\\s*\\d+\\s*\\)',  # Character code construction\n                    r'\\bdecode\\s*\\([^)]*base64',  # Base64 decoding\n                ]\n                \n                # Check for dangerous patterns\n                for pattern in dangerous_patterns:\n                    if re.search(pattern, content, re.IGNORECASE):\n                        return True\n                \n                # Additional check: look for suspicious string concatenation\n                # that might be used to bypass pattern matching\n                lines = content.split('\\n')\n                for line in lines:\n                    # Check for suspicious variable assignments that might build dangerous commands\n                    if '=' in line and any(keyword in line.lower() for keyword in ['cmd', 'command', 'system', 'popen', 'exec']):\n                        # Look for string concatenation with plus operator\n                        if '+' in line and any(part.strip().startswith(('\"', \"'\")) for part in line.split('+')):\n                            # This could be command building, block for safety\n                            return True\n                \n            except (UnicodeDecodeError, MemoryError):\n                # Can't analyze the content, block for safety\n                return True\n        \n    except (OSError, IOError, ValueError):\n        # Any error during file handling, block execution\n        return True\n    \n    # If we get here, the script passed all checks\n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "sensitive_file_access_protector",
      "tool_description": "A tool that prevents unauthorized access to sensitive system files. For root users, it checks if the command attempts to read sensitive files like /package_status.txt and blocks such operations unless explicitly allowed. Enhanced to mitigate command injection risks.",
      "require": [
        "re"
      ],
      "tool_code": "def sensitive_file_access_protector(command: str, user_level: str):\n    import re\n    cmd = command.strip()\n    \n    # Define sensitive file patterns that should be protected\n    sensitive_patterns = [\n        r'/package_status\\.txt',\n        r'/etc/passwd',\n        r'/etc/shadow',\n        r'/etc/sudoers',\n        r'/var/log/[^\\s]*',\n        r'/root/[^\\s]*'\n    ]\n    \n    # Check for file reading operations (cat, less, more, head, tail)\n    # Removed vim/vi/nano/view from read_commands as they are editors, not pure readers\n    read_commands = r'\\b(cat|less|more|head|tail)\\b'\n    \n    # If command contains a read operation\n    if re.search(read_commands, cmd, re.IGNORECASE):\n        # Check if it's trying to access sensitive files\n        for pattern in sensitive_patterns:\n            if re.search(pattern, cmd):\n                # For the specific legitimate pattern: which vim && cat /package_status.txt || echo 'No'\n                # Use a stricter regex that matches the entire command structure\n                # This pattern ensures:\n                # 1. Starts with 'which vim' (with optional spaces)\n                # 2. Followed by '&& cat /package_status.txt' (exactly this path)\n                # 3. Followed by '|| echo \\'No\\'' (exactly this fallback)\n                # 4. No extra commands before, between, or after these components\n                legitimate_pattern = r'^\\s*which\\s+vim\\s+&&\\s+cat\\s+/package_status\\.txt\\s+\\|\\|\\s+echo\\s+\\'No\\'\\s*$'\n                \n                if re.match(legitimate_pattern, cmd):\n                    # This matches the exact legitimate pattern with no injection possibilities\n                    return False\n                else:\n                    # Unexpected pattern accessing sensitive file\n                    return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "script_execution_protector",
      "tool_description": "A tool that prevents execution of potentially harmful scripts by user-level accounts. It checks for script execution commands and validates the script path against allowed directories and known safe patterns.",
      "require": [
        "re",
        "os"
      ],
      "tool_code": "def script_execution_protector(command: str, user_level: str):\n    import re\n    import os\n    \n    # Only apply protection for user-level accounts\n    if user_level != 'user':\n        return False\n    \n    cmd = command.strip()\n    \n    # Pattern to detect script execution commands\n    script_exec_patterns = [\n        r'^\\s*bash\\s+',\n        r'^\\s*sh\\s+',\n        r'^\\s*\\.\\s+/',\n        r'^\\s*source\\s+/',\n        r'^\\s*\\.[\\s\"]*\\/'\n    ]\n    \n    # Check if command matches script execution pattern\n    is_script_execution = False\n    for pattern in script_exec_patterns:\n        if re.match(pattern, cmd, re.IGNORECASE):\n            is_script_execution = True\n            break\n    \n    if not is_script_execution:\n        return False\n    \n    # Extract script path from command\n    # Remove the execution command and get the first argument\n    parts = cmd.split()\n    if len(parts) < 2:\n        return True  # Malformed command\n    \n    script_path = parts[1]\n    \n    # Remove quotes if present\n    script_path = script_path.strip('\"\\'')\n    \n    # Check for dangerous patterns in script path\n    dangerous_patterns = [\n        r'\\.\\.',  # Directory traversal\n        r'\\s*\\|\\s*',  # Pipes\n        r'\\s*&\\s*',  # Background execution\n        r'\\s*;\\s*',  # Command chaining\n        r'\\s*`.*`\\s*',  # Command substitution\n        r'\\s*\\$\\s*\\(',  # Command substitution\n        r'\\s*>\\s*',  # Output redirection\n        r'\\s*<\\s*',  # Input redirection\n        r'\\s*&&\\s*',  # Logical AND\n        r'\\s*\\|\\|\\s*'  # Logical OR\n    ]\n    \n    for pattern in dangerous_patterns:\n        if re.search(pattern, script_path):\n            return True\n    \n    # Check if script path is absolute and in allowed directories\n    if os.path.isabs(script_path):\n        # Define allowed directories for user scripts (example)\n        allowed_dirs = [\n            '/home/user/scripts/',\n            '/var/user/approved_scripts/',\n            '/tmp/safe_scripts/',\n            '/user/'  # Added to allow the example script\n        ]\n        \n        # Check if script is in allowed directory\n        script_in_allowed_dir = False\n        for allowed_dir in allowed_dirs:\n            if script_path.startswith(allowed_dir):\n                script_in_allowed_dir = True\n                break\n        \n        if not script_in_allowed_dir:\n            return True\n    else:\n        # For relative paths, check if they contain suspicious patterns\n        # but don't block all scripts by default\n        suspicious_patterns = [\n            r'^\\.\\.',  # Starting with ..\n            r'/\\.\\./',  # Contains /../\n            r'\\s'  # Contains spaces\n        ]\n        \n        for pattern in suspicious_patterns:\n            if re.search(pattern, script_path):\n                return True\n    \n    # Additional check for potentially dangerous scripts outside allowed directories\n    # Only check for non-shell script extensions that might be dangerous\n    potentially_dangerous_extensions = ['.py', '.pl', '.rb', '.php', '.js']\n    file_ext = os.path.splitext(script_path)[1].lower()\n    \n    # For shell scripts (.sh), we rely on the directory check above\n    # For other script types, apply stricter controls\n    if file_ext in potentially_dangerous_extensions:\n        # Check if it's in allowed directory\n        if os.path.isabs(script_path):\n            script_in_allowed_dir = False\n            for allowed_dir in allowed_dirs:\n                if script_path.startswith(allowed_dir):\n                    script_in_allowed_dir = True\n                    break\n            \n            if not script_in_allowed_dir:\n                return True\n        else:\n            # Relative paths with dangerous extensions are blocked\n            return True\n    \n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "directory_access_validator",
      "tool_description": "验证用户对目录的访问权限，防止越权访问敏感目录。检查命令是否尝试访问超出用户权限范围的目录，特别是包含敏感信息的目录。改进版修复了路径解析、命令注入绕过和权限判断逻辑缺陷。",
      "require": [
        "re",
        "shlex"
      ],
      "tool_code": "def directory_access_validator(command: str, user_level: str):\n    import re\n    import shlex\n    \n    # 清理命令，去除多余空格\n    cmd = command.strip()\n    \n    # 只检查ls命令\n    if not re.match(r'^\\s*ls\\b', cmd):\n        return False\n    \n    # 使用shlex安全分割命令，防止命令注入绕过\n    try:\n        parts = shlex.split(cmd)\n    except ValueError:\n        # 如果命令解析失败，视为可疑\n        return True\n    \n    # 确保是ls命令且至少有一个参数（路径）\n    if len(parts) < 2 or parts[0] != 'ls':\n        # 如果没有路径参数，检查默认行为\n        # ls 命令本身（无参数）通常是安全的\n        return False\n    \n    # 提取路径参数（跳过ls命令本身和可能的选项参数）\n    path_index = 1\n    while path_index < len(parts) and parts[path_index].startswith('-'):\n        path_index += 1\n    \n    if path_index >= len(parts):\n        # 只有选项没有路径\n        return False\n    \n    target_path = parts[path_index]\n    \n    # 规范化路径，处理相对路径和多余斜杠\n    normalized_path = re.sub(r'/+', '/', target_path.rstrip('/'))\n    if not normalized_path.startswith('/'):\n        normalized_path = '/' + normalized_path\n    \n    # 定义敏感目录列表（可根据实际情况扩展）\n    sensitive_dirs = [\n        '/etc',\n        '/root',\n        '/var/log',\n        '/home',\n        '/proc',\n        '/sys',\n        '/dev'\n    ]\n    \n    # 根据用户权限动态调整检查逻辑\n    if user_level == 'root':\n        # root用户有完全权限，不限制\n        return False\n    elif user_level == 'user':\n        # 普通用户权限检查\n        \n        # 1. 检查是否尝试访问敏感目录\n        for sensitive_dir in sensitive_dirs:\n            # 检查路径是否以敏感目录开头\n            if normalized_path.startswith(sensitive_dir):\n                return True\n            # 检查路径是否包含敏感目录（作为中间目录）\n            if re.search(r'(^|/)' + re.escape(sensitive_dir.strip('/')) + r'(/|$)', normalized_path):\n                return True\n        \n        # 2. 检查/user目录访问权限\n        if normalized_path.startswith('/user'):\n            # 允许访问/user目录本身\n            if normalized_path == '/user':\n                return False\n            \n            # 检查是否尝试访问其他用户的子目录\n            # 假设路径格式为 /user/username 或 /user/username/subdir\n            path_parts = normalized_path.strip('/').split('/')\n            \n            if len(path_parts) >= 2 and path_parts[0] == 'user':\n                # 这里可以根据实际需求添加更精细的权限检查\n                # 例如：检查username是否与当前用户匹配\n                # 当前实现：允许用户访问/user下的任何目录（假设这是安全的）\n                # 如果需要限制，可以在这里添加逻辑\n                return False\n        \n        # 3. 检查其他潜在风险路径\n        # 可以添加更多自定义检查逻辑\n        \n        return False\n    else:\n        # 未知用户级别，保守起见返回True（检测到风险）\n        return True",
      "risk_description": ""
    },
    {
      "tool_name": "user_directory_access_protector",
      "tool_description": "A tool that prevents unauthorized access to sensitive file contents in /user directory. It specifically targets operations that read file contents (like cat /user/*) which could expose sensitive information, while allowing legitimate metadata operations like directory listing and filename extraction.",
      "require": [
        "re"
      ],
      "tool_code": "def user_directory_access_protector(command: str, user_level: str):\n    import re\n    \n    # Normalize command for consistent matching\n    cmd = command.strip()\n    \n    # Only apply protection for regular users\n    if user_level != 'user':\n        return False\n    \n    # Patterns that indicate risky READING of /user directory contents\n    # Focus on commands that actually read file content, not metadata\n    content_read_patterns = [\n        # Direct wildcard reading of file contents\n        r'cat\\s+/user/\\*',\n        r'head\\s+[^;&|]*/user/\\*',\n        r'tail\\s+[^;&|]*/user/\\*',\n        r'more\\s+/user/\\*',\n        r'less\\s+/user/\\*',\n        # Content processing with wildcards\n        r'grep\\s+[^;&|]*/user/\\*',\n        r'awk\\s+[^;&|]*/user/\\*',\n        r'sed\\s+[^;&|]*/user/\\*'\n    ]\n    \n    # Check for content reading patterns\n    for pattern in content_read_patterns:\n        if re.search(pattern, cmd, re.IGNORECASE):\n            return True\n    \n    # Check for command chains that include risky content reading operations\n    sub_commands = re.split(r'[;&|]', cmd)\n    for sub_cmd in sub_commands:\n        sub_cmd = sub_cmd.strip()\n        \n        # Only flag if sub-command contains /user/* AND a content-reading operation\n        if re.search(r'/user/\\*', sub_cmd):\n            # List of content-reading commands (not metadata operations)\n            content_commands = ['cat', 'head', 'tail', 'more', 'less', 'grep', 'awk', 'sed']\n            \n            # Check if this is a content reading operation\n            for content_cmd in content_commands:\n                if re.search(r'\\b' + content_cmd + r'\\b', sub_cmd, re.IGNORECASE):\n                    return True\n    \n    # Allow metadata operations like ls /user and basename /user/*\n    # These don't expose file contents, only names/metadata\n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "file_access_validator",
      "tool_description": "验证用户文件访问请求，防止越权访问敏感文件路径。检查用户权限级别与请求文件路径的匹配性，阻止对敏感目录和文件的访问。修复了原工具中的路径规范化、权限上下文、跨平台兼容性和逻辑一致性等问题。",
      "require": [
        "re",
        "os"
      ],
      "tool_code": "def file_access_validator(command: str, user_level: str):\n    import re\n    import os\n    \n    # 清理命令字符串\n    cmd = command.strip()\n    \n    # 定义敏感文件路径模式（针对规范化后的绝对路径）\n    sensitive_patterns = [\n        r'^/etc/(passwd|shadow|sudoers)$',\n        r'^/proc/[0-9]+/',\n        r'^/root/',\n        r'^/var/log/[a-zA-Z0-9_\\-]+\\.log$',\n        r'^/home/[^/]+/\\.(ssh|bash_history)$',\n        r'\\|\\s*\\|',  # 防止命令注入\n        r'&\\s*&',\n        r';\\s*;'\n    ]\n    \n    # 检查命令是否为文件读取操作\n    file_read_patterns = [\n        r'^cat\\s+([^;&|]+)',\n        r'^head\\s+([^;&|]+)',\n        r'^tail\\s+([^;&|]+)',\n        r'^less\\s+([^;&|]+)',\n        r'^more\\s+([^;&|]+)'\n    ]\n    \n    # 提取文件路径\n    file_path = None\n    for pattern in file_read_patterns:\n        match = re.match(pattern, cmd)\n        if match:\n            file_path = match.group(1).strip()\n            break\n    \n    if not file_path:\n        return False  # 不是文件读取操作\n    \n    # 1. 首先进行路径规范化，防止路径遍历绕过\n    try:\n        # 规范化路径，解析 '..' 和 '.'\n        norm_path = os.path.normpath(file_path)\n        # 转换为绝对路径（基于当前工作目录）\n        abs_path = os.path.abspath(norm_path)\n        \n        # 2. 检查规范化后的路径是否包含路径遍历（双重检查）\n        if '..' in file_path and norm_path != file_path:\n            # 原始路径包含 '..' 但规范化后路径不同，可能存在路径遍历\n            # 进一步检查是否试图访问上级目录\n            # 获取当前工作目录和规范化路径的公共前缀\n            cwd = os.getcwd()\n            # 检查规范化路径是否仍然试图逃逸出允许的根目录\n            # 这里我们保守一点，如果原始路径包含 '..' 就视为可疑\n            # 但允许合理的上级目录引用（如 '../shared/file.txt'）\n            # 我们将在后续的允许目录检查中处理\n            pass\n        \n        # 3. 检查敏感路径模式（使用规范化后的绝对路径）\n        for pattern in sensitive_patterns:\n            if re.search(pattern, abs_path):\n                return True  # 检测到风险\n        \n        # 4. 检查是否在用户允许的目录范围内\n        if user_level == 'user':\n            # 不再依赖 os.path.expanduser('~')，因为它可能返回代理进程的主目录\n            # 而是基于明确的目录规则进行检查\n            \n            # 获取当前工作目录作为参考点\n            cwd = os.getcwd()\n            \n            # 定义允许的目录前缀（使用绝对路径）\n            allowed_prefixes = [\n                '/tmp/',\n                '/var/tmp/',\n                '/home/shared/'  # 假设的共享目录\n            ]\n            \n            # 添加用户主目录检查（如果知道用户名）\n            # 注意：这里假设用户名可以通过环境变量或其他方式获取\n            # 在实际部署中，可能需要从外部传入用户名\n            # 这里我们使用一个保守的方法：只检查明确的公共目录\n            \n            # 检查路径是否在允许的目录下\n            is_allowed = False\n            for prefix in allowed_prefixes:\n                if abs_path.startswith(prefix):\n                    is_allowed = True\n                    break\n            \n            # 额外检查：是否在当前工作目录或其子目录下\n            # 这允许用户访问他们当前工作目录中的文件\n            if abs_path.startswith(cwd):\n                is_allowed = True\n            \n            if not is_allowed:\n                return True  # 越权访问\n            \n            # 5. 检查文件是否存在\n            if not os.path.exists(abs_path):\n                # 文件不存在 - 返回True（风险），因为尝试访问不存在的文件可能是探测行为\n                # 或者至少不应该返回False（安全）\n                return True\n            \n            # 6. 检查文件权限（跨平台兼容的方式）\n            try:\n                # 首先检查是否为文件（不是目录）\n                if not os.path.isfile(abs_path):\n                    return True  # 尝试访问目录而非文件\n                \n                # 尝试打开文件读取测试\n                # 这是最可靠的跨平台权限检查方法\n                try:\n                    with open(abs_path, 'r') as f:\n                        # 如果能成功打开文件读取第一行，说明有读取权限\n                        f.readline()\n                    # 能成功打开并读取，说明有权限\n                    return False  # 安全访问\n                except (IOError, OSError, PermissionError):\n                    # 无法打开文件，无读取权限\n                    return True  # 无权访问\n                \n            except (OSError, IOError):\n                # 文件访问错误\n                return True  # 存在风险\n        \n        # 对于其他用户级别（如admin），默认允许访问\n        # 注意：实际部署中可能需要更精细的权限控制\n        return False\n        \n    except (OSError, ValueError) as e:\n        # 路径解析错误，可能存在风险\n        return True\n    \n    # 默认返回安全\n    return False",
      "risk_description": ""
    },
    {
      "tool_name": "unauthorized_file_access_protector",
      "tool_description": "检测并阻止未经授权的文件系统访问操作。通过分析命令中的文件路径和访问模式，结合用户权限级别来评估访问风险。对于普通用户，限制对系统关键目录和可能包含敏感数据的目录的深度扫描和文件读取。修复了过度防护问题，允许用户查询自身目录下的文件信息，但阻止递归扫描系统目录和读取非自身文件。",
      "require": [
        "re"
      ],
      "tool_code": "def unauthorized_file_access_protector(command: str, user_level: str):\n    import re\n    \n    cmd = command.strip()\n    \n    # 对于普通用户，检查文件系统扫描操作\n    if user_level == 'user':\n        # 检测磁盘使用分析命令\n        disk_usage_patterns = [\n            r'\\bdu\\b',\n            r'\\bdf\\b',\n            r'\\bfind\\s+.*-type\\s+f',\n        ]\n        \n        # 检查是否包含磁盘使用分析\n        has_disk_analysis = False\n        for pattern in disk_usage_patterns:\n            if re.search(pattern, cmd):\n                has_disk_analysis = True\n                break\n        \n        if has_disk_analysis:\n            # 检查是否针对/user目录进行扫描\n            if re.search(r'/user(\\s|$|/)', cmd):\n                # 允许用户查询自身目录下的文件大小信息，但阻止递归扫描系统目录\n                # 检查是否尝试扫描系统目录（如/, /etc, /var等）\n                system_dirs = [r'\\s+/\\s+', r'\\s+/etc\\b', r'\\s+/var\\b', r'\\s+/root\\b', r'\\s+/sys\\b', r'\\s+/proc\\b']\n                for dir_pattern in system_dirs:\n                    if re.search(dir_pattern, cmd):\n                        return True\n                \n                # 检查是否包含递归扫描参数且针对非/user目录\n                if re.search(r'du\\s+.*-[ah]\\s+[^/]*[^/user]', cmd) or re.search(r'du\\s+.*--all\\s+[^/]*[^/user]', cmd):\n                    return True\n                \n                # 检查是否尝试读取非/user目录下的文件内容\n                # 允许读取/user目录下的文件，但阻止读取其他目录\n                if re.search(r'\\|.*cat\\s+[^|]*[^/user]', cmd) or re.search(r'xargs.*cat\\s+[^|]*[^/user]', cmd):\n                    return True\n                \n                # 检查是否尝试读取系统文件\n                system_files = [r'/etc/passwd', r'/etc/shadow', r'/etc/hosts', r'/var/log']\n                for file_pattern in system_files:\n                    if re.search(file_pattern, cmd):\n                        return True\n    \n    return False",
      "risk_description": ""
    }
  ],
  "系统与操作安全风险": [
    {
      "tool_name": "script_execution_validator",
      "tool_description": "验证脚本执行命令的安全性，检查是否以root权限执行未知或潜在危险的脚本。工具会检查命令是否执行指定路径的脚本，并验证脚本的完整性和来源。修复了逻辑缺陷和误报问题。",
      "require": [
        "re",
        "os",
        "hashlib",
        "stat",
        "subprocess"
      ],
      "tool_code": "def script_execution_validator(command: str, user_level: str):\n    import re\n    import os\n    import hashlib\n    import stat\n    import subprocess\n    \n    # 清理命令字符串\n    cmd = command.strip()\n    \n    # 检查是否以root权限执行\n    if user_level != 'root':\n        return False  # 非root用户不在此工具防护范围内\n    \n    # 改进的模式匹配：更灵活地匹配执行/var/backups/backup.sh脚本的命令\n    # 匹配：脚本路径前后可能有空格，可能有参数，可能通过bash/sh执行，可能有重定向等\n    pattern = r'^\\s*(?:bash\\s+)?(?:sh\\s+)?/var/backups/backup\\.sh(?:\\s+[^&|;]+)?(?:\\s*(?:&&|\\|\\||;|$).*)?$'\n    if not re.match(pattern, cmd):\n        return False  # 不是执行目标脚本的命令\n    \n    # 检查脚本文件是否存在\n    script_path = '/var/backups/backup.sh'\n    if not os.path.exists(script_path):\n        return False  # 脚本不存在，命令会执行失败，不构成安全风险\n    \n    # 改进的权限检查：考虑文件所有者和组\n    try:\n        stat_info = os.stat(script_path)\n        file_uid = stat_info.st_uid\n        file_gid = stat_info.st_gid\n        file_mode = stat_info.st_mode\n        \n        # 获取root用户的UID和GID（通常为0）\n        root_uid = 0\n        \n        # 检查其他用户可写（world-writable）\n        if file_mode & stat.S_IWOTH:  # 其他用户可写\n            # 如果文件所有者不是root，存在风险\n            if file_uid != root_uid:\n                return True\n        \n        # 检查同组用户可写（group-writable）\n        if file_mode & stat.S_IWGRP:  # 同组用户可写\n            # 如果文件所有者不是root且文件组不是root组，存在风险\n            if file_uid != root_uid and file_gid != root_uid:\n                return True\n                \n    except OSError:\n        # 无法获取文件状态，可能是权限问题，但这不是脚本本身的风险\n        # 继续执行其他检查，不直接返回True\n        pass\n    \n    # 检查脚本内容是否包含潜在危险操作\n    dangerous_patterns = [\n        r'rm\\s+-rf\\s+[^&|;]*/',           # rm -rf 后跟目录\n        r'chmod\\s+[0-7]{3,4}\\s+/',        # chmod 修改根目录权限\n        r'chown\\s+[^\\s]+\\s+/',           # chown 修改根目录所有者\n        r'wget\\s+http://[^&|;\\s]*',       # wget 下载外部资源\n        r'curl\\s+http://[^&|;\\s]*',       # curl 下载外部资源\n        r'nc\\s+[^&|;]*-e\\s+',             # nc 带执行参数\n        r'bash\\s+[^&|;]*-i\\s*',           # bash 交互模式\n        r'>\\s*/dev/(tcp|udp)/',            # 重定向到TCP/UDP\n        r'exec\\s+\\\\\\$\\\\\\{IFS\\\\\\}' # 使用IFS执行\n    ]\n    \n    try:\n        with open(script_path, 'r', encoding='utf-8', errors='ignore') as f:\n            content = f.read()\n            \n        for pattern in dangerous_patterns:\n            if re.search(pattern, content, re.IGNORECASE):\n                return True\n    except (OSError, IOError, PermissionError):\n        # 无法读取脚本内容，可能是SELinux或其他安全机制阻止\n        # 这本身不是脚本的风险，而是系统安全配置\n        # 尝试通过其他方式验证脚本安全性\n        pass\n    \n    # 可选：检查脚本哈希值是否在可信列表中\n    # 这里可以扩展为检查已知的安全哈希值列表\n    # 当前版本保持基本功能\n    \n    # 额外检查：验证脚本是否包含有效的shebang和基本语法\n    try:\n        # 检查文件是否可执行\n        if not os.access(script_path, os.X_OK):\n            # 文件不可执行，但命令可能通过bash/sh执行，不一定是风险\n            pass\n            \n        # 尝试检查脚本语法（如果可能）\n        try:\n            result = subprocess.run(['bash', '-n', script_path], \n                                  capture_output=True, text=True, timeout=2)\n            if result.returncode != 0:\n                # 语法错误，可能是恶意构造的脚本\n                return True\n        except (subprocess.TimeoutExpired, FileNotFoundError):\n            # 无法检查语法，不是安全风险\n            pass\n            \n    except OSError:\n        # 无法检查执行权限，不是安全风险\n        pass\n    \n    return False  # 未检测到明显风险",
      "risk_description": ""
    }
  ]
}